<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-07-31T04:22:05+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">同志社大学社会学研究科　陳凌雲</title><subtitle>地域福祉プログラムとソーシャルワーク評価について学びます。</subtitle><entry><title type="html">Chapter 2</title><link href="http://localhost:4000/2023/07/31/Chapter-2.html" rel="alternate" type="text/html" title="Chapter 2" /><published>2023-07-31T00:00:00+09:00</published><updated>2023-07-31T00:00:00+09:00</updated><id>http://localhost:4000/2023/07/31/Chapter%202</id><content type="html" xml:base="http://localhost:4000/2023/07/31/Chapter-2.html"><![CDATA[<h2 id="orientation-to-the-bigger-picture-of-evaluations">Orientation to the Bigger Picture of Evaluations</h2>

<p>What’s Next?</p>

<p>The chapters in Part II focus on the bigger picture of evaluations. In Chapter 2, several theoretical perspectives and approaches on evaluation are presented along with the key perspectives used in the book. The history of evaluations beginning over 100 years ago are also highlighted. Professional ethics that are important to follow are highlighted in Chapter 3, and some common types of evaluations evident in agencies are described in Chapter 4. Chapter 5 begins to delve into how evaluations are conducted and provides guidelines for how to focus an evaluation.</p>

<p>These chapters are intended to provide a general background of relevant information for the chapters that follow them.</p>

<p>CHAPTER 2</p>

<h2 id="the-influence-of-history-and-varying-theoretical-views-on-evaluations">The Influence of History and Varying Theoretical Views on Evaluations</h2>

<p>Evaluations can take many different forms. We will look at why in Chapter 2.</p>

<p>Evaluations are conducted in many different ways and this chapter focuses on the question of why. It is partially because there are so many different reasons why evaluations are conducted. As described in Chapter 1, evaluations are used to fulfill many different purposes. They can be to determine the effectiveness of a program or practice intervention, its efficiency, its level of quality, or its relevance to helping a particular client group.</p>

<p>Further, evaluations can vary in method. For example, from being small exploratory case studies of one individual to large explanatory studies involving big samples and well-tested measurement instruments. Evaluations can also vary from being more inductive or more deductive and more qualitative or more quantitative in method. Moreover, evaluators have widely varied approaches based on their disciplines. The discipline of social work, being one of them, is largely the focus of this text.</p>

<p>The chapter addresses important historical events and several theoretical perspectives that have influenced what evaluations are about. These varying theoretical perspectives are important to know so that we can be more fully aware of why evaluators do what they do. The chapter begins by highlighting some pertinent historical events that have significantly influenced the evolution of evaluations over more than one hundred years. This is followed by a description of several theoretical perspectives and approaches on evaluations. The chapter closes with a synthesis of the many perspectives and an introduction to how they have contributed to the concept of evaluation developed in this text.</p>

<h3 id="relevant-events-in-history">RELEVANT EVENTS IN HISTORY</h3>

<h4 id="the-impact-of-historical-events-on-program-evaluation">The Impact of Historical Events on Program Evaluation</h4>

<p>The history of social programs has had an enormous impact on what we refer to as evaluations today. Evaluations have emerged through a long and tumultuous history of experimentation with social programs. Several historical events have been instrumental in ensuring that social programs are increasingly accountable to the larger society and to the funding and regulatory agencies that oversee their activities. Concurrently, social workers who function within these programs are also becoming more accountable for what they do.</p>

<p>Program evaluations have not always been a central concern in the functioning of social programs. However, even administrators of social programs operating during the settlement movement and Charity Organization Societies in the early part of the past century were mindful that their programs must work. However, their costs were relatively low, they often depended on volunteers, and they operated at the local level without state and federal governmental assistance or regulation. Perhaps this local control and management ensured that those who oversaw the early programs kept a close watch on their volunteers and activities. Further, they most likely used common sense to determine if they were making headway in accomplishing their goals.</p>

<p>Since then, social problems have become much more complex and expensive to solve. Unfortunately at this point in time, available solutions will, at best, require broad governmental support at an enormous cost that many segments of society may not be willing to allow. Problems like poverty, chronic and severe diseases and other medical problems, addictions, and marital strife are examples. Also, these social programs have expanded to serve infinitely more and varied types of people.</p>

<p>The New Deal legislation in the 1930s ushered in the beginning of national government involvement in social programs by establishing old-age pensions and public assistance for the first time. The public assistance programs, for example, were intended to provide temporary relief to poor people who could not find employment. The emphasis in these programs was on helping limited numbers and only during the Great Depression. Yet, as we know in retrospect, public assistance programs developed into a huge, burgeoning system of social services that became permanent, not temporary, relief.</p>

<p>Social programs soared in the 1960s. Historical events of that decade brought major changes in public policies, particularly in the areas of civil rights, poverty, housing, employment, and de-institutionalization of people with mental illnesses and mental retardation. President Johnson’s Great Society and War on Poverty were instrumental in creating numerous programs, including local Community Action Councils, Job Corp, Neighborhood Youth Corp, Community Legal Services, and Head Start, among others. But the War on Poverty promised much more than it could deliver, as it claimed it could achieve broad goals like eliminating poverty and building strong low-income communities and local community control.</p>

<p>In addition, the 1962 and 1967 Social Security Amendments created new initiatives including social services for welfare recipients who were receiving financial assistance. Rehabilitation became the mantra that replaced relief, and training people for useful work became the goal for addressing prolonged dependency. The 1967 Social Security Amendments separated eligibility for public assistance and social services in the hope of overcoming family disorganization and conflicts. These new social service functions were to be filled by professionals with advanced degrees in social work and other fields who would help poor people strengthen their family ties and become employed, educated, and ultimately self-sufficient. These initiatives not only promised more than they could deliver, but they also led to runaway federal funding to pay for them.</p>

<p>These and other events moved program evaluation to the top of the list of priorities for legislators, funding agencies, and program providers. The pie-in-the-sky promises and expanding federal budgets devoted to social programs created an environment in which a rising social movement of fiscal conservatives emerged and demanded more emphasis on financial cutbacks and fiscal management, program accountability, and evaluations.</p>

<p>After the euphoric reform days of the 1960s, social programs began to face major problems in the 1970s and 1980s. Such programs, particularly those funded by governmental agencies, were no longer popular among many people in positions of power and came under increasing attack. Accountability was still lacking for many of these programs, which left them exposed to growing criticism. Their ambitious agendas sought too much, including overcoming dependency on government and eliminating poverty. Ironically, the opposite appeared to be happening as the number of recipients in public programs soared and costs to the public exploded.</p>

<p>The growing demand for social program accountability culminated in the passage of the Government Performance and Results Act of 1993. This act required strategic planning by all governmental agencies focusing on client outcomes and especially required definitions of how their outcomes would be achieved. The Act gave the U.S. Congress tools to hold all governmental programs and those receiving governmental funds accountable. From here on, the federal government intended to base budget decisions on the agencies’ reports of performance and success in achieving their intended outcomes. This federal act was so important to social work that it became a focus of a key article in the journal Social Work (Kautz, Netting, Huber, Borders, &amp; Davis, 1997).</p>

<p>From this point on, programs would be expected to develop annual performance plans with clear goals and objectives for their programs and employees, quantifiable measurements of these goals, strategies for achieving goals and objectives, a description of the program evaluations that they would use, and a presentation of the results demonstrating the extent to which they had reached their identified goals. These new policies were implemented in 1997. By the end of that year, almost one hundred federal agencies delivered their plans to Congress as required. However, the new act helped federal overseers realize that evaluation plans did not offer an easy or quick fix.</p>

<p>Performance goals and measures were not as results-oriented as expected, and some goals were found not to be objective or measurable. Further, these goals and objectives were not always linked to the individual programs and day-to-day agency activities intended to affect them. Nevertheless, the Government Performance and Results Act has become a key catalyst in an ongoing social movement aimed to hold social programs accountable for documenting their achievements. Amazingly, virtually every program proposal submitted to a funding agency today requires an evaluation.</p>

<p>Today, the development of program and practice evaluations has become more and more professional. Professions like social work, education, and other disciplines have formed professional associations to promulgate standards for high-quality, acceptable evaluations and a regular conference context for sharing ideas and experiences in implementing evaluations. These types of activities occur in professional associations like the National Association of Social Workers and the Council on Social Work Education (CSWE). The CSWE gives major emphasis to evaluating BSW and MSW social work programs as part of its accreditation standards. Multidisciplinary organizations like the American Evaluation Association are also actively involved in promoting similar purposes, and there are at least eight professional journals that focus exclusively on evaluation (see Chapter 6).</p>

<p>The Impact of Historical Events on Practice Evaluation Prominent social workers and government officials have frequently challenged the social work profession and other helping professions to be accountable for their practice effectiveness. Back in 1973, Joel Fischer authored a landmark article in Social Work titled “Is Casework Effective? A Review,” in which he examined all of the studies that he could find to determine whether social casework (what we call practice with individuals currently) was effective. Fischer assumed that effectiveness could be determined only by using a classic experimental design that included a control group that would not receive social casework services. He found seventy studies that he had to discard because they did not have a control group. Only eleven studies met this criterion and thus were reviewed. Unfortunately, Fischer found no evidence from the eleven studies that social casework worked; in some instances, he claimed that client progress declined. This was an embarrassing study that got a lot of bad press for social work at that time.</p>

<p>Numerous evaluations and meta-analyses have been published since Fischer’s study that have focused on the effectiveness of specific social work interventions in helping a variety of client populations (for an example of such a meta-analysis, see Harding &amp; Higginson, 2003). In brief, this meta-analysis uncovered findings not too dissimilar from Fischer’s. Of twenty-two evaluations of interventions to help cancer and palliative care patients, few even used experimental and quasi-experimental designs that could evaluate the interventions’ effectiveness.</p>

<p>The social work profession has been involved in a long, arduous, and often impressive search for new ways to examine how to scrutinize social work interventions to ensure that they work for clients. This examination has continued, sometimes in dramatic ways, up to the present. Gambrill and Gibbs (2017) have made major contributions to the development of critical-thinking principles that practitioners can use. In addition, several authors (e.g., Gibbs, 2003; Glicken, 2005; O’Hare, 2005, 2015) have expanded on the concept of evidence-based practice. O’Hare introduces evidence-based concepts that apply to specific client conditions and circumstances like schizophrenia, depression, personality disorders, and child abuse and neglect.</p>

<p>Glicken has reviewed what evidence-based practice is and how it can be enhanced and measured. He has also focused on evidence-based practice with different client groups including those with substance abuse problems, personality disorders, and mental illnesses. The importance of the therapeutic relationship and the challenges of measuring its impact were also explored by Glicken including variations based on race, gender, and ethnicity. Finally, Fischer and colleagues (e.g., Bloom, Fischer, &amp; Orme, 2009) have helped develop more sophisticated practice evaluation tools, especially additional ways to apply a single system design to evaluating practice and analyzing the results of single-system designs. Greater use of standardized scales is also encouraged by these authors.</p>

<p>Most of the authors writing about evidence-based practice have emphasized the importance of research concepts like experimental and quasi-experimental designs, internal and external validity, influences of sampling, both quantitative and qualitative designs, standardized scales and other related topics. Unfortunately, these are not usually the topics of much interest in most practice courses and with most students in practice tracks. Instead, it seems they have much more invested in developing their own practice approaches that can be artful, complex, and sometimes unique. This makes their approaches difficult if not impossible to replicate for evaluations.</p>

<p>It is the author’s observation, for example, that most social work programs offer separate courses on practice and evaluating practice. The practice courses typically give little attention to the details of applying the tools for evaluating practice such as a single-system design and leave this up to research and evaluation courses taught by a different set of teachers. In this regard, more attention has always been needed in most social work academic programs to infuse the practice and research curricula and the preparedness of faculty to implement it.</p>

<p>Social work faculty, students, and practitioners who are weaker in either area (practice or research) should recommit themselves to further develop their expertise in that neglected area. Social work programs and the profession generally must also do their part in stressing the important work that still needs to be done in forging the critical relationship between delivering practice and measuring its effectiveness. The accreditation agency, the CSWE is to be commended for highlighting evaluation as one of nine overall social work competencies in its accreditation standards (CSWE, 2015). It reads as follows: “Competency 9: Evaluate Practice with Individuals, Families, Groups, Organizations, and Communities.”</p>

<h3 id="varying-views-on-theoretical-approaches">VARYING VIEWS ON THEORETICAL APPROACHES</h3>

<p>The evaluation enterprise is by no means monolithic or uniform in the way it is conducted. It has been driven by many different perspectives. Because all the theoretical perspectives and approaches existing in the evaluation field are too numerous to cover in this short introduction (e.g., Stufflebean, 2001), five are highlighted that seem to be most pertinent to social work. They are the results-oriented approach, feminist approaches, empowerment approaches, experimental and quasi experimental designs, and fourth-generation evaluations. Note that these five theoretical approaches also sometimes have overlapping features. The specific concepts, principles, and skills that each of them uses are described next to assists readers in determining what you may choose to incorporate into your own evolving eclectic evaluation approach.</p>

<hr />
<p>Table 2.1. Five Theoretical Approaches</p>

<ul>
  <li>Results-oriented</li>
  <li>Feminist</li>
  <li>Empowerment</li>
  <li>Experimental and quasi-experimental</li>
  <li>Fourth-generation</li>
</ul>

<hr />

<h4 id="results-oriented-approach">Results-Oriented Approach</h4>

<p>The results-oriented approach focuses on performance, outcomes, and accountability. Evidence-based program and practice approaches and outcome evaluations are most important in this approach. This approach has emerged as a public necessity because social programs have often fallen short of meeting their goals or have had difficulty communicating how they were achieving them (Wholey, 1999).</p>

<p>Advocates of the results-oriented approach believe that it is important to convince a variety of stakeholders that the outcomes they achieve are the ultimate reason why they are in business. In this regard, Wholey presents this three-step process: (a) develop agreement among stakeholders on goals and strategies, (b) regularly measure and evaluate performance goals, and (c) use performance results to improve programs and enhance accountability to stakeholders and the public. This approach gives most of its attention to the ultimate point of a program’s existence: socially desirable outcomes for clients.</p>

<p>As mentioned in Chapter 1, Martin and Kettner (1996) give primary attention to performance and its measurement based on elements such as the efficiency and effectiveness of a social program. Efficiency involves calculating the amount of service provided and the number of clients who complete the program (program outputs) and comparing the outputs to the costs involved (program inputs). Effectiveness, another element of performance measurement, focuses on the outcomes of social programs or results, impact, and accomplishments. Examples could include the number of parents who stop abusing their children as the result of a parenting-skills training program or, in an adoption agency, the number of children successfully placed with new parents. The concepts of program inputs, outputs, and outcomes are developed further in later chapters.</p>

<h4 id="feminist-approaches">Feminist Approaches</h4>

<p>Feminist evaluations are defined by the substantive areas that some researchers choose to study. Feminist evaluators are likely to pursue evaluations that increase social justice for the oppressed, especially but not exclusively for oppressed women. They are inclined to focus on the relative positions and experiences of women in relation to men and the effects that gender issues have on both genders (Deem, 2002). Examples of topics in agency organizations include gender discrimination in hiring and promotion, the low representation of women in administrative and other leadership roles, salary inequities based on gender, and family-supportive policies of employers. Other feminist topics could include the roles of men and women in parenting children and assuming household tasks, enforcement of child support, the earning power of single-parent households, and the availability of quality day care for low-income families. In recent years, feminist evaluations are also becoming increasingly evident in other countries (e.g., Brisolara, Seigart, &amp; SenGupta, 2014).</p>

<h5 id="an-example-of-a-feminist-study-womens-salaries">An Example of a Feminist Study: Women’s Salaries</h5>

<blockquote>
  <p>Gibelman (2003) examined the issue of men’s and women’s salaries in the human services by analyzing existing data from the Bureau of Labor Statistics. She found that salary disparities continue to exist. She attributes these disparities to discrimination patterns. Gibelman recommended several strategies to combat such discrimination, including public and professional education and advocacy. She also pointed out that the gender discrimination experienced by social workers is also evident among some client groups.</p>
</blockquote>

<p>In addition, feminist evaluations can be partially defined by the research methods that they prefer. Most feminist researchers prefer qualitative over quantitative methods because of the flexibility built into this method and the value that it places on uncovering new knowledge about and insight into interventions at deeper levels of meaning. Some suggest that similar principles guide both feminist studies and qualitative methods (Skeggs, 2001). Both feminist and qualitative methodologists are sensitive to a power differential between evaluators and participants in evaluations, and both are concerned that the participants gain something from their involvement in an evaluation.</p>

<p>Both feminist and qualitative methodologists are also likely to assume accountability to the wider community as well as to the research participants. In addition, many feminist evaluators attempt to use principles of the participatory action approach (PAR), such as involvement of participants in as many of the steps of planning and implementing an evaluation as possible. It should be noted that some evaluators do not perceive feminist evaluation as a distinct approach; instead, they view it as a stance taken by some within a broader evaluation approach.</p>

<p>Several authors have covered feminist perspectives in social work practice (e.g., Bricker-Jenkins, Hooyman, &amp; Gottlieb, 1991; Butler-Mokoro &amp; Grant, 2018; Brisolara, Seigart, &amp; SenGupta, 2014). Their practice perspectives have focused on person-centered approaches, inclusiveness, collaboration with clients, and empowerment. These qualities also tend to be highlighted by other evaluators and encourage clients to become as fully involved as possible in evaluations to benefit the clients’ welfare (e.g., Brisolara, Seigart, &amp; SenGupta, 2014).</p>

<h4 id="empowerment-approaches">Empowerment Approaches</h4>

<p>Empowerment is a familiar action term in social work. It refers to promoting increased power for clients and equipping them to assume greater control over their lives. Empowerment approaches advocate for both client rights and client responsibilities in their lives. An empowerment philosophy can be especially important to evaluation activities. For example, it is evident in the empowerment evaluation approach of Fetterman, Kaftarian, and Wandersman (2015). The value orientation of their approach is to help people help themselves and to improve their programs using self-evaluation and self-reflection techniques. Fetterman (2003) describes a basic, logical, and systematic approach to facilitating self-evaluation. Program participants are helped to conduct their own evaluations, and they use outside evaluators and other experts as coaches. Evaluation concepts, techniques, and findings are used to help specific oppressed groups or communities develop their self-determining capacity and improve their programs. Such evaluators typically play the roles of coach, facilitator, expert consultant, and critical friend.</p>

<p>Fetterman et al. (2015) distinguish between empowering processes and empowering outcomes. Empowering processes help people develop the skills needed for them to become independent problem-solvers and decision makers (Zimmerman, 2000). These processes are critical in providing people with a stake in gaining control over their future, obtaining needed resources, and critically understanding their social environment. Macro practice approaches taught in social work programs emphasize these processes. Empowered outcomes, in some contrast, are the consequences that empowerment processes seek. Examples include creating or strengthening organizational networks, creating more accessibility to community resources, and greater citizen control over community decision-making.</p>

<p>“Inclusive evaluations,” developed by Mertens (2003), can be useful to an empowerment approach; she advocates for a deliberate inclusion of groups and communities that have been historically discriminated against on the basis of race, ethnicity, culture, gender, social class, sexual orientation, and disability. This perspective aims to redress power imbalances in society by involving these oftenoverlooked stakeholders and taking seriously and accurately their views and needs.</p>

<p>This perspective promotes social justice outcomes and takes issue with deficit models that blame those affected by a problem.</p>

<p>PAR is a practical type of empowerment model that can be used in evaluations. Sometimes referred to as participant action research or critical action research, PAR is readily familiar in social work research (DePoy, Hartman, &amp; Haslett, 1999). As its perspective, PAR has an interest in actively involving the research participants or subjects in all or most steps of the process. Some of the key PAR principles are the following:</p>

<ul>
  <li>Collaborate with those affected by the problem to clearly articulate the social problem, its scope, and all the people to consider as stakeholders.</li>
  <li>Articulate the purpose of the change that the research is designed to accomplish.</li>
  <li>Have both professional and lay researchers on the team.</li>
  <li>Train the lay researchers in how to design, conduct, and use appropriate research methods.</li>
  <li>Report findings in accessible formats for all stakeholder groups.</li>
</ul>

<p>In specific terms, implementation of PAR can occur in all or some of the Seven Evaluation Steps. For example, if involving community stakeholders in every step is not realistic, they can have a significant role in some steps. For example, client and community stakeholders can be particularly important in the first step (identify the problem to be evaluated) by helping articulate program issues that need to be addressed. Clients can also be involved in the last step (disseminate the results) by assisting in dissemination of evaluation results to various community groups and getting feedback and greater community involvement.</p>

<h5 id="example-of-an-evaluation-with-par-principles-to-support-social-action">Example of an Evaluation with PAR Principles to Support Social Action</h5>

<blockquote>
  <p>Reese, Ahern, Nair, O’Faire, and Warren (1999) initiated a program evaluation using PAR principles that resulted in improved access to hospice services for  African Americans. Collaboration occurred between the research participants and practitioners throughout the study. The evaluators’ activities began with a small qualitative study with African American pastors. This pilot study was followed by    a larger quantitative study of African American hospice patients that documented their access barriers to hospice. Finally, a social action effort was initiated to engage local health care providers in addressing these access barriers. The findings of their studies were used to facilitate this social action effort.</p>
</blockquote>

<h4 id="experimental-and-quasi-experimental-designs">Experimental and Quasi-Experimental Designs</h4>

<p>Advocates of experimental designs believe that experimental and quasi-experimental designs are superior to other designs because they deliver scientifically credible evidence of the impact of a program on the clients’ welfare (Cook &amp; Campbell, 1979). They argue that experimental designs and the randomized samples that they use are feasible and ethical. Further, the features of these designs are the only way to rule out the influence of other factors, such as other means of helping clients and the maturity processes for participants that inevitably occurs over the time of an experiment.</p>

<p>Philosophies deriving from this traditional scientific research paradigm are reviewed only briefly in this section, as readers are expected to be well acquainted with this approach from research methods courses in professional degree programs. In addition, Chapter 9 is partially devoted to experimental and quasi-experimental designs used in program and practice outcome evaluations. If you wish to have more details about experimental and quasi-experimental designs, go to Chapter 9.</p>

<h4 id="fourth-generation-evaluations">Fourth-Generation Evaluations</h4>

<p>Lincoln (2003) and Guba and Lincoln (1989) advocate for a “fourth-generation” philosophy for this era that strives to redress power imbalances and expand the repertoire of data-gathering and data analysis methods used in evaluations. They argue that we must move beyond the modernist and Eurocentric philosophies that tend to believe that rational, orderly investigations and deductions in the social sciences will suffice in arriving at social truth, as it has in the physical sciences. A postmodernist would argue that no single method or design can produce anything more than a partial truth. A postmodernist distrusts all methods equally and recognizes and admits the situational limitations of the knower, whether based in science, literature, the spiritual realm, or another vantage point. Lincoln views politics as a major voice of influence in her inquiries, and her perspective considers the needs of global society, not just Western society. This global perspective particularly seeks to hear and value the often-unheard indigenous voices of other societies.</p>

<p>Guba and Lincoln (1989) also advocate for the use of different types of qualitative inquiries along with the more traditional quantitative methodologies in evaluations. Their writings offer qualitative methodologies and techniques in many forms. Qualitative methods used in evaluations are covered extensively in Chapters 8 and 10 and other parts of this book. In terms of the practical aspects of evaluation, these theorists warn that evaluators who fail to pay attention to the growing number of pluralistic voices in social life will find these voices in a chorus of opposition to any evaluation with a single method of inquiry. Their perspective may be most helpful as a reminder that there is no one perfect evaluation approach and we must always be prepared to think of alternatives to what is currently in vogue.</p>

<h3 id="synthesis-of-these-evaluation-perspectives">SYNTHESIS OF THESE EVALUATION PERSPECTIVES</h3>

<p>As mentioned earlier, the previously discussed five perspectives on evaluation are examples drawn from a larger pool of theoretical perspectives. At this point, it is important to ask how we can make sense out of the differences that exist among these perspectives? Also, what might they mean for a social worker wanting to be an evaluator or conduct their own evaluations? This section looks more closely at these questions. How might the specific features of each perspective be relevant in the different agency settings where you may be located? Hopefully, this section will encourage many of you to begin to craft your own evaluation approaches that may combine features of some or all of these perspectives.</p>

<h4 id="pattons-five-distinct-paradigms">Patton’s Five Distinct Paradigms</h4>

<p>Patton (2002), an evaluator who tends to favor qualitative evaluations, offers five distinct paradigms. Each paradigm, in part, captures elements of the types of evaluations that are pertinent to social service agencies, schools, and institutions that employ human service workers. These paradigms include the traditional social science research paradigm, the social constructionist, artistic and evocative, the pragmatic and utilitarian, and critical change.</p>

<ol>
  <li>Traditional social science research paradigm: The traditional social science research paradigm emphasizes objectivity and the independence of the evaluator from the group studied, and it minimizes the possibility of investigators’ bias. It also pays close attention to validity, reliability, generalizability, and a marked preference for quantitative measurement and experimental designs. This paradigm is expanded in the work of Rossi, Freeman, and Lipsey (2003).</li>
  <li>Social construction and constructionist: This paradigm asserts the inevitability of subjectivity, uses multiple perspectives, favors qualitative inquiry, and offers alternative criteria to validity and reliability for judging methodological quality (e.g., trustworthiness, authenticity, and gathering findings that enhance and deepen understanding). Responding to multiple stakeholder perspectives is a hallmark of constructionist evaluation. This paradigm is expanded in the work of Guba and Lincoln (1989) and Greene (2000).</li>
  <li>Artistic and evocative paradigm: This paradigm, while not widely used in evaluations, uses role-playing and dramatic techniques, poetry, and other literary forms to gather and present data, as well as short stories and narrative techniques to report findings. The criteria for judging artistic and evocative evaluations include creativity, aesthetic quality, and interpretive vitality. The findings of such studies can open the program world to the evaluation audience through literary and dramatic devices and offer a deep sense of the lived experience of program participants. Eisner’s (1991) work models this paradigm.</li>
  <li>Pragmatic and utilitarian paradigm: This paradigm emphasizes the specific practical, informative needs of users of an evaluation. Criteria include responsiveness to the needs of stakeholders, situational adaptability, attending to interactive engagement between the evaluator and stakeholders, methodological flexibility, and preparation of findings that respond to stakeholders’ needs. Patton’s (2008, 2015) utilization-focused evaluations highlight this paradigm.</li>
  <li>Critical change paradigm: In this paradigm, evaluators are involved in evaluations primarily as change agents by bringing a critical change orientation and an explicit agenda to uncover political, economic, and social inequalities; to raise people’s consciousness; and to strive to change the balance of power in favor of the less powerful. A purpose of such evaluations is to increase social justice and increase the ability of the oppressed to represent their own interests through the evaluation and follow-up actions. Critical change criteria undergird empowerment evaluations (e.g., Fetterman, 2003), diversity-inclusive evaluations (e.g., Mertens, 2003), and deliberate democratic evaluations that involve values-based advocacy for democracy (e.g., House &amp; Howe, 2000).</li>
</ol>

<p>Based on these five paradigms, what are the implications for social workers who conduct evaluations? Social workers need aspects of most if not all of these paradigms. They need the objectivity and rigor of the traditional social science research paradigm that is covered extensively in later chapters.</p>

<p>The social constructionist paradigm is also useful because a growing number of concepts that are involved in social work interventions and evaluations are difficult to measure quantitatively. As a result, social work evaluators are increasingly using qualitative methods as well. Chapters 7, 8, and 10, among others, discuss some of these issues in more depth. Also, the social constructionist paradigm has relevance and flexibility in response to the concerns of multiple stakeholders, especially the program recipients.</p>

<p>Social work, a very practical profession, stresses a utilitarian perspective like the pragmatic and utilitarian paradigm, as social work evaluations must be relevant, practical, and responsive to evolving program and practice needs in social agencies. In addition, among the ethical priorities of a social work evaluator is the persistent concern for social justice; many social work evaluators will gravitate toward evaluations that focus on macro practice interventions that can bring about social change beneficial to clients, in keeping with the critical change paradigm. Social change and its role in evaluations is covered further in various chapters of the book.</p>

<p>In conclusion, the evaluation enterprise is by no means monolithic or uniform in its theoretical perspective. It has been driven by many different perspectives and can generate many different benefits for the recipients of programs and practice.</p>

<h4 id="formative-and-summative-evaluations">Formative and Summative Evaluations</h4>

<p>Finally, an important way to distinguish evaluations is to ask whether they are formative or summative. This is the traditional way in which evaluations are distinguished in many program evaluation texts. Formative evaluations focus on planning for a program and improving its delivery of services. Program processes are important to examine, correct, and enhance because of the direct impact they have on the outcomes for program recipients. These evaluations tend to be exploratory and utilitarian in that their findings can be immediately channeled back into enhancing a program, solving a problem, or filling an obvious omission in a program. The agency sponsoring the program usually initiates and conducts such evaluations; the agency staff or outside consultants chosen by the agency drive the evaluation.</p>

<p>Summative evaluations focus on the outcomes of programs and attempt to answer the ultimate question: Did the intervention reach its goals or make a real difference in the lives of recipients? These evaluations have a finality to them in that they attempt to measure whether a program was effective. An external agent, such as an independent evaluator or governmental agency, typically conducts such evaluations to ensure that they are objective. They primarily use a narrower set of research design options, such as experimental and single system. The results of these studies can be decisive in determining whether a program continues, expands, or terminates. Funding and regulatory agencies are most interested in summative evaluations because they provide the kinds of information that they need to make major decisions about future funding.</p>

<p>These two distinct types of evaluations, formative and summative, are somewhat parallel to the distinction in research between exploratory and explanatory studies. Exploratory studies are conducted to learn more about a phenomenon when not much is currently known. Exploratory studies mostly identify general research questions to answer. Explanatory studies are conducted to find support for theoretical explanations that have already had some confirmation in previous studies. Formative evaluations are like exploratory studies in that they are exploratory in nature and not intended to provide results that can help make major decisions about a program. Summative evaluations are like explanatory studies in that they are used to bring finality to a program’s future; either it did or it did not have a significant impact on recipients (see Table 2.2).</p>

<p>Yet, these two types of evaluations, formative and summative, are helpful only to a limited extent. As mentioned in Chapter 1, most evaluations conducted by social workers will be formative. Summative evaluations are less likely to be initiated by a social agency. Nevertheless, the purposes of summative evaluations are important to understand, as they have a vital role in decisions about a program’s future. Research designs used in summative evaluations are a focus of Chapter 9 and are illustrated in other parts of the book.</p>

<h4 id="evidence-based-interventions">Evidence-Based Interventions</h4>

<p>Evidence-based interventions are not a philosophy or theoretical perspective; they are a pledge of assurance that programs and practice interventions are effective and ultimately accountable for what our clients need. Regardless of the specific perspective that an evaluator selects to conduct an evaluation, it should attempt to be as evidence-based as possible. Evidence-based interventions have been defined in medicine as the integration of the best research evidence with clinical expertise and patient values (Straus, Glasziou, Richardson, &amp; Haynes, 2011). Furthermore, Gambrill (1999), a social worker, states that “it involves integrating individual practice expertise with the best available external evidence from systematic research as well as considering the values and expectations of clients” (p. 346). Based on these definitions, evidence-based interventions are defined in this book as interventions that use the best available external evidence that the intervention is effective. Evidence comes mostly from practice experience and research studies with quasi experimental or experimental designs. It is also important that evidence-based sources are consistent with the values and expectations of the clients who receive such interventions.</p>

<p>The words evidence and evidence-based are often used throughout this book. Evidence is something observed first-hand with some or all the senses (sight, hearing, taste, touch, smell). Evidence documenting the effectiveness of a program or practice intervention needs to be empirical or reflect some form of reality in the world. When evidence of a phenomenon is not directly observable, then a secondhand source needs to be found that is reliable and valid. Agency case records and questionnaires responses are examples of second-hand sources of evidence.</p>

<p>Evidence can take many forms and can be used with varying degrees of confidence. The best evidence is based on evaluation studies using the scientific method. Yet, even the results they produce provide evidence at differing levels of confidence. For example, a pre/posttest design only measures how a client functions before and after an intervention, which is much weaker evidence than a pre/posttest experiment design using a control group or a comparison group.</p>

<p>Another important consideration about evidence pertains to who the clients are that benefited from the intervention. Evidence may be available indicating that a specific intervention works with a group of predominantly white mothers in a suburban area of a large city, but we must be cautious not to necessarily assume that this evidence is also relevant to mothers of different ethnic groups or mothers living in large cities, small towns, or rural environments. An evaluation determines whether or not an intervention is effective with a specific group that receives the services. They could be predominately African American, Euro-American, or Mexican, high income or poor. Whatever the characteristics of the clients, they need to be known because we can probably assume that the evidence is more likely applicable to other people similar to this group than people with different characteristics or circumstances. Generalizing from one group to another should involve caution in this respect.</p>

<h4 id="evidence-based-interventions-with-cancer-and-palliative-care-patients">Evidence-Based Interventions with Cancer and Palliative Care Patients</h4>

<p>Harding and Higginson (2003) systematically reviewed articles from several relevant professional journals to identify interventions for helping noninstitutionalized cancer and palliative care patients and their caregivers. They found twenty-two relevant interventions. Overall, they concluded from their review that one-to-one interventions are a means of providing effective support, education, and building problem-solving and coping skills. However, they are time-consuming and costly and may be unacceptable to many caregivers. Group work interventions, in contrast, were also reported to be widely effective for support and education for both caregivers and patients.</p>

<p>The challenges of obtaining empirical evidence of a phenomenon can be illustrated in an outcome study in which the frequency of positive contact that occurs between a client with mental illness and other people can be an outcome measure of successful social adaptation. How can this be determined empirically? It can be observed first-hand if someone were available to observe the interactions of a client all day long without interfering with the contacts in any way. However, this may not be a realistic or ethically sound method of obtaining such information. A second-hand source of such information, such as a relative, friend, or the self reporting of the client, is another possible way to count contacts, albeit subjective and likely inaccurate. Second-hand sources can be inaccurate, so the challenge is to make sure that such reports are as accurate as possible. One way to increase this possibility is to obtain multiple sources, such as reports from two or more people and compare them.</p>

<h4 id="a-unique-international-source-of-evidence-based-information">A Unique International Source of Evidence-Based Information</h4>

<p>The Collaboration or C2 (<www.campbellcollaboration.org></www.campbellcollaboration.org>) is an international source of evidence-based information for programs and practice approaches. Its offices are in several international cities. It may be beneficial to become familiar with the resources that they provide. It is “an independent, international, non-profit organization that provides decision-makers with evidence-based information to empower them to make well-informed decisions about the effects of interventions in the social, behavioral and educational arenas.” C2 has a strategic network of renowned scholars and practitioners worldwide that can provide evidence-based information in two ways: (a) by preparing, maintaining, and disseminating systematic reviews of existing social science evidence, and (b) by random controlled trials using their own databases. C2’s vision is noble as it promotes positive social change and can improve programs and services across the world.</p>

<p>“Best practices” has been a frequently used term in social agencies and is also relevant to the discussion of evidenced-based interventions. Best practices are the “best” or most effective programs or practices known to be effective in helping people overcome their problems. For this reason, evidence-based practices, in many ways, are strongly correlated with best practices. For example, best practices could be the best evidence-based practices known to exist for a specific client group.</p>

<h3 id="key-perspectives-for-the-book">KEY PERSPECTIVES FOR THE BOOK</h3>

<p>This review of several types of perspectives and approaches in conducting evaluations reveals some common and overlapping elements. Those that are most compatible with the evaluation perspectives used by the author include the following:</p>

<ul>
  <li>Importance of science, neutrality, and objective methods;</li>
  <li>Use of critical-thinking skills;</li>
  <li>Recognition that achieving socially acceptable outcomes is an essential program expectation;</li>
  <li>Recognition that the purposes of evaluations can vary widely and dictate what is to be done;</li>
  <li>Importance of working closely with stakeholders and being accountable to them;</li>
  <li>Following a professional ethical code;</li>
  <li>Flexibility in the use of various methodologies, including considering the use of qualitative methods when they can be helpful;</li>
  <li>Affirmation and promotion of diversity; and</li>
  <li>Commitment to social and economic justice.</li>
</ul>

<h3 id="three-stage-approach">THREE-STAGE APPROACH</h3>

<p>The book is organized around the three developmental stages that programs and practice interventions go through; they are planning, implementation, and outcome. This three-stage approach was introduced in Chapter 1 in the discussion about the logic model and is central to the book because evaluations address important issues at all three stages.</p>

<p>When discussing evaluation perspectives and approaches, it is important to remember that a program or a practice intervention is the primary focus. Furthermore, within programs and practice interventions, evaluations give specific attention to a variety of entities called elements. Let’s look at some of the elements of</p>

<p>program and practice interventions that need to be considered. They include input elements, process elements, and outcome elements. (See Figure 2.1.)</p>

<p>Program Elements</p>

<blockquote>
  <p>Important elements of a program are pertinent to an evaluation and may need to be identified at each of the three stages. Input elements are the focus during the planning stage of a program. Input elements can include identifying the potential group of clients to be served, the program intervention to be used, any technologies to be considered, and the various types of staff that need to be hired. During the implementation stage, the elements are referred to as process elements. Examples of process elements include ongoing monitoring of how the intervention is being implemented, and ongoing training provisions for the staff. The elements to be considered during the outcome stage are referred to as outcome elements. They could include, for example, data on the extent to which clients’ reach their goals after completing the program.</p>
</blockquote>

<p>Practice Elements</p>

<blockquote>
  <p>Let’s look more closely at how these three stages are evident in practice interventions. At the practice level, an evaluation could investigate the input elements before the practice intervention is implemented. Some important input elements in practice are similar to those for programs. They can include identifying the potential group of clients to be served and choosing the practice interventions to be used. The credentials that practitioners will need to have to qualify for their positions, such as a professional degree, work experience, and other special skills are also input elements.</p>
</blockquote>

<p>During the implementation of a practice intervention, important process elements can be important to evaluate including monitoring how the practice intervention is being carried out or implemented. Finally, the outcome stage considers how the intervention has impacted the clients. Outcome elements are primarily measures of client progress or lack of it.</p>

<h4 id="client-satisfaction-with-various-practice-approaches">Client Satisfaction with Various Practice Approaches</h4>

<p>Client satisfaction studies are sometimes used to evaluate how well a practice approach is being implemented based on the clients’ perceptions. A client satisfaction study by Baker, Zucker, and Gross (1998) sought, among other things, to determine the perceptions of five groups of inpatient mental health clients who were receiving different treatment modalities and services in five different facilities. The evaluator presumed that the clients with severe mental illness “know what’s good for themselves.” Practice approaches varied across facilities. For example, one facility offered extensive assistance with daily activities, while another offered training groups in psychosocial skills, and a third emphasized case management, family services, and individual counseling. The results revealed that client satisfaction was not found to be significantly different among the five facilities, although some approaches that were used received low ratings.</p>

<h3 id="summary">SUMMARY</h3>

<p>The history of both program and practice evaluations are highlighted in the chapter and provide a fuller understanding of why evaluations are so important and why they take the forms that they do. Five theoretical approaches are described to illustrate some of the varied ways that evaluators’ view the evaluation process. These five approaches include results-oriented approaches, feminist approaches, empowerment approaches, use of experimental and quasi-experimental designs, and fourth-generation evaluations. In addition, nine principles are identified that reflect the author’s preferences for how evaluations should be conducted. They comprise</p>

<p>(a) the importance of science, neutrality, and objective methods;
(b) use of critical-thinking skills;
(c) recognition that achieving socially acceptable outcomes is an essential program expectation;
(d)recognition that the purposes of evaluations can vary widely and dictate what is to be done;
(e) the importance of working closely with stakeholders and being accountable to them;
(f) following a professional ethical code;
(g) flexibility in the use of various methodologies, including considering the use of qualitative ones;
(h) affirmation and promotion of diversity; and
(i) a commitment to social and economic justice.</p>

<p>Evidence-based programs and practice interventions are also defined and elaborated on in the chapter and their importance is emphasized. Evaluations are described as the primary source in determining whether programs and practice interventions are evidence-based. The three-stage approach is also introduced further. This organizational framework is helpful in informing you about each of the three stages of program and practice development and the wide range of possible ways to focus an evaluation.</p>

<h3 id="discussion-questions-and-assignments">DISCUSSION QUESTIONS AND ASSIGNMENTS</h3>

<ol>
  <li>In small groups, choose one of the historical events listed next, review what is summarized about the event in the chapter, and find an additional source of information related to evaluations. Discuss within your small groups what you learned about the event and its importance in shaping evaluations and then share what you have learned with the class.</li>
  <li>Select one of the five theoretical evaluation approaches. Find out more about this approach by reading about it in this and other texts and then find a report of an evaluation in a professional journal that is an example of this approach.</li>
  <li>What is your view of the role of empowerment in evaluation? How can an evaluator promote empowerment through an evaluation? What are your views about the limits of empowerment in evaluations, if any?</li>
  <li>Briefly describe a program evaluation that could be conducted at your agency. What is the overall purpose of the evaluation? What could be accomplished by conducting this evaluation? Which perspectives described in the chapter would have the most impact on how you would conduct this evaluation? Explain why?</li>
  <li>Why is it important to know the theoretical perspective of an evaluator? Pick one of the five approaches described in the chapter and discuss how it can affect, both positively and negatively, how an evaluator conducts a study.</li>
</ol>

<ul>
  <li>President Johnson’s Great Society and War on Poverty, which were instrumental in creating programs such as local Community Action Councils, Job Corps, Neighborhood Youth Corp, Community Legal Services, and Head Start.</li>
  <li>The 1962 Social Security amendments, which established initiatives such as services for welfare recipients, rehabilitation, and training for useful work to overcome prolonged dependency.</li>
  <li>The passage of the Government Performance and Results Act of 1993, which requires all governmental agencies to focus on client outcomes and define how they are to be achieved.</li>
  <li>Joel Fischer’s (1973) article “Is Casework Effective? A Review.”</li>
</ul>

<h3 id="references">REFERENCES</h3>

<ul>
  <li>Baker, L., Zucker, P., &amp; Gross, M. (1998). Using client satisfaction surveys to evaluate and improve services in locked and unlocked adult inpatient facilities. Journal of Behavioral Health Services Research, 25(1), 51–68.</li>
  <li>Bloom, M., Fischer, J., &amp; Orme, J. G. (2009). Evaluating practice: Guidelines for the accountable professional (6th ed.). Boston, MA: Allyn &amp; Bacon.</li>
  <li>Briar-Lawson, K., &amp; Zlotnik, J. L. (Eds.). (2002). Evaluation research  in child welfare: Improving outcomes through university-public agency partnerships. Binghamton, NY: Haworth Press.</li>
  <li>Bricker-Jenkins, M., Hooyman, N. R., &amp; Gottlieb, N. (Eds.). (1991). Feminist social work practice in clinical settings. Thousand Oaks, CA: SAGE.</li>
  <li>Brisolara, S., Seigart, D., &amp; SenGupta, S. (Eds.). (2014). Feminist evaluation and research: Theory and practice. New York, NY: Guilford Press.</li>
  <li>Butler-Mokoro, S., &amp; Grant, L. (Eds.). (2018). Feminist perspectives on social work practice: The intersecting lives of women in the 21st by century. New York, NY: Oxford Press.</li>
  <li>Cook, T. D., &amp; Campbell, D. T. (1979). Quasi-experimentation: Design and analysis issues for field settings. Skokie, IL: Rand McNally.</li>
  <li>Council on Social Work Education. (2015). Educational policy and accreditation standards. Retrieved from <a href="https://www.cswe.org/getattachment/Accreditation/Accreditation-">https://www.cswe.org/getattachment/Accreditation/Accreditation-</a> Process/2015-EPAS/2015EPAS_Web_FINAL.pdf.aspx</li>
  <li>Deem, R. (2002). Talking to manager-academics: Methodological dilemmas and feminist research strategies. Sociology, 36(4), 835–856.</li>
  <li>DePoy, E., Hartman, A., &amp; Haslett, D. (1999). Critical action research: A model for social work knowing. Social Work, 44(6), 560–569.</li>
  <li>Eisner, E. (1991). The enlightened eye. New York, NY: Macmillan.</li>
  <li>Fetterman, D. (2003). Empowerment evaluation strikes a responsive chord. In S. I. Donaldson &amp; M. Scriven (Eds.), Evaluating social programs and problems: Visions for the new millennium (pp. 63–76). Mahwah, NJ: Erlbaum.</li>
  <li>Fetterman, D. M., Kaftarian, S. J., &amp; Wandersman, A. (Eds.). (2015). Empowerment evaluation: Knowledge and tools for self-assessment and accountability (2nd ed.). Thousand Oaks, CA: SAGE.</li>
  <li>Fischer, J. (1973). Is casework effective? A review. Social Work, 18(1), 5–20.</li>
  <li>Gambrill, E. (1999). Evidence-based practice: An alternative to authority-based practice.</li>
  <li>Families in Society, 80(4), 341–350.</li>
  <li>Gambrill E., &amp; Gibbs, L. (2017). Critical thinking for helping professionals: A skills-based workbook (4th ed.). Thousand Oaks, CA: Pine Forge Press.</li>
  <li>Gibbs, L. (2003). Evidence-based practice for the helping professions: A practical guide with integrated multimedia. Pacific Grove, CA: Thomson.</li>
  <li>Gibelman, M. (2003). So how far have we come? Pestilent and persistent gender gap in pay. Social Work, 48(1), 22–32.</li>
  <li>Glicken, M. (2005). Improving the effectiveness of the helping professions: An evidence-based approach to practice. Thousand Oaks, CA: SAGE.</li>
  <li>Greene, J. C. (2000). Understanding social programs through evaluation. In N. K. Denzin &amp;</li>
  <li>Y. S. Lincoln (Eds.), Handbook of qualitative research (2nd ed., pp. 981–999). Thousand Oaks, CA: SAGE.</li>
  <li>Guba, E., &amp; Lincoln, Y. (1989). Fourth generation evaluation. Thousand Oaks, CA: SAGE.</li>
  <li>Harding, R., &amp; Higginson, I. J. (2003). What is the best way to help caregivers in cancer and palliative care? A systematic literature review of interventions and their effectiveness. Palliative Medicine, 17, 63–74.</li>
  <li>House, E. R., &amp; Howe, K. R. (2000). Deliberative democratic evaluation. New Directions for Evaluation, 85, 3–12.</li>
  <li>Kautz, J. R., Netting, F. E., Huber, R., Borders, K., &amp; Davis, T. S. (1997). The Government Performance and Results Act of 1993: Implications for social work practice. Social Work, 42(4), 364–373.</li>
  <li>Lincoln, Y. S. (2003). Fourth generation evaluation in the new millennium. In S. I. Donaldson &amp; M. Scriven (Eds.), Evaluating social programs and problems: Visions for the new millennium (pp. 77–90). Mahwah, NJ: Erlbaum.</li>
  <li>Martin, L. L., &amp; Kettner, P. M. (1996). Measuring the performance of human service programs. Thousand Oaks, CA: SAGE.</li>
  <li>Mertens, D. M. (2003). The inclusive view of evaluation: Visions for the new millennium. In S. I. Donaldson &amp; M. Scriven (Eds.), Evaluating social programs and problems: Visions for the new millennium (pp. 91–107). Mahwah, NJ: Erlbaum.</li>
  <li>O’Hare, T. (2005). Evidence-based practices for social workers: An interdisciplinary approach. Chicago, IL: Lyceum Books.</li>
  <li>O’Hare, T. (2015). Evidence-based practices for social workers: An interdisciplinary approach (2nd ed.). Chicago, IL: Lyceum Books.</li>
  <li>Patton, M. Q. (2002). Feminist, yes, but is it evaluation? New Directions for Evaluation, 96, 97–108.</li>
  <li>Patton, M. Q. (2008). Utilization-focused evaluation (4th ed.). Thousand Oaks, CA: SAGE.</li>
  <li>Patton, M. Q. (2015). Qualitative research &amp; evaluation methods: Integrating theory and practice (4th ed.) Thousand Oaks, CA: SAGE.</li>
  <li>Reese, D., Ahern, R., Nair, S., O’Faire, J., &amp; Warren, C. (1999). Hospice access and use by African Americans: Addressing cultural and institutional barriers through participatory action research. Social Work, 44(6), 549–559.</li>
  <li>Rossi, P., Freeman, H., &amp; Lipsey, M. (2003). Evaluation: A systematic approach (7th ed.). Thousand Oaks, CA: SAGE.</li>
  <li>Skeggs, B. (2001). Feminist ethnography. In P. Atkinson, A. Coffey, &amp; S. Delamont (Eds.), Encyclopedia of ethnography (pp. 426–442). London, England: SAGE.</li>
  <li>Straus, S. E., Glasziou, P., Richardson, W. S., &amp; Haynes, R. B., (2011). Evidence-based medicine: How to practice and teach E. M. (4th ed.). New York, NY: Elsevier.</li>
  <li>Stufflebean, D. L. (2001). Evaluation models. New Directions for Evaluation, 89, 7–98.</li>
  <li>Wholey, J. S. (1999). Quality control: Assessing the accuracy and usefulness of performance measurement systems. In H. P. Hatry (Ed.), Performance measurement: Getting results (pp. 217–239). Washington, DC: Urban Institute.</li>
  <li>Zimmerman, M. A. (2000). Empowerment theory: Psychological, organizational, and community levels of analysis. In J. Rappaport &amp; E. Seldman (Eds.), Handbook of community psychology (pp. 43–63). New York, NY: Plenum.</li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Orientation to the Bigger Picture of Evaluations]]></summary></entry><entry><title type="html">Chapter 1</title><link href="http://localhost:4000/2023/07/27/Chapter-1.html" rel="alternate" type="text/html" title="Chapter 1" /><published>2023-07-27T00:00:00+09:00</published><updated>2023-07-27T00:00:00+09:00</updated><id>http://localhost:4000/2023/07/27/Chapter%201</id><content type="html" xml:base="http://localhost:4000/2023/07/27/Chapter-1.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Chapter 1 introduces foundational material for understanding virtually all the material in the remaining chapters. The book begins by indicating that both programs and practice are its focus. The concept of an evaluation and the steps in conducting an evaluation are introduced. Evaluations are viewed broadly and can be conducted at three different possible stages of development, when programs and practice interventions are being planned, implemented, and during an outcome stage after implementation.</p>

<h2 id="chapter-1"><strong>CHAPTER 1</strong></h2>

<p>Evaluation and Social Work
Making the Connection
Let’s begin by considering three important questions:</p>

<ol>
  <li>Is evaluation an important practice area of social work?</li>
  <li>Is the evaluator role an important one for social workers?</li>
  <li>How can evaluations help improve or enhance social work interventions?</li>
</ol>

<p>These questions may be your questions as you begin to read this book. They are questions that many social work practitioners and students have pondered. This book is about evaluation so the responses to the first two questions, in brief, will be no surprise to you. Yes, evaluation is an important area of social work. In addition, the evaluator role is an important one for every social worker to prepare to practice. Think about this. Some social workers will be evaluators of programs, and virtually every social work practitioner will be an evaluator of their own practice. It’s like asking whether social workers need to know whether they are doing a good job. A good job should include knowing whether your interventions are effective in helping your clients. The third question, asking how evaluation can enhance or improve social work interventions, is the focus of this text.</p>

<p>The underlying theme driving the book is that evaluation is a vital element of any social work approach and is critical for ensuring that social work does work! A reassuring theme is that evaluation is a practice area that BSW and MSW students and practitioners alike can learn. Social workers and students wanting to maximize their impact in their jobs will find what they need in the knowledge, ethics, and skills about evaluations covered in this book. Learning about them will both help you enhance your practice and have a greater impact on your clients’ well-being.</p>

<p>This book provides the needed preparation for evaluation in both a comprehensive and readable format. The primary emphasis is on the various kinds of small and mid-range formative evaluations that are often implemented at the local agency level; less emphasis is placed on the large, complex national and regional evaluations. These smaller formative evaluations are critical ones that social workers either are assigned or may want to take on as an opportunity to expand their practice. Such evaluations can be instrumental in determining whether the programs in which you are working will continue and possibly expand.</p>

<p><strong><em>Example of a Small Formative Evaluation</em></strong></p>

<blockquote>
  <p>An agency that provides an anger management program to perpetrators of domestic violence offers a series of 10 psychoeducational group sessions to help them manage their anger. The agency also conducts an evaluation of this program that is vital to it. An anger management scale is used to measure changes that occur in the participants’ anger after they have completed all 10 sessions of a group program. Throughout the series, the specific items of the anger management scale (e.g., being respectful, having self-control, being self-aware, learning alternatives to violent behavior) identify some of the key discussion topics of the group sessions. In this way, the intervention and its evaluation go hand in hand in helping practitioners and clients engage in a partnership to meet the goals of the program.</p>
</blockquote>

<h2 id="a-focus-on-both-programs-and-practice"><strong>A FOCUS ON BOTH PROGRAMS AND PRACTICE</strong></h2>

<p>Both programs and social work practice are the focus of the book. While programs are covered quite extensively in most evaluation texts, evaluation of practice is covered less. Programs can be larger medium-sized entities serving many clients while practice refers to the activities of a single social worker with one client system. While program entities typically are much larger than practice, evaluations at both levels are important. It’s sort of like saying a family system is important, and the parts played by each family member are as well.</p>

<p>Virtually every social worker is or should be responsible for evaluating their practice. Based on this reality, all social workers need to have competencies in conducting practice evaluations if they are to be accountable for the effectiveness of their practice interventions. This will include evaluations at different system levels of practice including work with one client, a group of clients, a family, a community, or an organization.</p>

<p>We need to know both what a program and practice intervention are and how they are different prior to understanding evaluations. Think of these two concepts as subunits of something larger. Programs are subunits of a social agency, and the practice of one worker is a subunit of a program. Their respective definitions are</p>

<p><strong><em>Program</em></strong>: A subunit of a social agency that provides a set of interventions with common goals for clients.</p>

<p><strong><em>Practice</em></strong>: A subunit of a program that provides a set of interventions by one worker to one client system.</p>

<p>Both programs and practice are referred to as interventions in the text and are often referred to as program interventions or practice interventions. For brevity, sometimes they are also addressed simply as services. Throughout the text, the square symbol will be a symbol that indicates the text in this section will focus only on program evaluations and a circle symbol will be a symbol of evaluations only of practice.Absence these symbols, the material in the text is largely relevant to both programs and practice.</p>

<p><strong><em>Exercise</em></strong></p>

<ol>
  <li>
    <p>As an exercise, identify a program of which you are familiar. Find out the program’s interventions to clients (e.g., a home health program may have a social worker referring clients to several agencies, a nurse assessing a client’s health indicators, and a nurse’s aide bathing the client). Then try to identify a goal that is a more general description of all the interventions (e.g., a goal of a home health program is to help an elderly individual or couple stay in their own home rather than be referred to a nursing home)?</p>
  </li>
  <li>
    <p>Second, identify the practice of one social worker. This may be easier to do. Practice should be the interventions of one social worker in helping a client system (e.g., advocating for the repair of the heating system of the apartment of a client family, referring them to obtain food stamps, or helping them clarify their rights to certain Social Security benefits). Then see if you can identify a goal that is a more general description of these interventions (e.g.,helping a client family live successfully in their own home).
Programs and practice are interdependent in many ways. Overall, practice interventions are defined and guided by the program and its goals. Yet, the effectiveness of programs depends upon the effectiveness of the practice interventions.</p>
  </li>
</ol>

<h2 id="practice-is-embedded-in-a-program"><strong>PRACTICE IS EMBEDDED IN A PROGRAM</strong></h2>

<p>A practice intervention is likely to be embedded in a program. This means that the program is instrumental in informing and shaping practice interventions.The program context offers numerous ways of informing what the practice interventions should be. As an example, one of the purposes of a program could be to reach out and provide services to underserved people in the community such as those who are the poorest and have the greatest material needs. In this case, the interventions of the practitioners should include finding out who the underserved are and reaching out to them in their neighborhoods. In addition, the practitioners could begin by conducting an informal community needs assessment to find out who the underserved people are and then reach out to them in their neighborhoods to find out if they need help.</p>

<p>Another way in which practice is embedded in a program is apparent in the desired program goals chosen for clients. The goals of the program should inform what the outcomes of practice should be. If the outcomes of a program, for example, are to help mental health clients live independently in the community, then the outcomes of practice would likely be to enhance indicators of living independently in their communities. These practice indicators or outcomes could include, for example, finding employment, making new friends, and linking to social supports in the community such as a social club or a church choir.</p>

<h3 id="a-program-is-dependent-on-what-happens-in-practice">A Program Is Dependent on What Happens in Practice</h3>

<p>Practice is an important place where you can discover what works and doesn’t work in programs. If the practice offered by a social worker is not reflecting the program in content and quality, it may be counterproductive both to the program’s purpose and its effectiveness.There can be several reasons why a worker’s practice may not reflect the program’s purposes. Possibly, the worker is not implementing the approach that supports the program’s purpose. This could be the result of inadequate communication within the agency about the practice approach and how to implement it. Or the agency may have hired someone who is not qualified to carry out the practitioner role. And there could be other reasons such as neglecting to monitor the practice of a worker and thus failing to be able to correct such practice. For example, a residential program for people with a drug addiction directly depends upon each of its practitioners and the effectiveness of their interventions. Several questions about practice could be asked such as, Are each of the therapy groups run by people who meet the staff qualifications for these groups? Have staff been adequately trained about what is expected of them by the agency? and Are staff covering the important topics relevant to program success in group sessions? Ultimately, are they achieving the goals set by the program? These and other types of evaluation questions will be discussed more fully later in the text.</p>

<h3 id="agency-training-for-practice-is-important">Agency Training for Practice Is Important</h3>

<p>Practice is not an entity developed in a vacuum or at the whim of a practitioner or supervisor. As previously indicated, practice interventions need to be aligned with the program within which they are embedded. Social work practitioners, once they graduate, usually have a good beginning sense of an overall approach to helping clients. They have likely been introduced to a variety of practice theories taught in their professional program such as cognitive-behavioral therapy, and they have been able to test some of these theories in their field practicum experiences. However, their beginning approach is not likely to be designed to serve a specific client population or at least not the clients in the agency in which they will be employed.</p>

<p>When a new social worker begins employment at an agency, school, or medical facility, they will need to consider numerous new ways to prepare for their practice. For example, their new agency scene will likely require that they make some changes in their approach to helping. Learning about the client population is an important part of that preparation. Who are your new clients? What kinds of problems and needs do they have? What kinds of interventions are known to be most effective in helping them?</p>

<p>The agency and its programs typically have an approach (or approaches) that the agency offers to help clients, and the agency is most likely to expect its practitioners to understand and know how to implement this approach. Mastering a new approach takes time and experience working with several clients.The agency approach may be quite explicit and detailed, it may only be described theoretically (e.g, cognitive-behavioral therapy), or it may even be vague and unnamed and absent a written description. Practitioners new to an agency will need to find ways to learn about the agency’s approach and how to implement it. Hopefully they will have some agency training sessions and assistance from a supervisor who can provide valuable guidance. As new practitioners meet with growing numbers of clients, they will also come to realize the subtle variations in how to implement an agency approach and the unique issues of each client that need to be considered.</p>

<h2 id="introduction-to-evaluation"><strong>INTRODUCTION TO EVALUATION</strong></h2>

<p>Evaluation is a multifaceted approach that addresses some of the most vital questions and issues facing programs and practice, such as the following:</p>

<ul>
  <li>What kinds of clients are the proposed program or practice intervention intended to reach?</li>
  <li>What types of interventions do these clients need?</li>
  <li>How are the interventions to be implemented?</li>
  <li>What impact is the intervention expected to have on the clients?</li>
</ul>

<h2 id="a-three-stage-approach"><strong>A THREE-STAGE APPROACH</strong></h2>

<p>The author views evaluation broadly as important to consider at any of the stages of development of a program or practice. The three basic stages that will be examined in the book are referred to as the planning, implementation, and outcome stages.The planning stage takes place prior to implementing the intervention and involves identifying the characteristics of the clients who are to be helped as well as their needs, designing the interventions that will be introduced to help these clients, and crafting the outcome measures that will be used to determine whether the clients have successfully reached their goals.</p>

<p>During the implementation stage, evaluations are introduced to monitor how well the intervention is being implemented. Finally, after the clients have completed receiving the intervention, an outcome stage occurs when its time to determine how successful the clients have been in reaching their goals. Figure 1.1 above is an important framework that helps begin to organize much of the content of the book and will be presented periodically in appropriate chapters to highlight the focus of each of the stages as they are being covered.Notice that it all begins with the clients’ needs.</p>

<h2 id="different-purposes-of-evaluations"><strong>DIFFERENT PURPOSES OF EVALUATIONS</strong></h2>

<p>Overall, evaluations can have different purposes. Usually, some purposes are emphasized more than others, and this will vary widely. Generally, the usual purposes of evaluations include investigations of the effectiveness, efficiency, and quality of interventions (Martin &amp; Kettner, 2010). Ideally, all three of these purposes are important. However, sometimes they can be at cross purposes with each other. For example, too much emphasis on efficiency could work against quality and effectiveness. This problem is often evident in some for-profit agencies that tend to concentrate too much on efficiency to maximize their profits and less on what clients may need such as more of the available resources.</p>

<h3 id="effectiveness">Effectiveness</h3>

<p>Effectiveness refers to having success in reaching the goals of an intervention. In the case of programs and practice, effectiveness refers to maximizing positive changes for clients. As an example, a public health agency that provides the flu vaccine is effective if it prevents its patients from contracting the flu. An employment referral agency serving chronically unemployed people will be effective if it finds them long-term employment in well-paid jobs. Note that measure of effectiveness for the employment program adds additional requirements beyond just any job (long-term and well-paid).</p>

<p>Effectiveness is evident in the results that are observed and measured after an intervention is completed. These results are often referred to as outcomes for clients. They reflect positive changes that have occurred for clients because of an intervention. It is important to note that if an intervention does not result in positive client changes (e.g., improved communication between a parent and her child), it must be concluded that the intervention was not effective. In such instances, the intervention may need to be revised or replaced by another intervention that potentially will be effective. Typically, a program intervention needs to have documentation that it is effective; otherwise, the program likely risks losing its funding.</p>

<h3 id="efficiency">Efficiency</h3>

<p>The efficiency of a program or practice intervention refers to the financial cost and other resources (e.g., staff, offices, and vehicles) necessary to provide the interventions to clients. Efficiency efforts are concerned with judiciously channeling available resources to what the intervention needs. Misdirected and wasted resources are to be avoided or minimized. Efficiency is particularly important because resources for health care and human service programs are always likely to be limited or even sometimes scarce. The more efficiently that interventions are delivered, the greater number of clients that can be potentially helped. Also, inefficient programs and practice, even if effective, are vulnerable to being discontinued. An example of efficiency could be to choose a less expensive new agency office after the rent goes up. Another example is hire one less staff member and increase the staff workloads.</p>

<h3 id="quality">Quality</h3>

<p>Quality refers to how well the program or practice interventions are delivered or implemented. Are they delivered at a high level of performance? Sometimes this high level has been referred to as “best practices.”” Quality is obviously important because a program or practice delivered very well will likely have a more positive impact on the recipients than one that is of a lower quality. Quality depends, among other things, on the quality of the staff members who are hired to provide the services. For example, do they have the most important credentials for the job such as a professional degree, appropriate training, and enough prior experience? Also, are new staff members responsible, ethical, reliable, and good communicators? In addition, does the program support enough home visits or group sessions for clients to accomplish their goals? Further, are the interventions provided in a most accessible way so clients can easily find and use them? Many other questions could also be asked such as, are the social workers to be hired culturally competent? Is clinical supervision readily available and provided by experienced personnel? These examples are all likely to be associated with a higher quality of services.</p>

<p><strong><em>Exercise</em></strong></p>

<blockquote>
  <p>Determining quality can be complicated, and yet it is extremely important. As an exercise, what would you do to augment the quality of a social worker to be hired in the following situation? A social worker is to be hired to provide intensive counseling to emancipated adolescents who are about to be released from foster care.The overall goal of the counseling is to help these adolescents begin to live independently in the community.What information would you want to gather from applicants, both in their resumes and in interview questions, to select a social worker who will likely provide high-quality counseling with these adolescents?</p>
</blockquote>

<h3 id="effort-and-relevance">Effort and Relevance</h3>

<p>In addition to the three previously mentioned common purposes of programs and practice, two more are also important if not crucial: evidence of substantial effort on the part of the sponsor of an intervention and relevance to the clients and the community. Evidence of effort is important regardless of the achievements of a program. Effort refers to the extent of involvement of staff members, volunteers, and administrators contributing to program and practice interventions. This involvement is most important when the interventions are being implemented. Questions that can be asked about effort include, How much time was spent in helping clients?</p>

<p>How many home visits or office sessions occurred and what happened during these sessions? Another important question is whether the effort is sufficiently responsive to the expectations of the stakeholders including the funding agency, the program director, and clients?</p>

<p>Relevance is another fundamental quality to consider in evaluating any intervention. Relevance of the intervention to the clients’ needs and the larger social problems that clients are experiencing is most important. A program intervention can be carried out with high performance standards, efficient use of resources, and achievement of specific goals, but if it is not directly relevant to what the clients need, it is incomplete and misguided. The concept of relevance is about addressing the causes of the clients’ problems, not merely symptoms or short-term surface issues of little significance. Relevance is also concerned with insuring that the diversity reflected in the clients who receive the intervention is similar to the diversity in the larger population that is suffering from the social problem. Overall, relevance involves seeking social justice for a client group that it serves. Diversity and social justice issues, as well as other important issues of relevance,are covered extensively in the text. As examples, both the National Association of Social Workers (NASW) Code of Ethics and the American Evaluation Association (AEA) code highlight numerous issues and responsibilities for evaluators to take seriously.
In summary, five important evaluation questions need to be asked in any serious evaluation of a program or practice intervention. Please keep all of them in mind as you proceed through the rest of the text.</p>

<h3 id="five-key-questions">Five Key Questions</h3>

<ol>
  <li>Is the intervention effective in helping clients?</li>
  <li>Does the intervention efficiently use all available resources?</li>
  <li>Is the intervention being implemented at a high level of quality?</li>
  <li>Is there evidence of substantial effort by staff members and others in implementing the intervention?</li>
  <li>Is the intervention sufficiently relevant to the needs of the clients and the social problems confronting them?</li>
</ol>

<h2 id="common-characteristics-of-evaluations"><strong>COMMON CHARACTERISTICS OF EVALUATIONS</strong></h2>

<p>To fully understand the nature of an evaluation, we need to not only understand the purposes of evaluation but also its common characteristics. When we examine an evaluation, we should be looking for manifestations of these common characteristics. The absence of any of them may suggest that an evaluation has important missing elements or shortcomings. These common characteristics include</p>

<ol>
  <li>Be accountable.</li>
  <li>Use scientific research methods.</li>
  <li>Use the logic model as an analytic tool.</li>
  <li>Be open to a diversity of stakeholders and a political process.</li>
  <li>Be attentive to contextual issues in an agency and its environment.</li>
  <li>Abide by an ethical code.</li>
  <li>Be critical thinkers.</li>
</ol>

<p>We should keep in mind that each of these common characteristics continually interacts with and influences the others.</p>

<h3 id="be-accountable">Be Accountable</h3>

<p>If there is one overall concept that explains why evaluations are so important, it is accountability. Partially because of past failings of social programs, all governmental and most privately funded agencies are held accountable for how they use their funds and what they achieve for their clients. Evaluations have become one of the most reliable mechanisms incorporated into program proposals for ensuring such accountability. Agency accountability is now inherent in the jurisdiction of virtually all funding and regulatory agencies, and it has become a key job expectation of agency and program administrators.
These funding, regulatory, and administrative entities require accountability to address questions such as the following:</p>

<ul>
  <li>Is the intervention focusing on the target population with the greatest need?</li>
  <li>Is the intervention designed to meet the specified needs of the target population?</li>
  <li>Is the intervention being implemented in the way that it was designed and proposed?</li>
  <li>Is the intervention being implemented with high standards?</li>
  <li>Are the clients and their families satisfied with the intervention?</li>
  <li>Is the intervention achieving its goals and objectives?</li>
  <li>Is the intervention cost-effective?</li>
</ul>

<p>Ultimately, it is important for program sponsors to be accountable to the clients they serve.Because of the power imbalance between an agency and clients, special attention is needed to bring more balance between these two entities in the form of greater power and protection for clients. In addition, agencies need to be accountable to the communities that are intrinsically connected to clients, such as their family members and the neighborhoods surrounding residential programs.Accountability to clients and relevant communities often requires the introduction of empowerment strategies, such as client satisfaction surveys and client representation on agency boards and advisory groups. Another strategy is to encourage agencies to involve client groups as participants in program evaluations and to share the results of their evaluations with them. Chapter 2 further elaborates on other empowerment strategies.</p>

<p>Social workers who work in such programs must be accountable not only to the agency employing them but also to their own professional groups, such as the NASW,Political Action for Candidate Election (PACE, a political arm of NASW), and their state-level professional licensing boards. In these instances, accountability refers to abiding by an ethical conduct of social work, commitments to clients’ dignity and well-being, advocating for social justice, and implementation of sound and evidence-based professional practice.</p>

<h3 id="use-scientific-research-methods">Use Scientific Research Methods</h3>

<p>Evaluation activities are expected to be scientific and consider using a wide range of research methodologies (e.g., Dudley, 2011). Scientific research has long-standing values and principles that distinguish it from other types of information gathering. Many of these principles are evident in evaluations.</p>

<h3 id="principles-of-scientific-based-evaluations">Principles of Scientific-Based Evaluations</h3>

<ul>
  <li>The search for something that exists rather than something that is desired</li>
  <li>Use of a methodology that minimizes the influence of biases and involves a systematic set of steps or procedures that can be flexibly employed</li>
  <li>Abide by a special code of ethical conduct that includes a commitment to neutrality in conducting research and a demonstration of concern to protect the people studied</li>
  <li>Assumption that the evaluation has a universal stance, representing the concerns of all society, even though it may focus on a few subgroups of people or a narrow topic</li>
  <li>Accurate report of the findings despite whether they are consistent with the researcher’s viewpoints.</li>
</ul>

<p>While these principles of scientific research are expected for all scientific studies, they are evident in evaluation studies to varying degrees and along a continuum of quality. The more an evaluation rigorously fulfills these principles, the more confident one can be that it is based on “good science.”</p>

<h3 id="use-the-logic-model-as-an-analytic-tool">Use the Logic Model as an Analytic Tool</h3>

<p>The logic model is an organizing framework that many evaluators use to analyze both programs and practice. The logic model helps highlight how the stages of an intervention mentioned earlier (planning, implementation, outcomes) should be logically linked. In other words, this model anticipates that what was decided in the planning stage will be used to inform what happens during the implementation and outcome stages. In turn, the planning and implementation stages directly influence what the client outcomes will be and how they will be measured.</p>

<p>First, let’s consider programs at all three stages using the logic model. The linkages among the three stages are important to understand in some depth. Using an illustration, assume that a group of stakeholders have the purpose of setting up and implementing a program to help people who are chronically homeless find semi-independent housing. They begin in the planning stage. First, they will need to decide who their clients will be. In our illustration, this will likely be people who are chronically homeless, and possibly they will also consider other important client characteristics. The stakeholders will also need to decide what their clients’ desired outcomes will be. This question addresses how these clients and their social circumstances will be different after they have been helped. In our example, the stakeholders are interested in helping the clients find and live successfully in a supportive, semi-independent living arrangement.</p>

<p>This leads to a central question in the planning process.How will they help these clients reach this outcome? Let’s say that the stakeholders have done some research about housing for homeless people and have become interested in the Housing First model that is being implemented many places across the United States.Agencies that have used this model have accumulated extensive evidence of chronically homeless people being helped to move directly from the streets and shelters into Housing First housing arrangements with minimal eligibility criteria. If they have mental health issues or substance problems, for example, this means that they will still be able to move into a supportive housing arrangement and receive help from a multidisciplinary professional team on site as soon as they arrive (e.g., Urban Ministry Center,2017).</p>

<p>Note that the link or connection between the client outcome measures and the interventions are critical to the logic model. In our example, this means that the intervention that is chosen is expected to help clients successfully reach the client outcomes identified. In other words, the intervention that is selected should be evidence-based if possible. Evidence-based interventions are interventions that have been implemented before with documented scientific evidence of their effectiveness. In our example, let’s assume that the chosen intervention, the Housing First model, has been found to be effective in the past in helping chronically homeless people live successfully in semi-independent housing (e.g., Urban Ministry Center,2017).</p>

<p>The implementation stage comes next. This stage involves implementing the chosen intervention. Evaluations that are important during the implementation stage primarily consist of monitoring how well the intervention is being carried out with clients. Important evaluation questions at this stage include exploring whether the intervention is being implemented in the manner that it was proposed and observing whether the clients are responding favorably to the intervention’s effect. In our housing example, the evaluators are attempting to determine if the clients are receiving the professional assistance that they need such as person-centered mental health services and adjusting well to their new living arrangement.</p>

<p>The third stage is the outcome stage. This step comes once the clients have completed the intervention. At this point the evaluators must decide whether the clients have succeeded in reaching the client outcomes identified in the planning stage.If so, a claim can be made that the intervention was successful or effective. In our housing example, positive measures of the outcomes would indicate that the clients are successfully living in their new apartment building and meeting other important needs related to successful housing, such as their mental health adjustment. Also, successful outcomes will likely need to reflect efficiently used available resources and costing less that any known alternative interventions.</p>

<p><strong><em>Example of the Use of the Logic Model in Designing a Program</em></strong></p>

<blockquote>
  <p>A group of MSW students was asked to design a program that would effectively help clients overcome substance abuse problems. They used the logic model to complete this exercise. They began by identifying some suspected causes of substance abuse, including heredity, peer influence, low self-esteem, social isolation, and inadequate coping skills. Next, they decided to design a program to address only the suspected causes that revolved around interpersonal issues, including peer influence, social isolation, low self-esteem, and inadequate coping skills. They decided to offer psychoeducational groups to teach clients the skills needed to manage these and other personal and interpersonal issues. They decided to cover specific topics such as how to find positive peer influences and avoid negative ones, how to find and participate in support groups, and some self-esteem building exercises. They anticipated that once participants had completed the psychoeducational group sessions they would be able to identify the factors that reduced their self-esteem, identify specific ways to build more positive selfesteem, and learn three or four new coping skills. By completion of the program, participants would also have made two or more visits to a support group in the community to help them stop using substances.</p>
</blockquote>

<p>Practice should also be evaluated at all three-stages using the logic model.Inputs are addressed during the planning stage including deciding which clients (or client systems) will receive the intervention, identifying the desired client outcomes, and choosing the intervention (approaches and processes) that the practitioner will use. During the time that the practice intervention is being implemented, monitoring is needed to determine how well the approach and processes are being implemented. Finally, after the intervention has been completed, evaluations of client outcomes are completed that determine how much progress the clients have made after they received help. This is largely determined by the outcome measures that were selected during the planning stage.
In summary, the logic model helps the evaluator link the documented problems and needs of the clients to the intervention that will address them, and the intervention is, in turn, linked to the client outcomes that are anticipated after the intervention has been implemented. The logic model is elaborated on further in Chapters 2, 6 and 8. The three-stage approach is introduced more fully in the next chapter.</p>

<h3 id="be-open-to-a-diversity-of-stakeholders-and-a-political-process">Be Open to a Diversity of Stakeholders and a Political Process</h3>

<p>While basic research is often considered apolitical, evaluations usually involve an overtly political process, meaning differences of opinion, view, and interest are present.Historical events and current political considerations need to be considered when discussing, planning, and implementing an evaluation. Indeed, an evaluation is a special type of research that intentionally incorporates political considerations into its execution. An evaluation may have several different stakeholders, and each one could have special interests that compete with that of other stakeholders. This is because stakeholders are usually a varied group. They could include governmental funding and regulatory agencies, foundations, public officials, board members, agency administrators, staff members, citizens, clients, advocacy groups, accountants and auditors, and representatives of the surrounding community. As you can imagine, each of them will likely have different interests.</p>

<p>When talking about an evaluation, political issues almost always come into play, whether explicitly or implicitly. For example, political processes might be involved in any of the following types of questions that agency administrators, in particular, might raise.</p>

<ul>
  <li>How can we help those with the greatest need?</li>
  <li>How can an evaluation help our program survive?</li>
  <li>How can an evaluation improve our chances of obtaining funding to expand our program?</li>
  <li>How can the results of an evaluation be used to enhance our program’s identity in the larger network of agencies in our field?</li>
  <li>How can we report negative findings from an evaluation without jeopardizing our program’s existence?</li>
</ul>

<p><strong><em>Example of a Political Consideration</em></strong></p>

<blockquote>
  <p>A graduate student conducted an evaluation of staff morale at her field agency. She gave the staff members a questionnaire to fill out, asking them how important they perceived each of several different issues that affected their morale.The issues included salaries, medical benefits, size of caseloads, hours of work, supervision (its quality and frequency), and openness of administration to staff concerns. The findings revealed that their major concerns about morale related to their problems with supervisors and administration. Because the administration of the agency was taken by surprise and unprepared to seriously address these issues, they decided to ignore them and instructed the graduate student to withhold sharing her findings with the staff members.</p>
</blockquote>

<p>In contrast, a funding agency might ask very different questions about an evaluation, such as:</p>

<ul>
  <li>How can I be sure that this program is fulfilling its responsibilities?</li>
  <li>How can I determine whether this program is more important than another program that we may want to fund?</li>
  <li>How can I get the most fiscal value out of this program?</li>
  <li>I like this program and its director, but how can I justify funding them when the proposal falls short of what we want?</li>
</ul>

<p>Political influences such as these must be considered at all stages of evaluating interventions, including during planning, implementation, and outcome. An approach that can be used to identify and analyze these contextual forces within and outside an agency is elaborated on later in the chapter. In general, this approach can help evaluators consider the political issues and questions that they may need to address or avert in conducting an evaluation before they become serious problems or ethical dilemmas. This approach helps evaluators identify both constraints that can create conflicts for an evaluation and potential resources that can help in conducting the evaluation.The identification ofpotential constraints and resources before implementation of an evaluation helps address both its feasibility and its ethical standing.</p>

<h3 id="be-attentive-to-contextual-issues-in-an-agency-and-its-environment">Be Attentive to Contextual Issues in an Agency and Its Environment</h3>

<p>A program and its practice interventions do not exist or operate in a vacuum. They are part of a larger dynamic system of many forces and factors. They include a wide range of policies, administrative leadership styles, staff and administrative communication patterns, varied perceptions of clients, and financial issues, all of which theoretically need to be taken into consideration when conducting a program evaluation. Figure 1.2 provides a sketch of many of these factors, large and small, in an agency and its environment.</p>

<p>These factors and their dynamic interplay can have a major influence on an evaluation conducted by the agency. Social policies, for example, from several sources have direct influence on evaluations since they give programs and practice approaches meaning and purpose related to the problem to be addressed and the proposed solution. Governmental policies (local, state, and federal) are important to consider because they dictate what problems and solutions they will fund. Agency policies also have a direct or indirect influence in a wide range of areas such as financial matters, hiring, personnel, client admissions, and programmatic issues. An agency may have a specific policy, for example, about which client groups to prioritize for receiving services. Or they may take a strong stand supporting evidence-based interventions. Or client-centered practice. Or they could have a major commitment to strong fiscal policy and an expectation that benefits be in line with costs.By the way, agency policies that explain something about the nature of programs and practice may not be evident to new staff members and may need to be explained to them.</p>

<p>Leadership style is another example of a factor of influence. One illustration of this dynamic interplay is administrative leadership styles. Administrators can assume many different styles, including autocrat, collaborator, and delegator. Administrators who are primarily collaborative, for example, are likely to have a different kind of influence on staff members when conducting an evaluation than those of an autocratic administrator.</p>

<p>Also, organizational structures and processes, both informal and formal, are important factors with respect to their interplay with decision making (Weissman, Epstein, &amp; Savage, 1983). In this case, while it is usually a good idea to consult everyone in an organization who is interested in and affected by an evaluation, some players will be more important to identify, including the people who formally oversee the program in question and those who have informal influence regardless of their formal title. These informal players, for example, could be instrumental in supporting or undermining an agency’s formal structure. They could be, for example, lower-ranked employees, such as a highly invested secretary or a popular and outspoken staff member. All in all, evaluators can commit a serious and possibly fatal error in an evaluation if they overlook informal stakeholders who may be potentially central to the success of an evaluation but are excluded from evaluation discussions.</p>

<p>Many other contextual factors are also directly relevant to an evaluation. For example, are the agency leaders well informed and educated about evaluations, as well as unequivocal supporters of evaluations? Or do they comprise novices who may be cautious and reluctant to pursue a study that can be risky? What is the agency’s track record in this regard? Some standard questions of this sort could be asked of agency leaders at the outset to find out:</p>

<ul>
  <li>What kinds of expertise does the agency have for conducting a variety of evaluations?</li>
  <li>How cooperative are staff members, both professional and support staff, in taking on additional responsibilities such as filling out questionnaires or searching for client records?</li>
  <li>What’s in it for the administration and direct service staff? Are all motives openly known and transparent, or do some appear to be covert or hidden?</li>
  <li>Are there reasons staff members may be suspicious of the motives for an evaluation or reluctant to participate for fear of jeopardizing their jobs?</li>
</ul>

<p>Several contextual factors could also influence the extent to which the agency will disseminate the findings of an evaluation and implement its recommendations, including whether there are adequate resources, degree of desire to bring about a change in direction, and openness to risk the program’s future. More attention will be given to these various forces in later chapters within the context of specific topics.</p>

<h3 id="abide-by-an-ethical-code">Abide by an Ethical Code</h3>

<p>Ethical issues are extremely important to identify when addressing political issues. The way in which decisions are made or not made should be partially based on an ethical code such as the NASW Code of Ethics (<www.naswdc.org>) or the ethical principles of the AEA (<www.eval.org>). As social workers and other human service professionals know, those who participate in research and evaluation are obligated to follow an ethical code.The NASW Code of Ethics is a basic code required of all social workers. It obligates an evaluator to be well informed about ethical issues and well versed in how to implement a variety of measures intended to prevent ethical problems from occurring. In addition, the ethical principles of the AEA are designed for professional evaluators specifically conducting evaluation studies. These principles are valuable to consult because they are directed toward issues essential for a professional evaluator to address (the AEA ethical principles are described in Appendix A).</www.eval.org></www.naswdc.org></p>

<p>Ethical problems include such things as physical and psychological harm to research participants, invasion of their privacy, and misrepresentation of study findings. Evaluators are obligated to prevent such ethical problems by implementing a variety of ethical safeguards, including an informed consent protocol, confidentiality, and selection of evaluators with appropriate credentials and objectivity. Chapter 3 focuses on a more extensive introduction to many of the ethical concerns that are evident in evaluations and how to address them. It examines the NASW Code of Ethics and some of the ethical principles of the AEA, particularly as they pertain to the ethical obligations of social workers conducting evaluations.</p>

<h3 id="think-critically">Think Critically</h3>

<p>Another important characteristic of evaluations is critical thinking. Critical thinkers are natural skeptics about how well an evaluation is conducted, whether it is someone else’s evaluation or one’s own. Gambrill and Gibbs (2017) identify several types of problems that program providers experience when they fail to be critical thinkers:</p>

<ul>
  <li>Overlooking the people who may need the services of a program the most;</li>
  <li>Not understanding the larger social forces that influence the ways clients behave;</li>
  <li>Focusing on irrelevant factors that are not important in helping clients make progress;</li>
  <li>Misclassifying or misdiagnosing clients and their problems;</li>
  <li>Selecting interventions that are weak or inappropriate;</li>
  <li>Arranging for interventions to continue either too long or not long enough; and</li>
  <li>Being overly preoccupied with financial profit and neglecting the impact of such decisions on the clients’ well-being (especially in for-profit agencies).</li>
</ul>

<p>The Council on Social Work Education (CSWE) views critical thinking as essential to the practice of every social worker. Because of the importance of critical thinking, CSWE refers to it as an element to be implemented in most of the nine required social work competencies (CSWE, 2015).</p>

<p>A final note needs to be made about how the characteristics of evaluations are different from other types of research, particularly social science research conducted in academic settings. A closer look at the previously described common characteristics of an evaluation provides a helpful way of distinguishing evaluations and other types of research. First, evaluations are conducted primarily to provide accountability to a funding agency, clients, and the larger community that an intervention works effectively and efficiently, while social science research does not. Second, an evaluation places major emphasis on the logic model while most social science research does not. The logic model helps evaluators examine the links between the clients’ problems, an intervention, and success in helping clients address these problems. Third, successful evaluations seek the involvement of all the important stakeholders while social science research may not. Evaluation stakeholders typically include groups with widely varying perspectives such as clients, regulatory agencies, and the agency administration overseeing the intervention. Fourth, an evaluation is continually engaged in a political process that attempts to bring together these widely different stakeholders so that ideally all their views are considered, and all are participating in harmony with each other. This is not usually an emphasis of social science research.</p>

<h2 id="seven-steps-in-conducting-an-evaluation"><strong>SEVEN STEPS IN CONDUCTING AN EVALUATION</strong></h2>

<p>A general approach for conducting an evaluation is introduced here and elaborated on further in later chapters. The steps of thnis approach apply to both program and practice evaluations. The approach involves seven general steps based on a modified version of the steps identified in other evaluation approaches (e.g., Bamberger, Rugh, &amp; Mabry, 2019;Linfield &amp; Posavac, 2019;York,2009). Since the word “steps” is also used in other contexts in various parts of the book, whenever “steps” refers to this approach, it will be identified as the Seven Evaluation Steps.</p>

<h3 id="seven-evaluation-steps">Seven Evaluation Steps</h3>

<p>Step 1:Identify the Problem or Concern to Be Evaluated.</p>

<p>Step 2:Identify and Explore Way/s to Involve Stakeholders.</p>

<p>Step 3:Determine the Purpose of the Evaluation.</p>

<p>Step 4:Plan the Evaluation.</p>

<p>Step 5:Implement the Evaluation.</p>

<p>Step 6:Prepare a Written or Oral Report.</p>

<p>Step 7:Disseminate the Findings.</p>

<h4 id="step-1-identify-the-problem-or-concern-to-be-evaluated">Step 1: Identify the Problem or Concern to Be Evaluated</h4>

<p>During step 1, the evaluator becomes familiar with the problem or concern that an evaluation will examine. Some general questions to ask include the following: What is to be evaluated? Is the program working effectively or are there some problems that are evident? Similarly, on the practice level, is the intervention with the client working effectively? Why or why not?</p>

<p>During this step, it is also important to begin gathering information about the context of the problem. It would be helpful to find out more about some of the pertinent components of the program or practice intervention. Also identifying the client population that is served, the clients’ problems and needs that the intervention addresses, and the goals of the intervention. The services and goods that are provided to reach these goals are also important to identify and understand.</p>

<h4 id="step-2-identify-and-explore-ways-to-involve-stakeholders">Step 2: Identify and Explore Ways to Involve Stakeholders</h4>

<p>A concurrent step with the information gathering of step 1 is to identify and explore ways to involve the stakeholders of the program. Stakeholders are the people who are invested in the intervention in some way, such as representatives of the funding and regulatory groups that finance and set standards for the intervention and the administrators and board members of the agency sponsoring the program.Some stakeholders, especially program directors, are likely to be evaluated based on the interventionI’s performance, so they also have an obvious stake in what happens. Staff members who deliver the goods and services have an obvious stake in the intervention as well. Their jobs depend on the program’s survival and may also depend upon the success of their interventions. In addition, clients who are the recipients of the intervention and their family members have a vital stake in what happens to the intervention, as their daily functioning and very survival may depend on how well it performs. Stakeholders are likely to be different for program and practice interventions. Program interventions tend to primarily be macro stakeholders, such as members of a board of directors, community advisory boards, and others in the public sector, while the main stakeholders of practice interventions are often supervisors, practitioners, and client advocates.</p>

<h4 id="step-3-determine-the-purpose-of-the-evaluation">Step 3: Determine the Purpose of the Evaluation</h4>

<p>At this point, the evaluator needs to become familiar with the program or practice interventions to be evaluated and any known problems. Concurrently, relationships need to be developed with the stakeholders.Also, information needs to be gathered about who wants the evaluation and why. These discussions can help the evaluator find out how much the stakeholders know about evaluations, their views and past experiences with them, and whether they have a narrow or broad understanding of what an evaluation can be. These discussions should also be used for the evaluator to highlight the potential contributions of an evaluation, such as program improvements, new opportunities to help clients, or assistance in making important decisions.Examples of potential contributions to an evaluation are listed next.</p>

<p>These discussions with stakeholders should not only uncover any contributions and resources that can support an evaluation, but also any apprehensions or doubts of stakeholders about evaluations generally. For example, could an evaluation be perceived as risky for some reason? Too costly? Take too much time? Interfere with program or practice operations? Therefore, during this step, it is also important to help the stakeholders identify any real or potential constraints such as the following.</p>

<p>Step 3 becomes complete when all stakeholders and the evaluator have agreed on the general purpose of an evaluation. If a commonly agreed-on purpose for an evaluation cannot be identified, negotiations would likely be delayed or discontinued until a purpose could be identified. Identifying the purpose of a program evaluation is important as it may lead to keeping, expanding, or eliminating a program, and a practice evaluation may lead to varying an approach with some types of clients.</p>

<p><strong><em>Examples of Contributions and Resources to Consider</em></strong></p>

<ul>
  <li>Concerns expressed by stakeholders are highly relevant to clients’ well-being.</li>
  <li>Stakeholders have considerable interest in an evaluation.</li>
  <li>Existing policies of the agency are supportive.</li>
  <li>Financial support is evident.</li>
  <li>An awareness of a problem with a program is evident.</li>
  <li>Openness to examine a problem further is expressed.</li>
  <li>Some understanding and respect for evaluations are expressed.</li>
  <li>Openness is evident to the evaluator as a resource.</li>
  <li>Staff are supportive of an evaluation.</li>
</ul>

<p><strong><em>Examples of Constraints or Resistant Forces</em></strong></p>

<ul>
  <li>Limited time is available to conduct an evaluation.</li>
  <li>Costs appear too high.</li>
  <li>An evaluation is not supportive of existing policies.</li>
  <li>Evaluation focus can be too subjective.</li>
  <li>Fears it will open up the need to change.</li>
  <li>Limits are evident about what can change.</li>
  <li>Politics of the system are complex and unpredictable.</li>
  <li>Evaluator lacks expertise.</li>
  <li>The evaluation would have a problem accessing clients for feedback.</li>
  <li>There is no need to justify such an evaluation to the funding agency.</li>
</ul>

<h4 id="step-4plan-the-evaluation">Step 4:Plan the Evaluation</h4>

<p>Once a general purpose for an evaluation is agreed on, a plan for conducting an evaluation follows. Background work is needed at this point if not before.For example, a literature review is often helpful in finding out more about the problem that is the focus of the evaluation team. Other reports are also important including those that provide ideas on evaluation methodologies, pertinent program and practice approaches, and, of course, other evaluations on similar topics. Next, several aspects of a research design need to be developed, including a set of study questions to explore and hypotheses to test, choosing data sources (e.g., clients, staff members), developing a specific data collection instrument, and a data analysis plan. In addition, a plan to protect human participants of the study should not be overlooked or minimized.</p>

<p>All aspects of a plan should involve discussions with the stakeholders so that there is strong support for it. When appropriate, the plan shouldI be prepared as a readable written proposal or oral presentation understandable to all stakeholders. With practice evaluations, it is important to engage the clients in understanding and participating in the evaluation plan even though this will take additional time and effort. For example, a goal attainment scale may be used in a practice evaluation to measure the clients’ progress on their outcomes. In this case, the scale should be described to the clients initially, and clients should be encouraged to help define the specific outcome measures that fit their circumstances. Goal attainment scales and the role that clients can play in developing them are described more fully in Chapter 9.</p>

<h4 id="step-5-implement-the-evaluation">Step 5: Implement the Evaluation</h4>

<p>The evaluation plan, often referred to as the evaluation design, is now ready to be implemented. Often its implementation may involve several people in an agency, such as secretaries searching for client case material, staff members who will interview clients individually or in focus groups, and a questionnaire that staff members might need to hand out to clients. In a practice evaluation, staff members are likely to implement one form or another of a single-system design. Along with implementing the data collection effort, quantitative data are coded and entered into a computer program for analysis. Qualitative data are usually prepared for analysis in narrative form.</p>

<h4 id="step-6-prepare-a-written-or-oral-report">Step 6: Prepare a Written or Oral Report</h4>

<p>Once the study has been completed, preparation of a report of the results follows. Such reports are designed to address the major questions of stakeholders, usually reflected in the initial purpose worked out in step 3. The report can be oral, written, or both. Report preparation involves several steps, including organizing, analyzing, and interpreting the findings so that they are understandable; developing conclusions and recommendations that are useful and practical; and exploring the use of visual aids, such as tables and graphs, to assist in communication. Reports of program evaluations are usually prepared for one set of stakeholders (e.g., funding agencies, administrators, boards of directors, community groups) and the reports of practice evaluations for another set (e.g., supervisors, program coordinators, clients).</p>

<h4 id="step-7-disseminate-the-findings">Step 7: Disseminate the Findings</h4>

<p>The last step of an evaluation is to disseminate the findings to stakeholders and others. Unfortunately, this step is often overlooked, minimized, or assumed to be up to those who would like to review it. The results are likely to be disseminated to several different types of stakeholders, some of which are obvious, such as the funding and regulatory agencies and the agency administration. Other stakeholders may be easily overlooked but are also important, including former and current clients and relevant community groups. A report can be communicated in many forms— including oral or written, comprehensive or brief—and in varied formats, such as a technical report, a public meeting, a staff workshop, a series of discussions, and a one-page summary for clients and their families.</p>

<h2 id="defining-and-clarifying-important-terms"><strong>DEFINING AND CLARIFYING IMPORTANT TERMS</strong></h2>

<p>Several important terms are important to define before going further. They are relevant to answering numerous basic questions like, What is a program and how is it different from services? What distinguishes programs from the practice of individual workers? What are program evaluations and practice evaluations? How are they similar and different? Finally, what are evidence-based interventions? Let’s consider the basic terms: program, program theory, practice, practice theory, services, interventions, program evaluation, practice evaluation, and evidence based interventions.</p>

<p>As mentioned earlier in the chapter, a program is a subunit of a social agency that provides clients with a set of goods and/or services with common goals.These goods and services are typically provided to a specific population of clients who either voluntarily seek them or are required to receive them. A program typically employs more than one and usually several staff members to provide goods and services.</p>

<p>Chen (2014) expands on this definition by developing the notion of program theory.Program theory is expected to encompass two important sets of documentation. First, it provides a descriptive documentation of the goals, outcomes, and interventions of the program based on the perspectives of various stakeholders. Second, program theory documents the nature of the causal relationship between the program interventions and the desired outcomes for the target group of recipients. It does this by offering research evidence that the proposed program model has been effective in helping a group of clients with a specific set of characteristics in the past. Also mentioned earlier, practice (or practice interventions) is a subunit of a program that provides the services of one worker to one client system. Practice consists of the helping processes provided by social workers and other staff that help each client reach their program goals. A social worker’s practice can be offered to an individual, a family, a small group of clients, an organization, a social policy area, or a larger community. These helping processes of practice are a major focus of practice courses in professional social work programs and draw from a broad range of practice theories, such as generalist problem-solving, cognitive behavioral, person-centered, solution-focused treatments, and social action. In-service training programs of agencies are expected to periodically provide helpful updates on such practice approaches used in the agency. Practice theory can be described like program theory. In practice, goals, outcomes, and interventions are all documented as are the causal relationship between a practice intervention and the desired outcomes for a specific client.</p>

<p><strong><em>Example of a Program and the Practice Interventions of a Home Health Agency</em></strong></p>

<p>A home health agency often sponsors one overall program, the goals of which are to help medically challenged clients remain in their own homes independently and prevent placement in a residential program such as an assisted living facility. Such a program offers several practice interventions or services to clients who are homebound, including counseling and referrals, nursing, physical therapy, and occupational therapy. These services are provided by a team of social workers, nurses, physical and occupational therapists, and others. They exist to help the program meet its goals.Home health programs also offer goods, such as medical supplies and incontinence products.</p>

<p>Distinguishing between programs and practice is important. For example, if you were to describe a program to someone unfamiliar with what you do, you would likely begin by referring to its goals and what it attempts to accomplish for clients. In contrast, practices are embedded in and largely shaped by a program as mentioned earlier in the chapter. If you begin by describing the specific goals of a practice intervention with one client, your explanation may appear incomplete and beg for an explanation of why it exists or what it intends to accomplish in general.</p>

<p>Because this book provides an emphasis on both programs and practice, the term intervention is often used to refer to either the entire program or the individual practices of each practitioner. As an example, interventions can be evident in a recovery program of a substance abuse agency as well as in the individual group practice of one staff member. In the previous editions of the book, services were also introduced as a term of importance. Services are the activities that both programs and one practitioner can offer. Services focus on the processes that help clients reach their goals. Since services do not distinguish between programs and practice interventions, think of services as a generic term that can be used interchangeably with program or practice interventions throughout the text.</p>

<p>Using working definitions of these key concepts (programs, practice, and interventions), we can define program evaluations and practice evaluations. A program evaluation is a study of a social program that uses the principles and methods of scientific research. It concerns itself with the practical needs of an organization, not theoretical issues, and it abides by a professional ethical code. The primary purposes of a program evaluation are to provide accountability to its various stakeholders and to determine how effective the program is in helping clients.</p>

<p>A practice evaluation is a study of a practitioner’s interventions with a client, which can be at several different system levels (e.g., individual, group, neighborhood). Like a program evaluation, a practice evaluation uses the principles and methods of scientific research and abides by a professional ethical code. Unlike a program evaluation, it focuses on only one practitioner’s practice at a time. One of the overall purposes of practice evaluations, like program evaluations, is to determine the effectiveness of the practice intervention in helping clients.</p>

<p>In addition, another purpose of a practice evaluation is introduced in this edition—to improve or fine-tune a practitioner’s practice interventions prior to a formal practice evaluation. For example, practice interventions may be found to work well with some clients and not others without needed modifications; in these instances, an informal practice evaluation may help identify what these modifications should be. A practice evaluation framework can also be used to help new practitioners enhance their skills in helping their clients informally.</p>

<p>Evidence-based interventions are a key concept of evaluations. Ideally, before we use an intervention to help our clients, we should find out whether there is any existing evidence that it works or is effective. This essentially requires that the intervention has been implemented before and found to be effective in helping one or more specific client groups. The more evidence available that an intervention has worked, whether it is a program or practice intervention, the more confident we can be about its potential for effectiveness when we use it.</p>

<p>Evidence can take many forms and can be used with varying degrees of confidence. The best evidence is based on evaluation studies using the common characteristics of evaluations described earlier in the chapter, especially using scientific research methods and abiding by an ethical code. Other forms of evidence are also possible to consider, including the wisdom passed on by another professional who has used the intervention. Another source could be the program and practice policies promulgated by respected professional organizations like NASW. Yet, these sources are weaker than the results of evaluations unless they had been substantiated by scientific evidence. Evidence-based interventions are discussed in more depth in the next chapter.</p>

<h3 id="what-program-evaluation-is-not">What Program Evaluation Is Not</h3>

<p>Considering what is not a program evaluation can also help us understand these key terms. Three important ways are described next.</p>

<ol>
  <li>
    <p>Program evaluations are not evaluations of individual clients. Instead, program evaluations typically aim to provide useful information about cohorts of clients. In this case, the emphasis is on the impact of the entire program on the cohort that it serves. Program evaluations usually have an informed consent protocol that clarifies that the client’s personal identity is not to be revealed in association with any of his or her specific responses. However, a program evaluation occasionally could become an evaluation of individual clients under special circumstances. In this case, the ethical thing to do would be to notify the clients as to wwhy this is occurring. This preparatory step allows clients the opportunity to withdraw from the stuidy if they wish.</p>
  </li>
  <li>
    <p>Program evaluations do not evaluate the performance of individual staff members.Although evaluations of staff effort and performance are necessary, it would be confusing and a mistake to mix the purposes of a program evaluation and an evaluation of individual staff members. Such an initiative would not only confuse the participants in a study but also would likely instill distrust in the evaluation and discourage full cooperation from staff members. It may even encourage staff participants to manipulate their response in their favor or sabotage the study by boycotting it.</p>
  </li>
  <li>
    <p>Program evaluations are not public relations projects. A public relations project could be falsely presented as a program evaluation and used to promote the agency’s programs in annual reports and other material disseminated to the public. In this case, the purpose would be misleading and dishonest, as it gives the impression that a genuine evaluation is going on. The results or portions of the results of an evaluation may be useful and appropriate to display in public relations materials that promote the agency but only after an independent evaluation is completed. Having a public relations emphasis built into an evaluation could bias the study toward a distorted positive outcome. In this case, some of the dramatic positive findings could end up being used in a report prepared for a funding agency while the neutral less dramatic findings could be disregarded and forgotten.</p>
  </li>
</ol>

<p><strong><em>Example of a Change from a Program Evaluation to Evaluation of Individual Clients</em></strong></p>

<blockquote>
  <p>The State of North Carolina was successfully sued in a federal district court for failing to provide adequate services and physical safety to a selected group of people with mental illness and mental retardation in state mental hospitals (Dudley &amp; Ahlgrim-Delzell,2002).For four years, a university sponsor of a longitudinal evaluation of these class members reported only aggregate data to a state agency, using a set of statewide indicators of client progress or success.Then the state agency’s needs shifted, and it decided to begin requesting information on individual participants in these programs. The original informed consent letter of the academic sponsor of the evaluation specified that data would be released only in aggregate form without identifying individuals. Therefore, a change in informed consent was needed. As a matter of policy, the longitudinal research team provided each class member and his or her guardian or family member with a letter informing them of the change in policy. The letter explained the purpose of the study, outlined the type of data that would be collected and how the data would be obtained and released to the state on an individual basis. This letter also provided the recipient with the opportunity to withdraw from the study at any time without repercussions. Surprisingly, no one withdrew from the study.</p>
</blockquote>

<p><strong><em>Example of a Program Evaluation withPotentially Conflicting Purposes</em></strong></p>

<blockquote>
  <p>A student was asked to conduct an evaluation of two different groups of formerly incarcerated women for a family agency. In designing the study,the student was told by her supervisor that the agency wanted to use the data in part to determine whether one staff member’s group practice was less effective than the others. After some discussion, the supervisor agreed to remove this concern, a personnel matter, as one of the agency’s study questions, so as not to confuse the study’s intent and to maximize staff cooperation.</p>
</blockquote>

<h3 id="what-practice-evaluation-is-not">What Practice Evaluation Is Not</h3>

<p>Considering what is not a practice evaluation can also help us understand these key terms. Two ways are noted next.</p>

<ol>
  <li>
    <p>Practice evaluations do not evaluate the performance of the individual staff members. They do evaluate whether a staff member’s intervention succeeded in helping clients reach their goals. As mentioned previously, evaluations of staff performance are needed, but it would be confusing to mix such evaluations with a practice evaluation. Mixing these two different types of evaluation can easily instill distrust and resistance in staff members. Furthermore, the results of evaluations are likely to be manipulated if success with a client can be translated into a favorable performance review of their work.</p>
  </li>
  <li>
    <p>Practice evaluations do not measure the effectiveness of a program. They only evaluate individual practice. Although one practitioner in a program may effectively help his or her clients based on the results of a practice evaluation, it’s not logical to conclude that the program is therefore effective.A practice evaluation does not consider other components of the program, including the practice interventions that other staff members provide.</p>
  </li>
</ol>

<p>It is also important to note that although it would be unethical to refer to a staff performance evaluation as an evaluation of a program or practice, this can unfortunately still happen. As mentioned earlier, thne politics of evaluations could lead some agencies to consider such things covertly if they rationalize that it’s okay because it is beneficial to the agency and its programs. Evaluators always need to be ready to confront any ethical dilemmas that can surface, as their obligation is to do the most ethical thing.</p>

<h2 id="summary"><strong>SUMMARY</strong></h2>

<p>Chapter 1 introduces foundational material for understanding virtually all the material in the remaining chapters. The book begins by emphasizing that both programs and practice are its focus. Evaluations are introduced as having five possible purposes in general: determining effectiveness, efficiency, quality, evidence of effort, and relevance. In addition, evaluations are expected to have seven common characteristics.They are accountability, use of scientific research methods, the logic model as an analytic tool, stakeholders and a political process, being attentive to contextual issues, an ethical code, and critical thinking. The steps in conducting an evaluation are also introduced.</p>

<p>Program and practice evaluation are viewed in the book as being equally important. Most of the time they are discussed together while occasionally they are examined separately because of important differences. In the book, the scope of evaluations is viewed broadly and can be conducted at any of three different possible stages of development: when programs and practice are being planned, during their implementation, and in an outcome stage that follows implementation. This three-stage approach is helpful in viewing all three stages as being interconnected, with the planning stage being used to identify the prospective clients, define and develop the intervention, and craft measures of the client outcomes that the intervention is intended to help them reach.</p>

<h2 id="key-terms"><strong>KEY TERMS</strong></h2>

<ul>
  <li>Accountability</li>
  <li>Logic model</li>
  <li>Scientific research Critical thinking</li>
  <li>Outcome stage</li>
  <li>methods Effectiveness</li>
  <li>Planning stage</li>
  <li>Seven Efficiency</li>
  <li>Political processes</li>
  <li>Evaluation Steps Effort</li>
  <li>Practice</li>
  <li>Stages of program Ethical codes</li>
  <li>Practice evaluation</li>
  <li>and practice Evidence-based</li>
  <li>Program</li>
  <li>development intervention</li>
  <li>Program evaluation</li>
  <li>Stakeholders Implementation stage</li>
  <li>Quality</li>
  <li>Three-Stage Approach Intervention</li>
  <li>Relevance</li>
</ul>

<h3 id="discussion-questions-and-assignments">DISCUSSION QUESTIONS AND ASSIGNMENTS</h3>

<ol>
  <li>
    <p>Prepare an agency information sheet about your field or employment agency. Answer as many of the following questions as you can to learn more about the agency.
a. What programs does your agency provide?
b.What agency policies are you aware of that help define these programs, and how do they define them?
c. What have you discovered so far to be the views, attitudes, and experiences of administrators and staff in your agency about both program and practice evaluations? If they vary, indicate what these varied views are.
d. What types of program and practice evaluations are conducted in your agency?
e. Who in your agency, if anyone, is involved and interested in evaluations? Have you been involved in any evaluation activities in this agency?
f. What aspects of programs or practice in your field agency do you think need to be evaluated? Why?
g.List the key funding and regulatory agencies, professional associations, consumer groups, and other organizations to whom you think your agency should be accountable.</p>
  </li>
  <li>
    <p>Assume that you are employed at the agency mentioned in this chapter that provides psychoeducational group services to perpetrators of domestic violence. After the study was completed, the executive director of the agency decides to use the results of the study to evaluate the performance of individual staff members who are the group leaders. What are the ethical issues that the executive director needs to consider before proceeding to do this? What would you recommend that the agency do or not do related to evaluating the performance of staff members?</p>
  </li>
  <li>
    <p>Review the factors that make up the larger context of a program in Figure 1.2. In your opinion, which factors are essential to consider related to the effective functioning of a program? Practice? Which are optional? Give reasons for your answers.</p>
  </li>
  <li>Select two different types of stakeholders of interest to you. Then identify the kinds of informational needs each of these stakeholders likely has. How are their needs different? How might this result in conflicting views about the purpose of an evaluation?</li>
  <li>Interview a staff member about an evaluation that he or she was (or currently is) conducting at your agency or read the final report of an evaluation. In what ways, if at all, do you see the seven common characteristics of evaluations (accountability, use of scientific research methods, the logic model as an analytical tool, stakeholders, and a political process, attention given to contextual issues, an ethical code, and thinking critically) evident in the staff member’s comments about the evaluation or in the final report that you review?</li>
</ol>

<h3 id="references">REFERENCES</h3>

<ul>
  <li>Bamberger,M., Rugh, J., &amp; Mabry,L.(2019). Real world evaluation:Working under budget, time,data,and political constraints (3rd ed.). Los Angeles, CA:SAGE.</li>
  <li>Chen,H. (2014).Practical program evaluation:Theory-driven evaluation and the integrated evaluation perspective (2nd ed.). Thousand Oaks, CA:SAGE.</li>
  <li>Council on Social Work Education. (2015). Educational policy and accreditation standards. Retrieved from <a href="https://www.cswe.org/getattachment/Accreditation/AccreditationProcess/2015-EPAS/2015EPAS_Web_FINAL.pdf.aspx">https://www.cswe.org/getattachment/Accreditation/AccreditationProcess/2015-EPAS/2015EPAS_Web_FINAL.pdf.aspx</a></li>
  <li>Dudley, J.R. (2011). Research methods for social work:Being producers and consumers of research (Upd.2nd ed.).Boston,MA:Pearson.</li>
  <li>Dudley,J.,&amp; Ahlgrim-Delzell,L.(2002). From lawsuit to quality improvement.In J.Dudley, M.L. Calhoun, &amp; L. Ahlgrim-Delzell(Eds.),Lessons learned from a lawsuit:Creating services for people with mental ilIness and mental retardation (pp.99-107). Kingston, NY:National Association for the Dually Diagnosed Press.</li>
  <li>Gambrill E.,&amp; Gibbs, L. (2017). CriticaI thinking for helping professionals: A skills-based workbook(4th ed.). Thousand Oaks,CA:Pine Forge Press.</li>
  <li>Linfield, K. J., &amp; Posavac, E. J. (2019). Program evaluation: Methods and case studies (9th ed.). Upper Saddle River,NJ: Prentice Hall.</li>
  <li>Martin,L.L., &amp; Kettner,P.M. (2009). Measuring performance of human service programs (2nd ed.). Thousand Oaks, CA:SAGE.</li>
  <li>Urban Ministry Center. (2017). Permanent supportive housing in Charlotte, NC. Retrieved from <a href="http://www.urbanministrycenter.org/helping-the-homeless/ways-we-help/">http://www.urbanministrycenter.org/helping-the-homeless/ways-we-help/</a> housing-for-homeless/</li>
  <li>Weissman,H., Epstein,I., &amp; Savage,A. (1983). Agency-based social work:Neglected aspects of clinical practice. Philadelphia,PA: Temple University.</li>
  <li>York,R.O. (2009). Evaluating human services: A practical approach for the human service professional.Boston,MA:Pearson.</li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">プログラム評価の理論と方法</title><link href="http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/16/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1%E3%81%AE%E7%90%86%E8%AB%96%E3%81%A8%E6%96%B9%E6%B3%95.html" rel="alternate" type="text/html" title="プログラム評価の理論と方法" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/16/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1%E3%81%AE%E7%90%86%E8%AB%96%E3%81%A8%E6%96%B9%E6%B3%95</id><content type="html" xml:base="http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/16/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1%E3%81%AE%E7%90%86%E8%AB%96%E3%81%A8%E6%96%B9%E6%B3%95.html"><![CDATA[<h2 id="メモ">メモ</h2>

<p>Rossi, P. H., Lipsey, M. W. and Freeman, H. E. 2004 Evaluation: A Systematic Approach, 7th ed., California Sage Publications（大島巌・平岡公一・森俊夫・元永拓郎監訳『プログラム評価の理論と方法――システマティックな対人サービス・政策評価の実践ガイド――』日本評論社, 2005年）.</p>

<h3 id="プログラム評価の定義">プログラム評価の定義</h3>

<p>プログラム評価とは，社会的介入プログラムの効果性をシステマティックに検討するために，プログラムを取り巻く政治的・組織的環境に適合し，かつ社会状況を改善するための社会活動に有益な知識を提供しうる方法で，社会調査法を利用することである（Rossi et al. 2004: 15）。</p>

<h3 id="社会調査法">社会調査法</h3>

<p>社会調査法は，そしてその方法論的質の標準は，長年にわたり，しっかりと事実に即して社会現象を記述するという明確な目的のもとで発展し，改良されてきた。とくに，体系的な観察，測定，標本抽出，調査設計，データ解析といった現代社会科学の諸技法は，妥当性と信頼性を備え，かつ正確な社会行動の記述を生み出すための手続きとして高度に発展したものである。そのため社会調査法は，可能な限り信頼できる正当な方法でプログラム実績を記述するという課題に対し，とりわけ適切なアプローチとなる（Rossi et al. 2004: 16）。</p>

<h3 id="社会プログラム">社会プログラム</h3>

<p>社会プログラムは，その主たる存在理由が「善いことをする」こと，すなわち社会問題を改善し，社会状況を向上させるための活動である（Rossi et al. 2004: 17）。</p>

<h3 id="評価者ー利害関係者">評価者ー利害関係者</h3>

<ul>
  <li>政策立案者と意思決定者：プログラムを開始するか，続けるか，中止するか，拡大するか，再編するか，短縮するかを決定する責任者。</li>
  <li>プログラムスポンサー：プログラムを開始し，プログラムの資金を提供する組織。彼らはまた，政策立案者や意思決定者と重複することもある。</li>
  <li>評価スポンサー：評価を開始し，評価の資金を提供する組織（ときにプログラムスポンサーと評価スポンサーが同じであることがある）。</li>
  <li>標的となる参加者：評価される介入やサービスを受ける個人や世帯，その他の単位。</li>
  <li>プログラム運営者：介入プログラムの監督，運営の責任者。</li>
  <li>プログラムスタッフ：プログラムサービスの提供を担う職員，あるいはサポートの役割を担う職員。</li>
  <li>プログラムの競合者：利用可能な資源について，そのプログラムと競合する組織や集団。</li>
  <li>社会文脈上の利害関係者：プログラムの近接環境にあり，そのプログラムがなにをしており，プログラムになにがおこっているのかについて関心をもっている組織や集団，個人（プログラムの行われている管轄地域内にある他の機関やプログラム，公務員，市民団体など）。</li>
  <li>評価と研究の学界：評価の技術的な質や信頼性を評価・査定する評価専門家，およびプログラムの関連領域で働く研究者。</li>
</ul>

<h3 id="独立評価">独立評価</h3>

<p>独立評価（independent evaluation）においては，評価者は，評価計画を立て，評価を実施し，結果を伝えることにおいて主たる責任を負う。社会科学者がその内訳を自身の裁量に委ねられている研究費を用いて，知識生成を目的とした評価を行う場合のように，評価者が，かなり自律的に評価を開始し指揮することもあるだろう。より一般的なかたちは，スポンサー機関が独立評価者に評価の委託をする際に，その目的と性質は規定するものの，評価計画の詳細や評価の実施は評価者に委ねるという形である。しかしそのような場合でも，評価者は評価を形成するなかでなんらかの影響をある範囲の利害関係者たちに与えるために，彼らと協議するのが一般的である（Rossi et al. 2004: 50）。</p>

<h3 id="参加型協働型評価">参加型・協働型評価</h3>

<p>参加型・協働型評価（participatory or collaborative evaluation）は，評価者およびひとつ以上の利害関係者集団の代表者がチームをつくり，チームプロジェクトとして組織される（Greene 1988; Mark et al. 1985）。参加する利害関係者は，評価の計画，実行，分析に直接的に関与し，評価者は，チームリーダーやコンサルタントから，必要なときにだけ呼ばれる人，というまでの幅広い役割を担いつつ，協働的作業していく。参加型評価でとりわけよく知られている形態のひとつに，Patton（1986, 1997）の利用焦点型評価がある。Pattonのアプローチは，評価知見を用いることになる人たちとの密接な協働関係を強調している。それは，評価がその使用者の必要性に応えるものであり，使用者が利用可能で，また実際に利用すると思われる情報を作り出すことを保証するからである（Rossi et al. 2004: 50）。</p>

<h3 id="エンパワーメント評価">エンパワーメント評価</h3>

<p>評価者ー利害関係者関係における利害関係者の主導権，権利擁護，自己決定を強調する視点を発展させてきた評価者たちがいる（Fetterman et al. 1996）。エンパワーメント評価においては，評価者ー利害関係者関係は参加型かつ協働型である。それに加えて，評価者の役割にはコンサルタントやファシリテーターの役割も含まれ，評価者は参加する利害関係者が自身で評価を行える力，権利擁護や変革のために評価結果を効果的に使える力，彼らの生活に影響を及ぼすプログラムに対して何らかのコントロール感をもつという体験的なものを開発していくことになる。それゆえ評価過程は，参考になり有用な知見を生み出すことだけではなく，参加者の自己開発と政治的影響力を高めることも指向する。これらのテーマが示しているように，エンパワーメント評価は，評価に参加しなけれプログラムという文脈のなかでほとんど力をもつことはない利害関係者，通常それはプログラムの受け手や受益者と見なされている人たちであるが，それらの人たちを含むことが最も適切な形である（Rossi et al. 2004: 50-51）。</p>

<h2 id="キーコンセプト">キー・コンセプト</h2>

<h3 id="社会調査法social-research-methods">社会調査法（Social research methods）</h3>

<p>社会的行動を研究するために社会科学者によって考案された手続きのことであり、体系的な観察と、それら観察と推論の論理方式を基礎とする（Rossi et al. 2004: 29）。</p>

<h3 id="社会プログラム社会的介入social-programsocial-intervention">社会プログラム；社会的介入（Social program；Social intervention）</h3>

<p>社会問題を緩和する、あるいは社会状況を改善するためにデザインされた組織的、計画的、そして通常は現在継続中の取り組みのこと（Rossi et al. 2004: 29）。</p>

<h3 id="評価スポンサーevaluation-sponsor">評価スポンサー（Evaluation sponsor）</h3>

<p>評価を依頼もしくは要求し、それを実施するのに必要な資源を提供する個人、集団、もしくは組織（Rossi et al. 2004: 29）。</p>

<h3 id="評価の利用utilization-of-evaluation">評価の利用（Utilization of evaluation）</h3>

<p>意思決定者や他の利害関係者が評価の概念や知見を利用すること。それは日々のマネジメントレベルのこともあれば、より大きな資金提供や政策レベルのこともある（Rossi et al. 2004: 29）。</p>

<h3 id="プログラム評価program-evaluation">プログラム評価（Program evaluation）</h3>

<p>社会的介入プログラムの効果性をシステマティックに検討するために、プログラムを取り巻く政治的·組織的環境に適合し、かつ社会状況を改善するための社会活動に有益な知識を提供しうる方法で、社会調査法を利用すること（Rossi et al. 2004: 29）。</p>

<h3 id="利害関係者stakeholders">利害関係者（Stakeholders）</h3>

<p>あるプログラムがどの程度機能しているかに対して重大な関心をもっている個人、集団、または組織のこと。たとえばプログラムに関して意思決定の権限を有する者、助成者やスポンサー、管理者や職員、利用者または意図されている受益者など（Rossi et al. 2004: 29）。</p>

<h3 id="インパクトアセスメントimpact-assessment">インパクトアセスメント(Impact assessment)</h3>

<p>プログラムアウトカムや、あるプログラムが改善を意図する社会状況への影響に関するクエスチョンに対して回答を与える評価研究のひとつ。インパクト評価（impact evaluation）またはアウトカム評価（outcome evaluation）としても知られている（Rossi et al. 2004: 61）。</p>

<h3 id="エンパワーメント評価empowerment-evaluation">エンパワーメント評価（Empowerment evaluation）</h3>

<p>参加する利害関係者が自身で評価を行い、権利擁護や変革のために評価結果を効果的に使い、彼らの生活に影響を及ばすプログラムに対してなんらかの影響を及ぼすために、評価者の役割のなかに、コンサルタントやファシリテーターの役割を含んでいる、参加型あるいは協働型のプログラム評価のひとつ（Rossi et al. 2004: 61）。</p>

<h3 id="形成的評価formative-evaluation">形成的評価（Formative evaluation）</h3>

<p>プログラムの改善を導くための情報提供を意図した評価活動（Rossi et al. 2004: 61）。</p>

<h3 id="効率アセスメントefficiency-assessment">効率アセスメント（Efficiency assessment）</h3>

<p>プログラムが取り組む社会条件にもたらされる変化の観点から、プログラム費用を、プログラムの便益や効果の金銭的価値と対比するクエスチョンに解答を与える評価研究のひとつ。</p>

<h3 id="参加型協働型評価participatory-or-collaborative-evaluation">参加型·協働型評価（Participatory or collaborative evaluation）</h3>

<p>評価計画を立て、評価を実施し、その結果を普及し使用することにおいて、評価者とひとつ以上の利害関係者グループが協働して作業するチームプロジェクトを組織して行うブログラム評価のひとつ（Rossi et al. 2004: 61-62）。</p>

<h3 id="総括的評価summative-evaluation">総括的評価（Summative evaluation）</h3>

<p>プログラム実績のある重要な側面に対する総括的な判断をするために行う評価活動、たとえば特別なゴールや目標が満たされているかどうかを判断することなどがある（Rossi et al. 2004: 62）。</p>

<h3 id="独立評価independent-evaluation">独立評価（Independent evaluation）</h3>

<p>評価者が、評価計画を立て、評価を実施し、その結果を普及することにおいて、主たる責任を負うブログラム評価のひとつ（Rossi et al. 2004: 62）。</p>

<h3 id="ニーズアセスメントneeds-assessment">ニーズアセスメント(Needs assessment)</h3>

<p>プログラムが改善しようとしている社会状況、およびそのプログラムに対するニーズに関するクエスチョンに対して回答を与える評価研究のひとつ（Rossi et al. 2004: 62）。</p>

<h3 id="評価クエスチョンevaluation-questions">評価クエスチョン（Evaluation questions）</h3>

<p>評価者や評価スポンサー、その他の利害関係者によって作成された一連のクエスチョンである。そのクエスチョンは、評価が調査することになる課題を明らかにしており、かつ、利害関係者に役立つやり方で、評価者が用いることのできる方法を使用しながら、回答可能な言業で述べられている（Rossi et al. 2004: 62）。</p>

<h3 id="費用効果分析cost-effectiveness-analysis">費用効果分析（Cost-effectiveness analysis）</h3>

<p>プログラム効率を決定する分析手続きであり、ある介入のアウトカムをそのプログラム費用との関係から得るもの（Rossi et al. 2004: 62）。</p>

<h3 id="標的集団target">標的集団（Target）</h3>

<p>プログラムの介入が対象とする、個人、家族、地域などのユニット。プログラムによってサービスを提供される地域内にあるこれらすべてのユニットは、その標的集団を構成している（Rossi et al. 2004: 62）。</p>

<h3 id="費用便益分析cost-benefit-analysis">費用便益分析（Cost-benefit analysis）</h3>

<p>費用とアウトカムとの関係を、通常の金銭的用語で評価して表現された、プログラムの経済的効率性を決定する分析手続き（Rossi et al. 2004: 62）。</p>

<h3 id="プログラムプロセスのアセスメントassessment-of-program-process">プログラムプロセスのアセスメント(Assessment of program process)</h3>

<p>プログラムの運営、実施、サービス提供に関するクエスチョンに回答を与える評価研究のひとつ（an evaluation study）。プロセス評価あるいは実施評価とも呼ばれている（Rossi et al. 2004: 62）。</p>

<h3 id="プログラムモニタリングprogram-monitoring">プログラムモニタリング(Program monitoring)</h3>

<p>プログラムが意図されたように、あるいは、ある適切な基準に従って機能しているかどうかを示す、プログラム遂行面の体系的な文書の収集。モニタリングは、通常、プログラムプロセスやプログラムアウトカムのどちらか、あるいは両方にかかわるプログラム遂行を含んでいる（Rossi et al. 2004: 62）。</p>

<h3 id="プログラム理論program-theory">プログラム理論（Program theory）</h3>

<p>プログラムが生み出すことが期待されている社会的便益や、プログラムがそのゴールや目標を達成するために採用する戦略や戦術に関連する様式に関する一連の仮説群。プログラム理論のなかでは、プログラム活動によってもたらされる社会状況変化の性質に関連したインバクト理論（impact theory）と、プログラムの組織計画とサービス利用計画を示すプロセス理論（process theory）を区別することができる（Rossi et al. 2004: 63）。</p>

<h3 id="プログラム理論のアセスメントassessment-of-program-theory">プログラム理論のアセスメント（Assessment of program theory）</h3>

<p>プログラムの概念化や設計に関するクエスチョンに回答を与える評価研究のひとつ（Rossi et al. 2004: 63）。</p>

<h3 id="プロセス評価process-evaluation">プロセス評価（Process evaluation）</h3>

<p>標的集団のサービス受け手に、意図されたようにサービスが届いているかどうかを判断するよう設計されたプログラムモニタリングのひとつ（Rossi et al. 2004: 63）。</p>

<h3 id="キャッチメントエリアcatchment-area">キャッチメントエリア(Catchment area)</h3>

<p>あるプログラムによってサービスされる地理的範囲（Rossi et al. 2004: 93）。</p>

<h3 id="実績基準performance-criterion">実績基準（Performance criterion）</h3>

<p>それと対照させて評価ができるように設定された、あるプログラム実績次元における標準（Rossi et al. 2004: 93）。</p>

<h3 id="プログラムゴールprogram-goal">プログラムゴール(Program goal)</h3>

<p>通常、一般的で抽象的な、プログラムが指向する望ましい状態についての叙述。プログラム目標と比較せよ（Rossi et al. 2004: 93）。</p>

<h3 id="プログラム目標program-objectives">プログラム目標（Program objectives）</h3>

<p>プログラムがその達成を望まれていることを詳述する特定的叙述で、ひとつ以上の測定可能な成功基準を伴う（Rossi et al. 2004: 93）。</p>

<h3 id="理論上の失敗theory-failure">理論上の失敗（Theory failure）</h3>

<p>計画どおりに実施されているのにそのサービスが、期待する参加者、または意図する最終的な社会的便益、またはその両方に対して、直接の効果をもたらしていないプログラムのこと（Rossi et al. 2004: 94）。</p>

<h3 id="キーインフォーマントkey-informants">キーインフォーマント(Key informants)</h3>

<p>その個人的または職業的地位によって、社会問題や標的集団の性質や範囲について見識をもっている人たちのことで、彼らの見解はニーズアセスメントのなかで得られる（Rossi et al. 2004: 123）。</p>

<h3 id="社会指標social-indicator">社会指標（Social indicator）</h3>

<p>社会状況の経過を追跡するようデザインされた定期的測定のこと。スノーポールサンプリング(Snowball sampling)
非確率的サンプリング法のひとつで、面接対象者それぞれに、面接するとよい他の有識者を紹介してもらう方法のこと。これは新たな名前が挙がらなくなるまで続けられる（Rossi et al. 2004: 123）。</p>

<h3 id="ニーズのある集団population-in-need">ニーズのある集団（Population in need）</h3>

<p>ある特定の問題となる状態を現在呈している個人、またはある特定範囲における構成単位。発生数（Incidence）
ある一定期間内にある特定範囲で新規に発生したある特定の問題や状況の数のこと。有症数と比較すること（Rossi et al. 2004: 123）。</p>

<h3 id="標本調査sample-survey">標本調査（Sample survey）</h3>

<p>集団の標本群に対して行われた調査のこと。その結果から統計学的に関連母集団における値が推定される（Rossi et al. 2004: 123）。</p>

<h3 id="フォーカスグループfocus-group">フォーカスグループ(Focus group)</h3>

<p>ファシリテーターの支援のもとである話題について議論するために、その話題に関して知識をもつ人を選んで召集した小集団バネルのこと。そこでの議論は、重要なテーマを同定したり、焦点となる話題についての見解やその経験の要約的記述を作成するために用いられる（Rossi et al. 2004: 123）。</p>

<h3 id="有症数prevalence">有症数（Prevalence）</h3>

<p>ある特定範囲において特定時点に存在するある特定状態の事例の総数。発生数と比較すること（Rossi et al. 2004: 123）。</p>

<h3 id="リスク集団population-at-risk">リスク集団（Population at risk）</h3>

<p>ある特定の状態である、またはそうなる可能性がきわめて強いことを示す特性をもつ個人、またはある特定範囲における構成単位（Rossi et al. 2004: 123）。</p>

<h3 id="率rate">率（Rate）</h3>

<p>ある特定状態の発生や存在を関連集団人口内での割合で表わしたもの（たとえば、成人1000人あたりの死者数）（Rossi et al. 2004: 123）。</p>

<h3 id="インパクト理論impact-theory">インパクト理論（Impact theory）</h3>

<p>あるプログラム活動が引き金となる原因で、結果としてある社会的利益が得られるような因果連鎖を記述した因果理論（Rossi et al. 2004: 158）。</p>

<h3 id="サービス利用計画service-utilization-plan">サービス利用計画（Service utilization plan）</h3>

<p>標的集団がどのように最初にプログラムに接触するか、また、それらの人たちが、予定されているサービスが完了するまでどのくらいプログラムにかかわるかについての仮定と期待。サービス利用計画の最も単純なかたちでは、未来のクライエントが未来のサービスと相互作用する一連の出来事が記述される（Rossi et al. 2004: 158）。</p>

<h3 id="潜在的プログラム理論implicit-program-theory">潜在的プログラム理論（Implicit program theory）</h3>

<p>プログラムのサービスと実践のなかに内在しているが、完全には明確化されておらず記録もされていない仮定と期待（Rossi et al. 2004: 158）。</p>

<h3 id="組織計画organizational-plan">組織計画（Organizational plan）</h3>

<p>社会的状況に目指す変化を生み出すプログラムー標的集団間の交流をもたらすために、プログラムがなにをしなければならないかについての仮定と期待。プログラムの組織計画はプログラムマネジメントの観点から明確化される。またここには、プログラムが実施しようとしている機能と活動、および実践に必要な人的、財政的、物理的資源とが、両方含まれる（Rossi et al. 2004: 158）。</p>

<h3 id="評価可能性アセスメント-evaluability-assessment">評価可能性アセスメント （Evaluability assessment）</h3>

<p>プログラムが評価に必要な前提条件を満たしているかどうかを確認し、満たしている場合には評価をどのようにデザインすれば最も有用性が高まるかを確認する話し合いと調査。評価者、評価スポンサー、場合によってはその他の利害関係者が一緒に実施する（Rossi et al. 2004: 158）。</p>

<h3 id="プラックボックス評価black-box-evaluation">プラックボックス評価（Black box evaluation）</h3>

<p>アウトカムをもたらすのはなにか、またそれはなぜかについての見通しを与えてくれる明確なプログラム理論がないままに行われる、プログラムアウトカムの評価（Rossi et al. 2004: 158）。</p>

<h3 id="プロセス理論process-theory">プロセス理論（Process theory）</h3>

<p>プログラムの組織計画とサービス利用計画とを組み合わせて、プログラムをどのように運営するかという仮定と期待を全体的に記述したもの（Rossi et al. 2004: 158）。</p>

<h3 id="明示的プログラム理論articulated-program-theory">明示的プログラム理論（Articulated program theory）</h3>

<p>明確に記述されているタイプのプログラム理論である。プログラム文書やプログラム証明の一部として、あるいは評価者と利害関係者が理論形成に向けて努力した結果として、詳細に明記されている（Rossi et al. 2004: 158）。</p>

<h3 id="アウトカムモニタリングoutcome-monitoring">アウトカムモニタリング(Outcome monitoring)</h3>

<p>プログラムがその改善に対し説明責任をもつなんらかの社会状況のあり方を表す指標に関する、継続的な測定と報告（Rossi et al. 2004: 188）。</p>

<h3 id="カバレッジcoverage">カバレッジ(Coverage)</h3>

<p>プログラムがその意図する標的集団に届いている程度（Rossi et al. 2004: 188）。</p>

<h3 id="管理的標準administrative-standards">管理的標準（Administrative standards）</h3>

<p>プログラム管理者や他の責任団体によって設定された達成目標レベルで、たとえば、紹介された人の90％を1ヶ月以内に受け入れることなど。こうしたレベルは、これまでの経験や類似プログラムでの実績，あるいは専門的判断を基にして設定されるだろう（Rossi et al. 2004: 188）。</p>

<h3 id="経営情報システムmanagement-information-system-mis">経営情報システム（Management information system: MIS）</h3>

<p>データシステムのことで、通常コンピュータ化され、利用者へのサービス提供に関する情報、およびしばしば広告、費用、診断および人口統計学的情報、アウトカム状態に関する情報を日常的に収集、報告する（Rossi et al. 2004: 188）。</p>

<h3 id="接近性アクセシビリティaccessibility">接近性（アクセシビリティ）（Accessibility）</h3>

<p>プログラムの構造的および組織的配置がプログラムへの参加を促進する程度。説明責任（Accountability）
プログラムスタッフにかかる責任で、利害関係者やスポンサーに対して、そのプログラムが効果的であり、カバレッジ、サービス、法的および財務的要請事項に合致していることを示すエビデンスを提供すること（Rossi et al. 2004: 189）。</p>

<h3 id="バイアスbias">バイアス(Bias)</h3>

<p>プログラムカバレッジに対して用いられる場合、標的集団のあるサブグループに対しプログラムが不均等に届けられている程度（Rossi et al. 2004: 189）。</p>

<h3 id="プログラムプロセスモニタリングprogram-process-monitoring">プログラムプロセス·モニタリング(Program process monitoring)</h3>

<p>時を経て繰り返し行われるプロセス評価（Rossi et al. 2004: 189）。</p>

<h3 id="アウトカムoutcome">アウトカム(Outcome)</h3>

<p>プログラムによって変化が期待されている標的集団あるいは社会状況の状態（Rossi et al. 2004: 217）。</p>

<h3 id="アウトカム変化outcome-change">アウトカム変化（Outcome change）</h3>

<p>時間的に異なる時点におけるアウトカムレベルの差。アウトカムレベルを参照（Rossi et al. 2004: 217）。</p>

<h3 id="アウトカムレベルoutcome-level">アウトカムレベル(Outcome level)</h3>

<p>ある時点におけるアウトカムの状態。アウトカムを参照（Rossi et al. 2004: 217）。</p>

<h3 id="インパクトimpact">インパクト(Impact)</h3>

<p>プログラム効果参照（Rossi et al. 2004: 217）。</p>

<h3 id="感度sensitivity">感度（Sensitivity）</h3>

<p>測定されている事象に変化や差異があるとき、測定尺度の値が変化する程度（Rossi et al. 2004: 217）。</p>

<h3 id="信頼性reliability">信頼性（Reliability）</h3>

<p>同じ事象を繰り返し測定する際に、ある尺度が同じ結果を生み出す程度（Rossi et al. 2004: 217）。</p>

<h3 id="妥当性validity">妥当性（Validity）</h3>

<p>測定尺度が、測定しようと意図したものを実際に測定している程度（Rossi et al. 2004: 217）。</p>

<h3 id="プログラム効果program-effect">プログラム効果（Program effect）</h3>

<p>プログラムが独自に寄与する、すなわち他の原因が制御されたり除外された影響に関するアウトカム変化の部分。プログラムのインパクトとも呼ばれる。アウトカム変化を参照（Rossi et al. 2004: 217）。</p>

<h3 id="介入群intervention-group">介入群（Intervention group）</h3>

<p>介入を受ける標的集団のことで、アウトカム指標について、ひとつあるいは複数の対照群と比較される。対照群を参照（Rossi et al. 2004: 244）。</p>

<h3 id="準実験法quasi-experiment">準実験法（Quasi-experiment）</h3>

<p>無作為割り付け以外の方法で介入群と対照群が形成されるインパクト研究デザイン（Rossi et al. 2004: 244）。</p>

<h3 id="対照群control-group">対照群（Control group）</h3>

<p>プログラム介入を受けない標的集団のことで、アウトカム指標について、介入を受けたひとつあるいは複数の集団と比較される。介入群を参照（Rossi et al. 2004: 244）。</p>

<h3 id="分析単位units-of-analysis">分析単位（Units of analysis）</h3>

<p>インパクトアセスメントにおいて、アウトカム指標が測定される単位のことで、すなわち分析データが得られる単位のことを指す。分析の単位は、個人だけでなく、家族、近隣地域、地域、組織、行政区、地理的区域、その他の団体であることもある（Rossi et al. 2004: 244）。</p>

<h3 id="無作為化randomization">無作為化（Randomization）</h3>

<p>標的集団を確率的に、介入群と対照群に割り付ける方法で、すべての対象者は、等しい確率をもって、どちらかの群に割り付けられる（Rossi et al. 2004: 245）。</p>

<h3 id="無作為化フィールド実験法randomized-field-experiment">無作為化フィールド実験法（Randomized field experiment）</h3>

<p>プログラム設定において実施される研究デザインで、無作為割り付けによって、介入群と対照群を形成し、そのアウトカム指標を比較して、介入効果を検討する。対照群と介入群を参照（Rossi et al. 2004: 245）。</p>

<h3 id="回帰不連続デザイン-regressiondiscontinuity-design">回帰—不連続デザイン （Regression—discontinuity design）</h3>

<p>準実験的デザインのうち、適切な量的尺度の観察値に基づいて介入群と対照群とが選択される、つまり標的集団を得点により、その尺度のカッティングポイントと目された得点より高い人を片方に、低い人を他方に割り付ける方法。カッティングポイント·デザインとも呼ばれる（Rossi et al. 2004: 277）。</p>

<h3 id="再帰的コントロール-reflexive-controls">再帰的コントロール （Reflexive controls）</h3>

<p>介入の前に参加する標的集団にアウトカム変数を測定し、コントロールの観察として用いること。前後比較デザイン、時系列デザインも参照のこと（Rossi et al. 2004: 277）。</p>

<h3 id="時系列デザインtime-series-design">時系列デザイン（Time-series design）</h3>

<p>介入の前と後にアウトカム変数について繰り返し数多くなされる測定に依存する再帰的コントロールデザイン（Rossi et al. 2004: 278）。</p>

<h3 id="前後比較デザインpre-post-design">前後比較デザイン（Pre-post design）</h3>

<p>ひとつの尺度が介入の前後に行われる再帰的コントロールデザイン（Rossi et al. 2004: 278）。</p>

<h3 id="選択バイアスselection-bias">選択バイアス（Selection bias）</h3>

<p>プログラム効果の体系的な過小あるいは過大評価であり、それは介入プログラムを受けていなくてもアウトカムに差異を生じさせるような、介入群と対照群間のコントロールされていない差異に起因する（Rossi et al. 2004: 278）。</p>

<h3 id="選択モデリングselection-modeling">選択モデリング（Selection modeling）</h3>

<p>不等価比較デザインでの介入群と対照群への選択の可能性を「予測する」多変量解析モデル。この分析の結果は、選択バイアスのコントロール変数を構成するために用いられ、アウトカムに対する介入効果を検討する第2段階の統計学的モデルに組み込まれる（Rossi et al. 2004: 278）。</p>

<h3 id="対象者の欠損attrition">対象者の欠損（Attrition）</h3>

<p>対照群または介入群に割り付けられた標的集団におけるアウトカムデータ測定の欠損であり、たいていは標的の所在がわからなかったり、データに貢献することを拒否されることで生じる（Rossi et al. 2004: 278）。</p>

<h3 id="統計学的コントロールstatistical-controls">統計学的コントロール（Statistical controls）</h3>

<p>統計学的手法を用いて介入群と対照群との間に存在するアウトカムに関連しうる差異に起因するバイアスに関して、プログラム効果の推定値を補正すること。これらの手法を用いてコントロールされる差異は、統計学的分析に含めることができる測定変数で表現されなくてはならない（Rossi et al. 2004: 278）。</p>

<h3 id="不等価比較デザインnonequivalent-comparison-design">不等価比較デザイン（Nonequivalent comparison design）</h3>

<p>介入群と対照群とが無作為化割り付け法以外の手段を通じて構成された準実験的デザイン（Rossi et al. 2004: 278）。</p>

<h3 id="マッチングmatching">マッチング(Matching)</h3>

<p>対照群を標的集団から選択し（個別的にまたは集合として）、介入を受けることを別にすれば介入群の人と特定の特性が同一であるように構成すること（Rossi et al. 2004: 278）。</p>

<h3 id="エフェクトサイズ統計effect-size-statistic">エフェクトサイズ統計（Effect size statistic）</h3>

<p>標準化された形式でプログラム効果を表現する統計学的公式。異なる単位や尺度を用いたアウトカム尺度間で比較可能になる。最もよく使用されるエフェクトサイズ統計は、標準化平均差とオッズ比である（Rossi et al. 2004: 303）。</p>

<h3 id="オッズ比odds-ratio">オッズ比（Odds ratio）</h3>

<p>エフェクトサイズ統計であり、介入群のよいアウトカムのオッズを対照群のオッズとの比で示す（Rossi et al. 2004: 303）。</p>

<h3 id="第i種の過誤type-i-error">第I種の過誤（Type I error）</h3>

<p>統計学的な結論の誤りのうち、実際には標的集団に効果がないのに、プログラム効果が統計学的に有意である場合（Rossi et al. 2004: 304）。</p>

<h3 id="第ii種の過誤type-ii-error">第II種の過誤（Type II error）</h3>

<p>統計学的な結論の誤りのうち、実際には標的集団に効果があるのに、プログラム効果が統計学的に有意でない場合（Rossi et al. 2004: 304）。</p>

<h3 id="調整変数moderator-variable">調整変数（Moderator variable）</h3>

<p>インバクトアセスメントでは、性別や年齢などのサブグループを特徴づける調整変数によって、プログラム効果が異なることがある（Rossi et al. 2004: 304）。</p>

<h3 id="統計的検出力statistical-power">統計的検出力（Statistical power）</h3>

<p>実際にプログラムに効果があるときに、観測されたプログラム効果が統計学的に有意となる確率。もし実際にある効果が統計学的に有意でないとされた場合、第II種の過誤が生じる。つまり、検出力は1引く第II種の過誤の確率である。第II種の過誤参照（Rossi et al. 2004: 304）。</p>

<h3 id="媒介変数mediator-variable">媒介変数（Mediator variable）</h3>

<p>インパクトアセスメントでは、ブログラムへの曝露の結果変化する近位アウトカムと、それによって影響される遠位アウトカムがある。媒介変数は、プログラムが遠位アウトカムに変化を及ぼす因果連関に介在する変数である（Rossi et al. 2004: 304）。</p>

<h3 id="標準化平均差standardized-mean-difference">標準化平均差（Standardized mean difference）</h3>

<p>エフェクトサイズ統計であり、介入群と対照群のアウトカムの平均の差を標準偏差の単位で示す（Rossi et al. 2004: 304）。</p>

<h3 id="メタ分析meta-analysis">メタ分析（Meta-analysis）</h3>

<p>同じまたは類似した介入についての複数の研究の多くの結果から引き出されるエフェクトサイズ統計の分析。一連の研究の知見を要約したり比較したりすることを目的に行われる（Rossi et al. 2004: 304）。</p>

<h3 id="会計学的観点accounting-perspectives">会計学的観点（Accounting perspectives）</h3>

<p>効率性分析において、費用や便益にどの種類の財·サービスを含めるかを決定する背景にある観点（Rossi et al. 2004: 337）。</p>

<h3 id="機会費用opportunity-costs">機会費用（Opportunity costs）</h3>

<p>プログラムの実施によって、見合わせることになった機会の価値（Rossi et al. 2004: 337）。</p>

<h3 id="事後的効率性分析ex-post-efficiency-analysis">事後的効率性分析（Ex post efficiency analysis）</h3>

<p>プログラムのアウトカムが判明した後に実施される効率性分析（費用便益分析や費用効果分析）（Rossi et al. 2004: 337）。</p>

<h3 id="事前効率性分析ex-ante-efficiency-analysis">事前効率性分析（Ex ante efficiency analysis）</h3>

<p>プログラムの実施に先立って実施される効率性分析（費用便益分析や費用効果分析）。通常、プログラムの計画の一部として、費用との関連におけるネットのアウトカムを推定するために実施される（Rossi et al. 2004: 337）。</p>

<h3 id="純便益net-benefits">純便益（Net benefits）</h3>

<p>割引済み総便益から割引済み総費用を差し引いた値。純収益（準）とも呼ばれる（Rossi et al. 2004: 337）。</p>

<h3 id="潜在価格shadow-prices">潜在価格（Shadow prices）</h3>

<p>市場において正確に評価することができない財·サービスの帰属費用あるいは推定費用。潜在価格は、規制や外部効果のために市場価格が適切でない場合にも用いられる。計算価格としても知られている（Rossi et al. 2004: 337-338）。</p>

<h3 id="内部収益率internal-rate-of-return">内部収益率（Internal rate of return）</h3>

<p>プログラムの割引済み総便益が割引済み総費用に等しくなるように算出される割引率の値（Rossi et al. 2004: 338）。</p>

<h3 id="二次的効果secondary-effects">二次的効果（Secondary effects）</h3>

<p>対象外の個人やグループに費用負担を課してしまうブログラムの効果（Rossi et al. 2004: 338）。</p>

<h3 id="費用コストcosts">費用（コスト）（Costs）</h3>

<p>プログラムを実施するために要する直接的および間接的なインプット（Rossi et al. 2004: 338）。</p>

<h3 id="分配効果distributional-effects">分配効果（Distributional effects）</h3>

<p>一般住民の間で資源の再分配をもたらすプログラムの効果（Rossi et al. 2004: 338）。</p>

<h3 id="便益benefits">便益（Benefits）</h3>

<p>プログラムの正のアウトカム。通常、費用便益分析において貨幣尺度に換算されるか、費用効果分析において費用と比較される。便益は直接的および間接的なアウトカムの双方を包含する（Rossi et al. 2004: 338）。</p>

<h3 id="割引discounting">割引（Discounting）</h3>

<p>効率性分析におけるブログラムの費用と便益を評価する際の時間の取扱い、すなわち、費用と便益を現在価値化するための調整方法。割引率と評価対象期間の選択を要する（Rossi et al. 2004: 338）。</p>

<h3 id="概念的利用conceptual-utilization">概念的利用（Conceptual utilization）</h3>

<p>知識や評価結果の長期的で間接的な利用（Rossi et al. 2004: 383）。</p>

<h3 id="政策空間policy-space">政策空間（Policy space）</h3>

<p>政策立案者が一時に容認することができる範囲内の一連の政策代替案（Rossi et al. 2004: 383）。</p>

<h3 id="政策上の意義policy-significance">政策上の意義（Policy significance）</h3>

<p>政策やプログラムの発展における評価結果の意義（統計的有意性に対して）（Rossi et al. 2004: 383）。</p>

<h3 id="第一次普及primary-dissemination">第一次普及（Primary dissemination）</h3>

<p>スポンサーや専門的な関係者のための詳細な評価結果の普及（Rossi et al. 2004: 383）。</p>

<h3 id="第二次普及secondary-dissemination">第二次普及（Secondary dissemination）</h3>

<p>利害関係者により構成された関係者のために、要約された多くの場合は簡略化された評価結果の普及（Rossi et al. 2004: 383）。</p>

<h3 id="直接的手段的利用directinstrumentalutilization">直接的（手段的）利用（Direct（instrumental）utilization）</h3>

<p>意思決定者や利害関係者による特定の知識や評価結果の明確な利用（Rossi et al. 2004: 383）。</p>]]></content><author><name></name></author><category term="プログラム評価" /><category term="理論と方法" /><summary type="html"><![CDATA[メモ]]></summary></entry><entry><title type="html">プログラム評価ハンドブック</title><link href="http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/16/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF.html" rel="alternate" type="text/html" title="プログラム評価ハンドブック" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/16/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF</id><content type="html" xml:base="http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/16/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1%E3%83%8F%E3%83%B3%E3%83%89%E3%83%96%E3%83%83%E3%82%AF.html"><![CDATA[<h2 id="プログラム評価とは">プログラム評価とは</h2>

<p>プログラムの評価対象は，社会課題解決をめざす社会的目的を達成するための社会的介入である。</p>

<h3 id="プログラム評価の定義">プログラム評価の定義</h3>

<p>プログラム評価とは，社会調査手法を活用し，社会的介入プログラムの有効性を体系的に調査するものである。その評価は，プログラムを取り巻く政策的・組織的な文脈を考慮して行われるもので，社会状況を改善するための社会的活動の情報源となるものである（Rossi et al. 2004: 29）。</p>

<h3 id="プログラム評価の２つの目的">プログラム評価の２つの目的</h3>

<p>プログラムの改善とアカウンタビリティの確保</p>

<h3 id="プログラム評価の２つのアプローチ">プログラム評価の２つのアプローチ</h3>

<p>形成的評価は，評価対象の設計・開発段階や継続的な改善・形成の途中に行うもので，プログラムの改善に役立てるものである。一方，総括的評価はプログラムの介入後に行うもので，成果や効率的な資源の活用がなされたのかが評価の中心となり，アカウンタビリティの確保を目的とした評価に役立つ。</p>

<p>社会的構成物である社会的介入プログラムの設計，実施過程においては多くの利害関係者が存在する。それぞれの立場により，評価に対する関心事や期待事は異なる。</p>

<h2 id="プログラム評価の5階層">プログラム評価の5階層</h2>

<h3 id="ニーズ評価">ニーズ評価</h3>

<p>社会的ニーズとは，あるべき状況と現状のギャップである。ニーズの検討と把握は，社会課題の解決に向けた効果的な介入方法を検討するうえで不可欠のもので，まずはプログラムを計画するときに行うものである。他方で，プログラムが効果的・効率的に実施されているかを評価するには，プログラムがそもそも解決されるべき社会的ニーズを適切にとらえているか，誰のニーズか，そもそも「課題」と人々に認識されているものが本当に充足すべきニーズになっているのかなどを確認・分析をし，課題を取り巻く環境に合わせて適切な解決方法・手段で実施されようとしているのかを問う必要がある（Rossi et al. 2004: 102）。</p>

<p>効果的なプログラムを設計する出発点は，そのプログラムを必要とするニーズ状況を明らかにすることにある。ニーズ状況を分析した結果に基づいてプログラムゴールを設定する，またプログラムが対象とするターゲット集団の状況、問題の範囲と程度を判断する。これらの一連の手続きはニーズ評価と呼ばれている。ニーズ評価では，まず課題となる社会問題を抱えている人たちがどのような人たちであるか，そしてその人たちの社会問題がどのような状況にあるのかを明らかにする。そのうえで，その社会問題がどのような社会的背景や要因によって生み出されているかを分析する（82-83）。</p>

<h3 id="セオリー評価">セオリー評価</h3>

<p>セオリー評価とは，プログラムがめざしている目的に対し投入資源や活動がもっともらしく組み立てられているかどうかを検証・評価するものである。その意味では，セオリー評価もプログラムの設計・開発段階でまずは行われるべきものである（例えば，事前評価と呼ばれる評価作業のなかで行うことも可能）。プログラムの実施途中に行う場合は，実施の現状・課題をふまえ，プログラムの活動が目的を達成する手段として有効な取り組みになっているのか，もし問題があるのならばどのように軌道修正したらよいのかを検討することができる（源ほか 2020: 33）。</p>

<h3 id="プロセス評価">プロセス評価</h3>

<p>プロセス評価はプログラムの活動を展開していく実施の過程（プロセス）の妥当性を問うもので，実施中に何が，なぜ起きているのかを検証する作業である。モニタリングと類似する部分もあるが，その違いは，モニタリングは計画通りに実施されているかといった進捗管理の意味合いが強いのに対し，プロセス評価は活動やアウトカムに関するデータ分析に基づくより効果的なプログラムの形成・改善を目的としている点である（大島・源 2020: 34）。</p>

<h3 id="アウトカムインパクト評価">アウトカム／インパクト評価</h3>

<p>「アウトカム評価」は，プログラムの介入後に期待されるターゲット集団や社会に現れる変化の状態を捉えるもので，介入との帰属性を問い純粋な効果（純効果：net effects）を検証する「インパクト評価」とは厳密には異なるものである。アウトカム評価は，時系列でアウトカムの変化を把握する「アウトカムモニタリング」や業績測定（もしくは実績測定：Performance Measurement）の手法により，予め設定された指標群を使い変化を捉えていく方法と親和性がある。プロセス評価の際には，より近位のアウトカムの変化との連動で活動内容の妥当性を検討することも有益で，プロセスデータとアウトカムモニタリングによるデータとの相関を探るといった方法が採用されている（大島・源 2020: 34）。</p>

<h3 id="インパクト評価">インパクト評価</h3>

<p>インパクト評価は，プログラムが一定期間実施された後の効果（effects）に焦点を当てて評価を行うもので，その効果が当該プログラムの実施によりもたらされたのであるがを検証するものである（大島・源 2020: 35）。</p>

<h3 id="効率性評価">効率性評価</h3>

<p>効率性評価は，投入コストに比してもたらされたアウトプット（活動の結果）やアウトカム（成果）が妥当であるのかを評価するもので，プログラムの特性によってプログラム実施前の計画段階で行うこともあれば，プログラム実施後の場合もある。</p>

<table>
  <thead>
    <tr>
      <th>評価の５階層</th>
      <th>内容</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ニーズ評価</td>
      <td>プログラムの実施により充足しようとしているニーズは何か，プログラムを実施する必要性はあるかを査定すること</td>
    </tr>
    <tr>
      <td>セオリー評価</td>
      <td>プログラムがどのように組み立てられているか，その設計は目的を達成するために妥当であるかを明らかにすること</td>
    </tr>
    <tr>
      <td>プロセス評価</td>
      <td>プログラムが意図されたとおりに実施されているのか，プログラムの実施過程で何が，なぜ起きているのかなどを明らかにすること</td>
    </tr>
    <tr>
      <td>アウトカム／インパクト評価</td>
      <td>プログラムの成果が上がっているかどうかを明らかにすること</td>
    </tr>
    <tr>
      <td>効率性評価</td>
      <td>プログラムが効率的に実施されているかどうかを明らかにすること</td>
    </tr>
  </tbody>
</table>

<p>出所；大島・源らはRossi et al. [2004]を参照し作成するもの。</p>

<table>
  <thead>
    <tr>
      <th>プロセス理論</th>
      <th>インパクト理論</th>
      <th>同左</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ターゲット集団との相互作用</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td>↑↓サービスの提供活動の実施↑↓</td>
      <td>近位アウトカム</td>
      <td>遠位アウトカム</td>
    </tr>
    <tr>
      <td>活動，人材，施機材</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>プログラムセオリーの概念図</p>

<h2 id="プログラムセオリー評価について">プログラムセオリー評価について</h2>

<h3 id="プログラムセオリーの意義">プログラムセオリーの意義</h3>

<p>プログラムセオリーには「インパクト理論」と「プロセス理論」の2つの理論が含まれる。インパクト理論とは，ある社会課題が解決された状態（＝アウトカム）の達成とそれをもたらすプログラムの活動・サービスとのあいだの手段・目的関係を示すものである。例えば，職業訓練サービスの提供（手段）により雇用が創出される（目的）というロジックモデル（仮説）が成り立つ。一方，プロセス理論は，プログラムの実施過程（プロセス）におけるサービス利用計画や組織計画（運営体制）が含まれ，サービスの提供や活動の実施がサービス利用者（ターゲット集団）に届く道筋を示している。評価は改善のための手段である。そのためにはなぜうまくいかなかったのかといった阻害要因の分析（2つの理論を活用）は欠かせない（大島・源 2020: 38-39）。</p>

<h3 id="インパクト理論のメカニズム">インパクト理論のメカニズム</h3>

<p>インパクト理論は，プログラムを手段とし，それによってもたらされるターゲット集団や社会の便益を目的とした。手段ー目的の道筋を明示したものである。目的が達成されたこと，すなわちプログラムの成果が上がったということは，プログラムの実施により参加者に何らかのインパクトを与えた状態を示す。その道筋を可視化したものが<strong>インパクト理論</strong>と呼ばれるものである。プログラムは社会的構成物でありプログラムではコントロールできない多くの要因の影響を受ける。したがって手段ー目的の関係性を検証する場合には，外部要因の影響をできる限り除去して成果を測定する「インパクト評価」の方法の検討が必要になる。プログラム実施による変化を複数の「アウトカム」として2つの段階で表す方法がある。より直接的，あるいは中間的な効果を「近位のアウトカム」とし，それによってもたらされた社会的な変化を「遠位のアウトカム」として明示する（大島・源 2020: 39-40）。</p>

<h3 id="インパクト理論と変化の理論">インパクト理論と変化の理論</h3>

<p>福祉や教育分野の対人サービス領域で発展してきたプログラム評価では，プログラムによってサービスの利用者や関係者の行動や態度の変容が起きているのか，プログラムによってなぜ利用者に変化が起こるのかなどを検証するためのモデルとして「変化の理論（Theory of Change）」が活用されてきた（大島・源 2020: 41）。考え方はインパクト理論と基本的には同じであるが，プログラム実施後からアウトカムが現れるまでの過程を細かく連鎖状に捉え，各関係者ごとの変化をより詳細に示すところに特徴があるとされる（安田2011：103）。</p>

<h2 id="プログラムプロセス評価について">プログラムプロセス評価について</h2>

<h3 id="プロセス理論の要素">プロセス理論の要素</h3>

<p>プログラムのプロセス理論は，「組織計画（人材，資機材，活動）」，ターゲット集団に対する「サービス利用計画（サービスをどのようにターゲット集団に提供するか）」の2つの要素からなり，「それらのあいだの相互作用」をとおしてインパクトが生み出されるであろうという仮説を表すものである（Rossi et al. 2004: 156）。</p>

<h3 id="ロジックモデルの基本要素">ロジックモデルの基本要素</h3>

<p>ロジックモデルは，プログラムセオリーの概念を活用し，プログラムをどのように運営すると近位，遠位のアウトカムがもたらされるのか，プログラムがどのように作用するのかの倫理（ロジック）をモデル化したものである。</p>

<p>ロジックモデルの基本要素は，「インプット（投入資源）」，「活動」，「アウトプット（活動の結果）」，「アウトカム（成果）」の4つからなる。</p>

<p>インプット→活動→アウトプット→アウトカム （コントロール可能な範囲）</p>

<table>
  <thead>
    <tr>
      <th>ロジックモデルの要素</th>
      <th>内容</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>インプット</td>
      <td>プログラム実施に必要な人，モノ，カネ，情報，計画など</td>
    </tr>
    <tr>
      <td>活動</td>
      <td>インプットを使い実施する活動の詳細</td>
    </tr>
    <tr>
      <td>アウトプット</td>
      <td>活動の結果／活動実施により生み出される財，サービス，状態</td>
    </tr>
    <tr>
      <td>アウトカム</td>
      <td>プログラムの介入後にターゲット集団や組織・社会に現れる変化</td>
    </tr>
  </tbody>
</table>

<h3 id="プログラムの実施段階に対応した評価デザインの必要性">プログラムの実施段階に対応した評価デザインの必要性</h3>

<p>対人サービス領域における社会課題解決のために設計されるプログラムでは，まず導入された当該のプログラムが，プログラムゴールを効果的かつ適切に達成するに至っていない導入段階，あるいは発展段階にある場合，プログラムゴールを効果的に達成する「効果モデル」を設計・開発，あるいは形成・改善するための形成的評価が必要となる（大島ほか 2019）。一方，「効果モデル」にプログラム成果に関するある程度十分なエビデンスが蓄積されてきた発達段階では，総括的評価としてRCTなどのアウトカム／インパクト評価の評価デザインが必要になる。なおプログラムの発達段階のアセスメントには，EBPなどの効果的プログラムモデルのエビデンスレベル把握も重要になる（津谷 1999）</p>

<h3 id="定性的評価と定量的評価もしくは混合法">定性的評価と定量的評価，もしくは混合法</h3>

<p>評価設問に回答するにはどのような測定を行い，どのような指標を集め，根拠となるデータを集めなければならないかを考える。収集したデータの分析方法や何と比較して評価を行うのか（比較基準）も念頭においてデータ収集方法を検討していく。その方法によって，統計分析を使った定量的評価が中心となるのか，あるいはナラティブの分析を中心とした定性的評価が中心となるのか，あるいは組み合わせた混合法を使うのかが明らかになる（Linamputrtong 2010 ; Creswell 2010）。</p>

<h3 id="阻害要因">阻害要因</h3>

<p>ロジックモデルで示す仮説が必ずしもそのとおりに実現するとは限らない。計画とのずれがあった理由や，想定した効果発見に至らなかった阻害要因（66）。</p>

<h3 id="セオリー評価の２つのアプローチ">セオリー評価の２つのアプローチ</h3>

<ol>
  <li>既存の文献，調査報告など，これまでわかっている専門的な知識や蓄積されているデータ・知見を踏まえてロジックを分析する方法（演繹的アプローチ）</li>
  <li>当該プログラムが現場でどのように実施されているのかを，観察や関係者のインタビュー，あるいはワークショップを行い把握し，ロジックの妥当性を検討する方法（帰納的アプローチ）</li>
</ol>

<h3 id="参加型評価ワークショップの実施">参加型評価ワークショップの実施</h3>

<p>プログラムセオリーの構築あるいは再構築を行う上で，実践家や関係者が「評価の場」に参加する参加型評価のワークショップ手法が有効である（源 2016 : 57-59 ; 大島ほか 2019 264-289）。評価はプログラムの改善に役立つ評価情報を提供するためのものであり，それを実現するためには，多様な視点や現場の知見をふまえたプログラムの設計を行う必要がある。参加型評価では，評価の専門家だけではなくプログラムの利害関係者（ステークホルダー），特に現場で実際に活動に携わる実践家の参加が有効であるとして，ワークショップ等の方法を推奨している。プログラムの形成・改善に意識の高い実践家等は，問題解決のために新規事業を立ち上げたり，既存プログラムの見直しに自ら積極的に関わり，新しい視点から取り組みをスタートさせることがある。一方で，研究者・評価専門家，行政関係者が設計の評価を開始する場合は，初期の段階から実践家の参加を得ることが望ましい。そのためには，実践家等が主体的に，積極的に評価活動に参画できるような環境を整えるとともに，参加を促す必要がある。</p>

<h3 id="質的データ">質的データ</h3>

<ol>
  <li>文献調査</li>
  <li>観察</li>
  <li>インタビュー調査</li>
  <li>フォーカスグループディスカッション</li>
  <li>ワークショップ／参加型調査</li>
</ol>

<h3 id="评估主义的历史43-53">评估主义的历史（43-53）</h3>

<p>实证主义在社会福利项目的评估研究中长期处于主导地位。尽管人文主义的研究方法目前在社会科学研究领域中取得了越来越强的影响，而评估研究也进入了建构主义（Constructivism）理论取向的第四代，甚至第五代，但实证主义的理论仍然对当今的评估研究有着重要的指导作用。库巴（Egon G. Guba）和林肯（Yvonna S. Lincoln）曾经描述了实证主义评估的发展及其特点，认为其先后经历了以测量（measurement），描述（description）和判断（judgement）为重点的三个评估阶段。</p>

<p>根据库巴和林肯的归纳，以实证主义为理论取向的第一代评估研究已测量为特征，其发展和成熟的标志，便是我们当今都非常熟悉的人类智商测量技术的诞生和成熟过程。第一代评估研究最早大量使用于教育领域，除了学生智商水平的测量，正如库巴和林肯指出的，通过考试评估学生的学习情况，也反映了第一代评估研究的思想方法。第二代评估研究除了继承前一阶段取得的成绩以外，开始注重项目目标。测量不再等同于评估，而仅仅是检查项目设计好坏的一种手段。也就是说，评估的目的，是要借助测量手段的检查效应，找到实现项目目标的一种最佳方案。过程性评估和改进型评估以及项目理论评估都可以视为描述性评估发展的结果。第三代评估的评估人员进一步对项目目标也提出了疑义。评估研究的评估内容不仅包括目标的实现过程，项目的目标同样应该是评估研究的内容。从上述历程来看，第三代评估已经逐步摆脱前两个阶段评估研究纯技术性的价值中立地位，研究者肩负起对项目的价值判断责任，特别是对项目目标的分析判断责任。</p>

<p>实证主义主张运用自然科学方法研究人类社会现象，但是人类社会毕竟不同于自然世界，社会科学的研究对象是有意识的生命个体，能够对生活世界作出主观反映，并且不同的个体具有不同的喜怒哀乐。正是基于上述背景，人为主义（humanism）或解释主义（interpretivism）作为一种独立的社会科学研究哲学应运而生，并逐渐取得日益突出的影响。在社会评估领域，建构主义作为第四代评估的哲学基础，对人类社会现象本体论提出了严峻的挑战，引发评估研究原则的重大变革。</p>]]></content><author><name></name></author><category term="プログラム評価" /><category term="ハンドブック" /><summary type="html"><![CDATA[プログラム評価とは]]></summary></entry><entry><title type="html">日本におけるコミュニティワーク理論の再構築 （池本賢一 2019）</title><link href="http://localhost:4000/%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%83%86%E3%82%A3%E3%83%AF%E3%83%BC%E3%82%AF/2023/04/16/%E6%97%A5%E6%9C%AC%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%83%86%E3%82%A3%E3%83%AF%E3%83%BC%E3%82%AF%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE.html" rel="alternate" type="text/html" title="日本におけるコミュニティワーク理論の再構築 （池本賢一 2019）" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%83%86%E3%82%A3%E3%83%AF%E3%83%BC%E3%82%AF/2023/04/16/%E6%97%A5%E6%9C%AC%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%83%86%E3%82%A3%E3%83%AF%E3%83%BC%E3%82%AF%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE</id><content type="html" xml:base="http://localhost:4000/%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%83%86%E3%82%A3%E3%83%AF%E3%83%BC%E3%82%AF/2023/04/16/%E6%97%A5%E6%9C%AC%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%83%86%E3%82%A3%E3%83%AF%E3%83%BC%E3%82%AF%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE.html"><![CDATA[<script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.0.2/+esm'; mermaid.initialize({ startOnLoad: true }); </script>

<h1 id="文献">文献</h1>

<p>池本賢一・村山浩一郎（2019）「我が国におけるコミュニティワーク理論の再構築に向けた試論ーコミュニティワークの定義及び範囲に着目してー」『福岡県立大学人間社会学部紀要』27(2), 45-58.</p>

<h1 id="要旨">要旨</h1>

<p>今日のわが国における社会福祉制度の動向を鑑みると、各福祉分野で地域支援が重要視されていると考えられる。しかしながら、これまで<strong>地域支援の方法論とされてきたコミュニティワークは、概念や展開プロセス、用いる技術等が必ずしも明確化されていない</strong>という課題がある。本稿は、これまでのコミュニティワークに関する研究から、特に<strong>定義及び範囲に着目して整理を行い、それらを踏まえた上で、理論の再構築に向けた試論を提示</strong>するものである。先行研究の検討から、「ニーズ·資源調整」、「インター·グループ·ワーク」、「統合」、「組織化」、「計画·政策」、「ソーシャル·アクション」、「アドミニストレーション」、「個別課題を踏まえた地域支援」、「主体形成とプログラム開発とその循環」がコミュニティワーク理論のキー概念として明らかになり、これらを基にコミュニティワークの体系図の提示を行った。</p>

<h1 id="キーワード">キーワード</h1>

<p>コミュニティオーガニゼーション、コミュニティワーク、社会福祉協議会、地域福祉、地域支援</p>

<h1 id="研究の背景と課題の所在">研究の背景と課題の所在</h1>

<p>今日、わが国の社会福祉の様々な領域において、地域づくりが重要視されており、それらの動向を集約する形で2017年に社会福祉法が改正された。同法においては、<strong>包括的な支援体制の構築などが明記され、地域共生社会の実現に向けた法改正が進められている。このことからも、住民同士の支え合いの醸成、分野横断的なサービス提供体制の構築などの地域づくりに取り組むこと</strong>が求められているといえる。</p>

<p>このような、地域を支援する方法論にコミュニティワークがある。コミュニティワークについて、瓦井（2011）は「1987年に社会福祉士及び介護福祉士法が成立して以降は、用語としてコミュニティワークが定着しましたが、それでも理論的に統一された定義は未だに見られません」と述べており、理論的に確立しているとは言い難い状況にある。様々な福祉分野が地域を志向しているわが国の福祉施策の動向を踏まえると、<strong>コミュニティワークの理論を明確化することは喫緊の課題</strong>である。</p>

<p>定義が理論的に確立していないという課題を残す一方で、わが国の社会福祉士養成に関わるテキストでは、コミュニティワークの記述が減少し、代わりにコミュニティソーシャルワークの記述が増加している。また、研究論文においても、=<strong>近年コミュニティワークに関する研究が減少傾向にある</strong>と金田は指摘している（金田2016)。</p>

<p>また、コミュニティソーシャルワークとコミュニティワークの関係性に関しては、<strong>コミュニティソーシャルワークがコミュニティワークを包含するか否かなど、出口の見えない議論が続いており、コミュニティワークの曖昧さは地域福祉の援助技術に関する研究を進める上で、大きな阻害要因になっている</strong>。</p>

<p>このことから、コミュニティワークに残された課題、すなわち定義や技術体系化に関する研究を進めていく必要があると考える。これを踏まえ、本稿はこれまでのコミュニティワークに関する研究から、特に定義と範囲に着目して整理を行い、それらを踏まえた上で、今後の理論研究の一つの方向性を示すものとして、試論ではあるが、コミュニティワークの定義、及び体系図の提示を行った。</p>

<h1 id="平野のコミュニティワーク">平野のコミュニティワーク</h1>

<p>平野（2003）も、コミュニティワークの展開プロセスとして<strong>永田（幹）の「活動主体の組織化→問題把握→計画策定→計画実施→評価」</strong>を示している。平野はさらに、コミュニティワークの実践プロセス整理において、活動主体の組織化とサービス資源の開発は区別されているものの、循環的な視点が弱いと指摘し、S⇔ Pモデルという実践モデルを提唱している。</p>

<p>永田（幹）</p>
<div class="mermaid">
flowchart LR
活動主体の組織化==&gt;問題把握==&gt;計画策定==&gt;計画実施==&gt;評価
</div>

<p>活動主体とプログラムの循環（平野2008:104）</p>
<div class="mermaid">
flowchart LR
1.組織化---&gt;2.把握---&gt;3.作成---&gt;4.実施---&gt;5.評価---&gt;1.組織化
subgraph one
活動主体:S===1.組織化
end
subgraph two
プログラム:M===3.作成
プログラム:M===4.実施
end
</div>

<p>平野は永田（幹）の示した地域組織化過程をベースに、コミュニティワーカーが活動主体の組織化に関わり、プログラム作成を支援するという「援助実践」にウェイトを置いた循環構造として、図2を示している。</p>

<p>平野の図では、活動主体を組織化し、プログラムを作成·実施するという循環を生み出すもの（また、それを支援するもの）としてコミュニティワークが位置付けられている。</p>

<p>つまり、平野は永田（幹）の地域組織化過程を踏まえてはいるものの、地域組織化をコミュニティワークとして捉えるのではなく、一連の循環を繰り返すことによって、メゾ領域からマクロ領域へと活動を波及させていく螺旋構造の循環がコミュニティワークにはあるとしている。</p>

<h1 id="永田祐のコミュニティワーク">永田（祐）のコミュニティワーク</h1>

<p>永田（祐）は、平野の示した図をもとに、以下のように述べている。地域組織化のプロセスは、（1）地域（コミュニティ）の問題状況の把握、（2）活動主体の組織化、（3）プログラムの作成と、（4）実施、そして（5）評価というプロセスに整理できる（永田2017：86）。</p>

<p>永田（祐）はコミュニティワークの展開を論じる上で、最後にソーシャルアクションについて言及している。また、永田（祐）はコミュニティワーク＝地域組織化とは捉えておらず、あくまでも地域組織化をコミュニティワークの中心的な実践と位置づけ、論述している。</p>

<p>さらに、永田（祐）の論述では、個別課題を踏まえたコミュニティワークの展開を考える上で、個別課題を普遍化するための「場」が必要であると述べている。永田（祐）は、その課題の普遍化に必要な「場」や「機会」をつくり、学び、活動、計画への反映などの行動を起こすためには支援が必要であり、その一連の過程をコミュニティワークとし、今日的なコミュニティワークの方向性を示唆している。</p>

<p>永田（祐）のコミュニティワークは、個別課題を踏まえて展開される、いわばコミュニティソーシャルワークの考え方に近いものであるといえる。しかしながら、個別課題と地域課題を同時進行的に行うコミュニティソーシャルワークの概念とは異なり、地域支援がべースとなっている。このことから、個別課題を志向したコミュニティワークといえるが、その中で重要視しているのが「場」や「機会」の創出である。これまでのコミュニティワーク研究（澤田2006、長谷中2012など）や、永田（祐）の論述において住民が参加する「場」や「機会」をつくることの重要性は示されてきたものの、この「場」や「機会」をどのように構築するのかという方法·プロセスは、具体的な研究がなされていないという課題がある。</p>

<h1 id="まとめ">まとめ</h1>

<p>これまでのわが国におけるコミュニティワークの研究をまとめると、わが国においてはレイン報告、ニューステッター、ロスが示した3つのCOが統合される形で発展してきたと考えられる。そして、永田（幹）は当初、コミュニティワークを地域組織化とイコールで結ぶのではなく、広範な概念として提唱していたが、これまでコミュニティワークを用いて実践を重ねてきた社会福祉協議会においては、地域組織化活動として認識が広がってしまった可能性が示唆された。そして、平野は活動主体の組織化とプログラム作成·循環によるコミュニティワーク、永田（祐）は個別を見据えた地域支援としてコミュニティワークを論じ、野口はケースマネージメントを含む広範な活動としてコミュニティワークを捉えている。</p>

<p>また、英米と日本のコミュニティワークを比較すると、諸外国においては概念およびモデルの研究が主であり、展開プロセスを示したものがない。逆に、わが国においては展開プロセスを示したものが多く、モデルに関する論述は、鈴木（2002）、濱野（2004）、平野（2008）らが行っているが、英米と比較してもその数は少ない。この差は非常に興味深いものであるが、本稿の本旨ではないため今後の研究課題としたい。</p>

<h1 id="考察一コミュニティワークの整理と試論">考察一コミュニティワークの整理と試論</h1>

<p>これまで、コミュニティワークの定義、実践モデル、展開プロセスに関する先行研究を概観してきたが、統一された見解はなく、いずれも論者によってさまざまであることが窺えた。先行研究を踏まえると、英米からわが国に取入れられた概念として、「ニーズ·資源調整」、「インター·グループ·ワーク」、「統合」、「組織化」、「計画·政策」、「ソーシャル·アクション」、「アドミニストレーション」などがコミュニティワークの中に含まれていると考えられる。また、わが国におけるコミュニティワークでは、英米からの概念に加え、「個別課題を踏まえた地域支援」、「主体形成とプログラム開発、その循環」の概念が示されている。</p>

<p>これらを踏まえて、コミュニティワークを一つの体系図に示した（図4）。以下の体系図は、ミクロ·メゾ·マクロという圏域（活動の範囲）で整理したものである。なお、フィッシャーが示したように、「ソーシャルワーク外」の活動も考慮している。また、永田（幹）、野口、口スマンの論述に従って、マクロ圏域までを対象とした。</p>

<p>ここでは、図4の体系図について説明を行う。この体系図の特徴は、ミクロとメゾ、そしてマクロの間にそれぞれの圏域をつなぐ「結節点」があることである。これは、永田（祐そしてニューステッターによる論を参考に、今日の地域福祉実践を踏まえて設定を行った。まず、ソーシャルワークにおける、個人や世帯に対するケースワークなどの直接的な援助が行われる範囲をミクロ圏域とした。先述したように、永田（祐）は個別課題を見据えたコミュニティワークを考える上で、課題の普遍化を行うための「場·機会」をつくることの必要性を述べている。つまり、個別的な課題を地域の課題として転換する結節点としての「場·機会」が必要であるということである。それをミクロ圏域とメゾ圏域の中間に位置付けている。また、必ずしもミクロ圏域から課題を把握するわけではなく、地域アセスメントによる地域共通の課題を直接的に把握する場合もある。このことから、「個別課題の普遍化」と同様に「地域アセスメント」も活動主体の組織化につながる開始点に位置付けている。</p>

<p>次に、ソーシャルワークのメゾ圏域ではロスの統合化説が小地域に対する支援として有効であると考え、これを中核概念とした。ここでのメゾ圏域は自治会～小学校単位とし、永田（幹）の「地域組織化過程」を基本に、平野の循環構造を取り入れた形で示した。なお、本稿においては、地域アセスメントは支援者が行うもので、地域組織化過程の中の「問題の把握」2）は、住民がその問題を把握することと解釈し、区別して表している。</p>

<p>最後に、ソーシャルワークのマクロ圏域は、中学校区～自治体全域とし、政策·計画を位置付けた。政策や計画実行に際しての進行管理·運営管理が求められるため、ここにアドミニストレーションを位置付けている。そのメゾ圏域とマクロ圏域の中間も、これまでの先行研究を踏まえ、インター·グループ·ワークによる「場·機会」の設定（例えば、計画策定委員会など）や組織化を行う必要があり、これらを結節点として捉えた。ソーシャル·アクションについても、政策改善を促すために組織化を改めて行うことも想定されるため、この結節点にその組織化を位置付けている。なお、図の煩雑さを避けるために、政策や活動などが課題を抱える個人へ還元されるというべクトルも当然考慮すべきだが、ここでは割愛している。</p>

<p>次に、フィッシャーの論述にある「ソーシャルワーク外」のコミュニティワークについて述べる。フィッシャー（1987）は「ソーシャルワークモデル」を「地域社会を組織化したり、社会サービス組織間の連携を促したり、あるいは社会資源を開発したり、配分することを主な目標とする。最も特徴的なのは、COはそれ自体を一つの社会的事業として捉え、そしてソーシャル·ワーク専門職の一般的志向の範囲内で機能することである」と定義している。近年、ソーシャルワーカーの活動範囲としては想定されない、ソーシャルワーク外でまちづくりを行うNPOが増加している。彼らの活動は必ずしも地域の福祉課題のみに取り組んでいるわけではなく、地域の活性化など幅広く支援を行っている。トゥエルブトゥリーズ（2006）によると、イギリスでは福祉に限らず、広くまちづくりを支援するものとしてコミュニティワークが捉えられており、フィッシャーの示したソーシャルワークモデルにおける、ソーシャルワーク専門職の一般的志向の範囲外の活動が、コミュニティワークには含まれる。</p>

<p>このことから、ここでは環境、教育、保健など、福祉以外の分野において地域住民を組織化し、活動を支援していくものを「ソーシャルワーク外」のコミュニティワークとした。
この体系図を踏まえると、以下のようにコミュニティワークを定義できるのではないか。</p>

<p>コミュニティワークとは、地域に内在する諸課題を地域社会みずからが組織的に解決するために、地域の個別的·地域的課題を把握し、それらの諸課題が地域の課題として認識されるよう場·機会を設け、そこで相互作用によって地域の主体性を高め、課題解決のための実行計画立案を側面から支援し、必要に応じて地域の福祉活動に対して社会資源·関係機関との連絡調整、行政機関等に対する社会行動支援、政策への意見反映支援、計画の進行管理等を行う援助活動であり、それを進める方法と技術を含むものである。</p>

<p>これまで述べてきたように、先行研究では論者によってコミュニティワークに含める概念が異なっていた。そこで本稿では、それぞれの論述を矛盾なく組み合わせ、コミュニティワークの包括的な定義とその範囲を示す体系図の作成を試みた。近年重要視されている「包括的な支援体制」を踏まえ、「個別課題の普遍化」をコミュニティワークの概念に加え、最大限に広く定義と範囲を示した。これはあくまでもこれまでの先行研究をまとめた試論であるため、今後の研究において、各圏域における実践から、コミュニティワークに含まれる概念、定義、範囲、技術等を精査し、コミュニティワークの理論を検討していきたいと考えている。</p>

<h1 id="終わりに">終わりに</h1>

<p>今日の福祉施策の動向を踏まえると、地域支援の方法やプロセスを確立することは、社会福祉協議会だけでなく、多くのそれに携わる職員のスキルアップにつながる。しかしながら、これまで述べてきたように、地域支援の方法論として位置づけられているコミュニティワークは、その定義も未だ確立していない状況にある。今日求められているジェネラリストとしてのソーシャルワーカーを養成していく上でも、コミュニティワークの理論の確立は重要な課題であると考える。
本稿で示した定義及び体系図は試論に過ぎないが、今後の研究の一つの道標になると考える。</p>]]></content><author><name></name></author><category term="コミュニティワーク" /><category term="研究" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Social Work Practice with Communities - Intervention, Termination, and Evaluation</title><link href="http://localhost:4000/social%20work%20practice/2023/04/16/Social-work-practice-with-community.html" rel="alternate" type="text/html" title="Social Work Practice with Communities - Intervention, Termination, and Evaluation" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>http://localhost:4000/social%20work%20practice/2023/04/16/Social%20work%20practice%20with%20community</id><content type="html" xml:base="http://localhost:4000/social%20work%20practice/2023/04/16/Social-work-practice-with-community.html"><![CDATA[<h1 id="書籍">書籍</h1>
<p>Birkenmaier, J., &amp; Berg-Weger, M. (2020). <em>The practice of generalist social work</em>. Routledge.P496-527</p>

<h1 id="begin">Begin</h1>

<p>LIKE SOCIAL WORK PRACTICE WITH INDIVIDUALS, FAMILIES, AND GROUPS, 
the middle and ending phases of work with communities are intervention ,termination, evaluation, and follow-up. As noted in Chapter 10, community practice is a broad term that includes grassroots community organizing, community development, human service program development, planning and coordination, and advocacy (Weil, Gamble, &amp; Ohmer, 2013). There are many types of community interventions, all of which are based on the data gathered and process used for community assessment. The aim of many community practice interventions is to build community capacity and shape institutional arrangements that meet the needs of community members.</p>

<p>In this chapter, we begin with a discussion of theoretical traditions and practice models that can help guide social work intervention with communities. Our focus is on the most recognized models of community intervention, as well as the ways in which they can be mixed in practice. After providing an overview of social work interventions with communities, the chapter continues with a look at the termination, evaluation, and follow-up processes.</p>

<h1 id="theoretical-traditions-and-models-for-community-intervention">Theoretical traditions and models for community intervention</h1>

<p>As we discussed in Chapter 10, conceptual and theoretical traditions in social work provide a lens through which to understand and analyze communities. For example, you can apply the strengths approach to communities by identifying assets and resources of individuals, groups, and institutions in that community. You can achieve the empowerment approach by helping community members realize their capacity to build on the community’s strengths (Netting et al., 2017).</p>

<p>Community practice models, which are primarily based in the concepts and language of systems, ecological, power, change, and politics theories, guide community interventions (Netting et al., 2017). As Exhibit 11.1 notes, systems theory helps to demonstrate that planned community change reverberates throughout a community and affects units within and outside of a community. Therefore, when you choose a community intervention, you should consider the possibility that community change may affect more people than you intend.</p>

<p>Ecological theory’s focus on competition for limited resources, which can affect the relationships among different parts of a community or between communities, informs community interventions. Theoretical traditions that focus on power, change, and politics emphasize the ways in which external forces influence local communities and the ways in which some members of a community possess social or political power while other members do not. Social workers in community practice can help members of a community critically examine both external and internal power and the influence of the various types of power. Without examining power dynamics, community members cannot have honest and open discussions about what is best for the community as a whole, and how to establish priorities for their community’s future.</p>

<h3 id="exhibit-111-understanding-community-practice-theoretical-contributions">Exhibit 11.1 Understanding Community Practice: Theoretical Contributions</h3>

<table>
  <thead>
    <tr>
      <th>Theoretical</th>
      <th>Contributions to understanding community practice</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Social systems</td>
      <td>Reveals that changes in one community unit impact other units indicates that changes in subunits influence the larger community</td>
    </tr>
    <tr>
      <td> </td>
      <td>Allows comparisons of the functioning of different communities</td>
    </tr>
    <tr>
      <td>Ecological</td>
      <td>Sheds light on relationships among community units</td>
    </tr>
    <tr>
      <td> </td>
      <td>Recognizes that community groups compete for limited resources</td>
    </tr>
    <tr>
      <td> </td>
      <td>Recognizes that groups without power must adapt to community norms</td>
    </tr>
    <tr>
      <td> </td>
      <td>Acknowledges the interconnections and mutual shaping of physical and social structures</td>
    </tr>
    <tr>
      <td>Power, Change, and politics</td>
      <td>Reveals the influence of external sources of resources on communities</td>
    </tr>
    <tr>
      <td> </td>
      <td>Views the community as divided into “haves” and “have-nots”</td>
    </tr>
    <tr>
      <td> </td>
      <td>Focuses heavily on “isms” such as racism</td>
    </tr>
    <tr>
      <td> </td>
      <td>Acknowledges the role of power in all interpersonal transactions</td>
    </tr>
  </tbody>
</table>

<p>Source: Netting, Kettner, McMurtry, &amp; Thomas, 2017</p>

<p>As highlighted in Chapter 10, data from the community-assessment process provides the basis for community change efforts, which often use a variety of approaches. The models most common in the literature are Rothman’s (2008) three models of community practice: planning/policy, community capacity development, and social advocacy. These three models have the goal of improving social, economic, and/or environmental well-being and share several common elements, including the following:</p>

<p>• the formulation of a change goal,</p>

<p>• roles for staff,</p>

<p>• leaders and members,</p>

<p>• a process for selecting issues to work on,</p>

<p>• a target of the change effort,</p>

<p>• assessment of resources needed to produce change, and</p>

<p>• an understanding of the role of organizations in the change process.</p>

<h2 id="the-planningpolicy-model">the planning/policy Model</h2>

<p>The planning/policy model of community intervention focuses on data and logic to achieve community change, using experts to assist in the process of studying problems and applying rational planning techniques. Social workers using social planning consider political realities and the usefulness of advocacy in the intervention process, but the primary emphasis is on rational planning.</p>

<p>The planning/policy model can be implemented in a range of practice situations. Social workers engage in social planning when they participate in efforts to envision, develop, coordinate, deliver, and improve human services. Planning is needed for all types of human services (i.e., child welfare, health, aging) and topics (i.e., gang violence, neighborhood development), and in all types of host organizations, including local, state, or federal governments, faith-based organizations, and community councils (Sager &amp; Weil, 2013). As one example, social workers prioritize data when they are involved in comprehensive planning, such as working with city officials to create a plan for homeless shelters or juvenile justice facilities in the community. In these situations, data from local nonprofit organizations, local and state governments, and the U.S. Census Bureau can be of great use in shaping decisions.</p>

<h2 id="the-community-capacity-development-model">The Community Capacity development Model</h2>

<p>The community capacity development model focuses on fostering the community’s ability to accomplish change by building relationships and skills that help solve local problems in a cooperative manner. Participant consensus is the optimal decision-making process for this model. This model emphasizes building competency of community members, groups, and the community as a whole through self-help and local problem-solving. Building community capacity often focuses on empowerment of members, solidarity among members, participation in civic action within a democratic process, and the development of leadership from the community. For example, neighborhood associations may work to educate themselves on ways to address a trash dumping problem. The work of the U.S. Peace Corps, in which international volunteers work with local communities to create a project or increase capacity in an ongoing community effort, is another example of the community capacity development model.</p>

<blockquote>
  <p>For another example of the community capacity development model, we return to Taylor and Ben, the social workers who are planning a barbeque for youth from a school and older adults from a nearby senior center. Taylor spoke ahead of time with two students who had excellent communication skills and asked them to help barbeque and serve food. Ben similarly lined up two senior center leaders to help. This planning seemed to smooth the initial moments of the “meet-and-greet” and gave the two age groups a chance to begin getting to know one another. Soon after people began to finish their meals, Taylor and Ben started the discussion by explaining how “brainstorming” worked and then asking everyone to share ideas for small enterprises that would help build new skills for the youth while also meeting needs in the larger community.</p>

  <p>A number of people shared ideas for small businesses that seemed feasible. One of the older adults said that he would love to have salads and vegetables with the senior center congregate meals that many participants brought as side dishes to accompany the barbeque. While he contributed the idea as a complement to the cooks, one of the students said that he would grow vegetables for the senior center if he knew anything about gardening. Another student said she would be happy to help cook vegetables if she knew anything about cooking. These comments had the group laughing but also led to a sharing of stories from the older adults about learning how to garden and cook as children.</p>

  <p>By the end of the meet-and-greet, an idea for a small community garden had begun to form. Many of the youth seemed interested in learning how to grow vegetables for older adults to add to their congregate meals, and in being able to sell the leftover vegetables to neighbors for a reasonable price. Several older adults offered to help plan the community garden and teach the youth how to cultivate and harvest vegetables. Others had little interest in working outside during the summer heat but said they would be happy to teach students how to prepare and cook vegetable dishes. One of the youths suggested creating a digital cookbook featuring vegetables from the community garden and selling e-copies to earn money to help sustain the garden. The group agreed to meet again the following week to develop a list of what each person could do to contribute to the community gardening effort. Taylor and Ben had successfully used a community capacity development model to form a collaborative intergenerational team to improve the neighborhood.</p>
</blockquote>

<h2 id="the-social-advocacy-model">the social advocacy Model</h2>

<p>The social advocacy model is based in theoretical traditions that focus on conflict, power dependency, and resource mobilization. This model is both process and task-oriented and focuses on shifting power relationships and redistributing resources to facilitate change in community structures or institutions to resolve problems affecting many residents. Through this model, community members often experience empowerment when they feel a sense of achievement in helping to influence decisions and policies that affect the entire community.</p>

<p>A helpful example of the social advocacy model is the work of Greenpeace. To seek solutions to environmental dilemmas, such as climate change, Greenpeace nonviolently confronts decision-makers and those who may influence decision-makers. The goal of their work is to promote public dialog about environmental issues and to advocate for policies that protect the earth.</p>

<p>As listed in Quick Guide 32, there are a wide variety of social advocacy activities, including, but not limited to, protesting, striking, walking on picket lines, and testifying (Rothman, 2008; Weil &amp; Gamble, 2009).</p>

<h2 id="applying-community-practice-models-to-a-case-example">Applying Community Practice Models to a Case example</h2>

<h3 id="activities-to-promote-social-change">Activities to Promote Social Change</h3>
<ul>
  <li>Conduct petition drives</li>
  <li><strong>Conduct public hearings</strong></li>
  <li><strong>Develop relationships with decision-makers</strong></li>
  <li>File complaints</li>
  <li>Lobby decision-makers</li>
  <li>Organize boycotts</li>
  <li>Organize public demonstrations</li>
  <li>Organize strikes</li>
  <li><strong>Provide testimony</strong></li>
  <li>Recruit and develop leaders</li>
  <li>Register voters</li>
  <li>Use legal action</li>
  <li><strong>Use media</strong></li>
  <li><strong>Write letters to legislators and/or the media</strong>
Sources: Bobo, Kendall, &amp; Max, 2010; University of Kansas Work Group for Community Health and Development, 2018</li>
</ul>

<h3 id="applying-community-practice-models-to-the-brickville-redevelopment-example">Applying Community Practice Models to the Brickville Redevelopment Example</h3>

<p>The Brickville community is in a quandary. Although the community needs redevelopment, the current proposal to completely overhaul the physical structures in the community, including razing some buildings, has stirred major controversy among current community residents, neighborhood social service providers, and sympathetic outsiders. The community has had little input into the plan, and some residents fear that they would no longer be able to afford to live in the neighborhood after the redevelopment. For example, after similar redevelopment efforts in other parts of the city, both rents and property taxes have increased, leading to long-term residents needing to move to more affordable neighborhoods. Other people do not like the plan itself, believing that the planned changes in community real estate will change the look and character of the area. Some residents think that the community will benefit from redevelopment despite the possible negative effects. Still others do not trust the developer who has proposed the redevelopment. Over the past half-century, real estate developers have made several half-hearted efforts to redevelop the residential and commercial parts of the community, with little success. However, several real estate developers are now working to redevelop different areas of the community, and all are requesting public funding in addition to applying for loans from area banks for their development efforts. While some developers are working with current residents, most have not asked community groups or local political leaders for their input or feedback on the redevelopment plans.</p>

<p><strong>The Planning/Policy Model</strong>: Using the planning/policy model, the community group or local political leader would request that city planners generate data or use previously existing data to create a redevelopment plan for the community to which all developers would have to adhere.</p>

<p><strong>The Community Capacity Development Model</strong>: using the community capacity development model, one or more community groups from the affected area would begin a process of developing their ability to create a comprehensive community redevelopment plan that they could present to real estate developers and/or city officials.</p>

<p><strong>The Social Advocacy Model</strong>: using the social advocacy model, one or more leaders from the affected area would organize community residents and groups to communicate with specific decision-makers, and sometimes bring pressure to bear as needed, to affect outcomes of interest such as zoning ordinances, public funding, and the availability and structure of tax breaks for redevelopers. advocacy efforts including messaging workshops, sign-making parties for public protests, and strategic timing and locations for community outreach and educational events would likely be involved using this model.</p>

<p>One of the ways that social workers facilitate social change in community practice is to provide testimony to decision-making bodies such as neighborhood associations, city councils, departments at the local or state level, and state legislatures. Preparing and providing testimony is a strategy that can be used in conjunction with any of the community intervention models. Quick Guide 33 provides details on preparing and presenting testimony.</p>

<h3 id="providing-testimony">Providing Testimony</h3>

<p>Social workers often provide testimony to legislative and planning committees at the local, state, regional, and national levels. The main purpose of testimony is to share information and advocate for evidence-based solutions. The following steps are helpful when preparing to provide testimony to a legislative body:</p>

<ol>
  <li>
    <p>Learn about how legislative proposals (bills) work their way through the legislature. Who sponsored or co-sponsored the bill? To what committee(s) has your bill been assigned? What are the possible outcomes of committee work on the bill? Where will the bill go next if the committee approves it? Has a similar bill been introduced in the other chamber?</p>
  </li>
  <li>
    <p>Learn about the history of the topic and bill. Has this bill been proposed before? Who sponsored it? What happened to the bill? Did the general public already vote on the topic through a referendum? Has this bill already been amended?</p>
  </li>
  <li>
    <p>Engage in research about the topic. Research existing statutes that the bill seeks to amend, revise, supplement, or delete. If possible, research the cost of the bill, if enacted. A “fiscal note” is often prepared by staff members of the legislative body to estimate the potential costs in some detail.</p>
  </li>
  <li>
    <p>Engage in research about the politics of the bill. Which individuals or what groups are working for the bill? Against the bill? What are their perspectives?</p>
  </li>
  <li>
    <p>Research the committee membership. Who is the chair? What is his/her perspective on the topic of your bill? Who else is on the committee? What are their interests and those of their constituents? How have they voted on this topic before?</p>
  </li>
  <li>
    <p>Determine how long your testimony should be, and, depending on time, draft a written statement that: (1) provides factual data, including cost estimates, needed to support the desired policy changes; (2) analyzes the proposed changes/additions to present law; (3) discusses how the desired policy changes would alleviate community problems, and any possible new problems that various attempts to do so may create; and/or (4) provides suggestions for needed amendments to changes that have been previously suggested.</p>
  </li>
</ol>

<p>When delivering your testimony, consider the following:</p>

<ol>
  <li>
    <p>Use effective nonverbal communication. Dress professionally, make eye contact, and display a calm and confident demeanor.</p>
  </li>
  <li>
    <p>Start your testimony by introducing yourself and the organization you represent. Use full titles to address committee members. At the beginning and end of your testimony, thank the committee chair and decision-makers for allowing you to speak. State your name and background information related to the topic at hand (such as where you live, your credentials, or your connection to the topic). Clearly state your request for the outcome of the decision-making process.</p>
  </li>
  <li>
    <p>Describe your involvement with the topic, including any helpful context or background. If the testimony is related to your employment, provide your employer’s name and interest in the topic.</p>
  </li>
  <li>
    <p>Describe how the topic affects you, your clients, and members of your community. Provide factual information as well as anecdotes. Describe how the pending decision will positively or negatively affect you, your clients, and members of your community, and include a description of who will benefit, or who will be hurt, by the decision.</p>
  </li>
  <li>
    <p>End by thanking the committee again, and offer to be of further assistance. Offer to leave a copy of your written statement with the committee.</p>
  </li>
  <li>
    <p>Convey passion for the topic you are addressing, balanced with professionalism.</p>
  </li>
  <li>
    <p>If you are asked questions, maintain your professionalism. Do not take questions personally, but rather state facts and your position on the bill. Offer to get facts or call on someone else to help, if needed.</p>
  </li>
</ol>

<p>Remember that a vote can be the result of a particular amendment to the bill, budget projections, position of party leadership, or complex interrelationships between procedural and substantive issues—not necessarily the subject of the bill. This means that it is important not to assume that votes against the community’s interest are the result of lack of support for the community at other times or on other issues.</p>

<p>Source: Kleinkauf, 1981; Oregon Legislature, n.d.; University of Kansas Work Group for Community Health and Development, 2018.</p>

<h2 id="blending-models">Blending Models</h2>

<p>While we present models here in a “pure” form, in practice strategies from various models are often used together in community practice. For this reason, it is important for social workers in community practice to know about and plan to use parts of all of the models as needed (Rothman, 2008; Weil &amp; Gamble, 2009). We present examples of using strategies from different models, or blending the models, in this section.</p>

<h3 id="blending-the-planningpolicy-and-community-capacity-development-models">Blending the planning/policy and Community Capacity development Models</h3>

<p>It is possible to blend the planning/policy model and the community capacity development model with the use of citizen input and a data-driven planning process. For example, the St. Louis Mental Health Board in Missouri periodically completes a needs assessment of local mental health services to identify unmet needs. The Board then creates a multiyear plan to allocate funding to best meet those needs. Throughout the process, the Board receives feedback from mental health providers and citizens, including those who receive mental health services. In this way, the Board uses strategies from two models through the strong reliance on data (planning/policy) and the use of citizen and provider input into the planning process (community capacity development) (Rothman, 2008).</p>

<p>Another example of using strategies from different models can be seen in social work practice within <strong>community development corporations (CDCs)</strong>, which are resident-driven organizations that exist to provide assistance to the community. This assistance can include facilitating housing improvements throughout the community, supporting businesses and commercial real estate efforts, and involvement in improving child care availability, community centers, and other community resources. Boards of residents, business owners, and local government officials generally govern CDCs. They often use data-informed approaches in creating small-business assistance programs, helping to establish cooperatives, which are member-owned and -operated businesses, or rehabilitating affordable housing in the community (Garkovich, 2011).</p>

<h3 id="blending-the-social-advocacy-and-planningpolicy-models">Blending the social advocacy and planning/policy Models</h3>
<p>This is done by emphasizing the use of data and logic in policy advocacy efforts. For instance, social workers in community practice often work with residents in using data from needs assessments and funding allocation plans to advocate for policy changes at the local or state levels in educating decision-makers and engaging in citizen lobbying efforts as needed. In this manner, community practice efforts can involve both the use of data (planning/policy) and advocacy efforts (social advocacy) to facilitate community change (Rothman, 2008). This blend can best describe the efforts of many prominent social justice pioneers in history, such as Jane Addams, John Dewey, Margaret Sanger, and Ida B. Wells-Barnett. These pioneers based their arguments about social ills such as child labor, lynching, inadequate housing codes, laws against birth control, and many other issues on data and logical arguments. Using tactics associated with different models that bring pressure to bear on decision-makers (social advocacy) with data and logic (planning/policy) most closely aligns with the roots of the profession (Rothman, 2008). Today, “think-tanks” such as the Urban Institute and the New America Foundation provide well-researched factual reports that social advocacy groups use to work for change.</p>

<h3 id="blending-the-social-advocacy-and-community-capacity-development-models">Blending the social advocacy and Community Capacity development Models</h3>
<p>By blending these models, networks of community stakeholders are encouraged to advocate with leaders, elected officials, and other decision-makers to improve the community. For example, a neighborhood group may learn about the plans to establish a landfill that would accept some toxic waste in their community and decide to fight it by lobbying key decision-makers, delivering petitions, and/ or picketing the local government. A group of parents of children who are lesbian, gay, bisexual, transgender, and queer (LGBTQ+) may decide to engage in an online effort to advocate for civil rights for LGBTQ+ people in their community. If their elected officials and key decision-makers in public offices responsible for civil rights protections are not responsive, the parent group may plan a more public action such as a sit-in at a strategic location to advocate for the support they need. This approach emphasizes building community capacity with social advocacy techniques in situations where this mix will maximize the possibility for community change (Rothman, 2008). The use of strategies associated with community capacity development and social advocacy together is common in long-term social change efforts such as the LGBTQ+ rights, environmental, and women’s rights movements. Strategically using social advocacy techniques while building the capacities of community members helps create an aptitude for long-term involvement in community intervention (Rothman, 2008).</p>

<h1 id="skills-for-community-intervention">Skills for community intervention</h1>

<p>Community intervention involves social work practice to improve community conditions and quality of life for neighborhood residents or community members. We discuss community social and economic development, asset building and asset mapping, and community organizing. We also cover the skills of conducting meetings and facilitating decision-making in community practice.</p>

<h2 id="community-social-and-economic-development">Community social and economic development</h2>

<p>Community social and economic development (hereafter referred to as “community development”), also called “locality development” and “community building,” is an often-ambiguous term with a variety of definitions. In this text, it is a community intervention method that seeks to maximize human potential by focusing on social relationships and the environment to improve the physical and social fabric of communities (Rubin &amp; Rubin, 2008). Community development emphasizes social development through relationship building, education, motivation for self-help, and leadership development. It encourages local participation in community efforts toward the goal of strengthening democracy at the local community level and can include efforts to revitalize institutions. Community development that is focused on economics includes economic development, affordable housing, employment services, and other activities. Often community social development and community economic development efforts are simultaneous and interdependent, and they can be viewed as a continuum.</p>

<p>Community development may include professions from many fields in addition to social work, including business, sociology, anthropology, psychology, and others (Gamble &amp; Hoff, 2013). Community development work most closely aligns with the community capacity development model discussed earlier, because its goal is to mobilize communities to solve problems and effectively work with institutions rather than to engage in social advocacy or planning/policy work. However, community development work also can use a mix of models, depending on the needs at the time.</p>

<p>The following assumptions drive community development (Cnaan &amp; Rothman, 2008, pp. 247–248):</p>

<ul>
  <li>
    <p>People may need to become aware of a common problem and create a desire to act in order to solve problems.</p>
  </li>
  <li>
    <p>A diverse group of people across various dimensions of diversity (i.e., race, ethnicity, socioeconomic status, etc.) adds value and authenticity to the efforts and ensures that they serve the interests of more than one group of people.</p>
  </li>
  <li>
    <p>Democratic decision-making and participatory democracy values and fosters local self-determination.</p>
  </li>
  <li>
    <p>Empowerment, or the capacity to solve problems by working with the authorities and institutions that affect the lives of community members, is a central goal of community development.</p>
  </li>
  <li>
    <p>The primary constituents of the community development social worker are community members and community organizations, rather than those who hold more power.</p>
  </li>
  <li>
    <p>Planned change is preferred to inaction that allows current conditions to continue.</p>
  </li>
</ul>

<h2 id="community-development-skills">Community development skills</h2>

<p>The most commonly used practice skills are group work skills. Group work, covered extensively in Chapters 8 and 9, is a major part of community development work, as this type of work is often conducted in meetings. To ensure success, community development social workers must employ task group work skills including leadership; communication; problem-solving; and managing group function and processes such as educating, forming groups, seeking consensus, encouraging group discussion, and focusing to solve concerns and problems common to the group. Other skills include analyzing community issues and facilitating the increase of communication among community members (Cnaan &amp; Rothman, 2008).</p>

<p>As discussed in Chapter 9, promoting leadership from within the community in social work directed at community development requires the ability to distribute leadership as widely as possible. Facilitation of effective task meetings is one example of a leadership skill that social workers may use or teach to community leaders. Quick Guide 34 provides an overview of the tasks involved in effective meeting facilitation. These tasks can be distributed among individuals during meetings or handled by a small group in preparation for a larger meeting as a way to learn and exercise leadership skills.</p>

<h3 id="quick-guide-34-elements-of-effective-meetings">QUICK GUIDE 34 Elements of Effective Meetings</h3>

<table>
  <thead>
    <tr>
      <th>Stage</th>
      <th>Element</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Preparation</td>
      <td>Goals</td>
      <td>Develop goals for each meeting</td>
    </tr>
    <tr>
      <td> </td>
      <td>Site</td>
      <td>Establish a meeting site that is familiar, accessible, perceived as safe, and has parking.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Date/Timing</td>
      <td>Set a date and time that is convenient for the majority of prospective participants.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Facilitator</td>
      <td>Involve the facilitator in setting the agenda.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Agenda</td>
      <td>Include information about each item, the name of the person who is introducing the item, and a time limit. Discuss easy items first, followed by hard and then moderate decisions.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Food</td>
      <td>Offer food and drinks in ways that are least disruptive.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Recruitment/Turnout</td>
      <td>Use word-of-mouth and written meeting announcements, and remind people a few days prior to the meeting.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Meeting Roles</td>
      <td>Assign roles ahead of time, including facilitator, note taker, timekeeper, presenter, and greeter.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Room Logistics</td>
      <td>Set up chairs, AV equipment, flipchart, sign-in table, food/drink, and microphone early enough to check the equipment.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Background Materials</td>
      <td>Prepare background materials about pending decisions and preliminary proposals to discuss.</td>
    </tr>
    <tr>
      <td>Meeting</td>
      <td>Timeliness</td>
      <td>Begin and end the meeting on time.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Welcome,Introduce</td>
      <td>Begin with a warm welcome and introductions to set a positive tone, regardless of the turnout.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Agenda</td>
      <td>Review the agenda with the group and make changes as needed.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Meeting Rules</td>
      <td>Explain any rules, including decision-making rules.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Discussion</td>
      <td>Encourage discussion of various viewpoints; encourage all to speak by drawing out quieter people, limiting those who dominate, and encouraging respect for viewpoints; summarize; and bring closure to discussion.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Focus</td>
      <td>Bring the group back to the agenda if the discussion wanders.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Endings</td>
      <td>Summarize meeting results, decisions, and needed follow-up. Thank people for attending.</td>
    </tr>
    <tr>
      <td>Follow-up</td>
      <td>Notes</td>
      <td>Prepare and disseminate meeting notes quickly.</td>
    </tr>
    <tr>
      <td> </td>
      <td>Think people</td>
      <td>Contact people, especially new people, to thank them for their contribution to the meeting, to encourage follow-up on commitments for action, and to encourage them to attend the next meeting.</td>
    </tr>
  </tbody>
</table>

<p>Source: Adapted from Bobo, Kendall, &amp; Max, 2010; Minieri &amp; Getsos, 2007</p>

<p>In task groups, using decision-making processes that promote full participation is important. Decision-making for groups can be handled in many ways, including the <strong>parliamentary procedures</strong>, sometimes known as <strong>Robert’s Rules of Order</strong>, and <strong>consensus decision-making</strong>. Quick Guide 35 provides an overview of Robert’s Rules of Order, and Quick Guide 36 provides an overview of consensus decision-making. Both types of decision-making processes are common in task groups, depending on the context of the work. Social workers need to be familiar with decision-making processes to fully participate as individuals and to help others participate.</p>

<p>Recruitment of new participants is an ongoing and important community development skill. Participants involved in community development work are often volunteers, and recruiting, training, monitoring, and rewarding volunteers is important to the success of long-term goals. The most effective ways to recruit participants include focusing on people who are most likely to join, using a well-formed recruiting message, using multiple recruitment methods, providing orientation for new participants, and making it easy to join activities. Volunteer activities have to be calibrated to fit the skills, time, and interests of volunteers and be meaningful to them (Cnaan &amp; Rothman, 2008).</p>

<h3 id="quick-guide-35-utilizing-roberts-rules-of-order">QUICK GUIDE 35 Utilizing Robert’s Rules of Order</h3>

<p>Many formal groups, such as boards of directors, committees, and policy-making groups, often use some form of a formal decision-making process. Parliamentary procedures, or Robert’s Rules of Order, are often used because they are well known, help to maintain order, and allow actions to be taken in an expedient and consistent manner. Although the process can be quite complex, some groups utilize the general rules without learning the minutiae. Understanding the major concepts of parliamentary procedure is a critical social work skill for facilitating and participating in a meeting.</p>

<p>Robert’s Rules of Order provide a structured, democratic (majority rules) mechanism whereby formal groups can engage in efficient and fair decision-making. The following are major elements of the process:</p>

<ul>
  <li>The use of a motion to introduce a proposal. Any idea for the group’s consideration must be introduced as a motion (i.e., “I move that …”). Only one motion can be considered at a time.</li>
  <li>The seconding of a motion to move a proposal forward for discussion. A motion cannot move forward in the process unless someone other than the person who made the motion “seconds” the motion (i.e., “I second the motion”). Without a second, a motion dies and is not discussed.</li>
  <li>The use of open discussion to enable participants to present perspectives and ask questions about a motion. After a motion is made and seconded, the facilitator can open discussion about the motion, and group members can ask questions of the people who made and seconded the motion.</li>
  <li>Amendments to reflect revisions to an original motion based on the debate/discussion. During the discussion, one or more participants may offer an amendment to clarify or narrow the motion. This amendment must be voted on before the original motion is voted on. A majority vote is required to pass an amendment.</li>
  <li>Majority rules (i.e., a minimum of 51 percent of members agreeing) to establish a motion as a decision.</li>
</ul>

<p>Source: Adapted from Robert, Honemann, &amp; Balch, 2011</p>

<h3 id="quick-guide-36-utilizing-consensus-for-decision-making">QUICK GUIDE 36 Utilizing Consensus for Decision-Making</h3>

<p>Real change, at the individual, family, group, community, or organizational level, comes from individuals who are highly committed to a decision or direction in which they fully participated. Consensus decision-making, or a cooperative process in which all members develop and agree to support a decision that is in the best interests of the whole group, can be effective in situations in which the following conditions are present:</p>

<ul>
  <li>Participants feel a genuine stake in the decision.</li>
  <li>Participants share a common purpose and values.</li>
  <li>Participants trust each other.</li>
  <li>Participants are willing to put the best interests of the group over personal preferences.</li>
  <li>Participants can share their ideas and opinions freely, without fear of ridicule.</li>
  <li>Enough time is available for the process.</li>
  <li>Participants can engage in active listening and consider different points of view.</li>
</ul>

<p>After preparing for the meeting, the process helps meeting participants:</p>

<ul>
  <li>Explore the issue toward the goal of developing an informed, shared understanding of the facts and the issue.</li>
  <li>Establish decision criteria, including such factors as interests/needs that must be met, resource constraints, and possible ramifications of decisions.</li>
  <li>Develop and discuss a written preliminary proposal.</li>
  <li>Test for consensus, asking participants whether they can live with the proposal (original or amended), whether it meets the decision criteria, and whether it is the best decision possible.</li>
  <li>Reach agreement by restating the proposed decision and ensuring that participants can support the implementation of the proposal.</li>
</ul>

<p>Source: Adapted from Dressler, 2006</p>

<h1 id="a-generalist-approach-to-community-intervention">A Generalist approach to Community intervention</h1>

<p>Depending on the context of the community intervention, generalist social workers often integrate aspects of community organizing and community development activities into their practice. For example, social workers can help community members develop a shared identity, interpersonal bonds, skills for public discourse, the ability to determine priorities and work on common challenges together, as well as leadership skills. All of these must be developed for community change efforts to be possible. Social workers can play an important role in helping develop these prerequisites. Further, social workers who work primarily with individuals, families, and groups have opportunities to support the development of these skills and to encourage people to participate in community efforts.</p>

<p>Social workers can help build the capacity of individuals to engage in community interventions in many ways. At the interpersonal level, social workers emphasize collaboration with both clients and community members to optimize rights, strengths, and capabilities. Social workers discuss power and control with clients and community members to increase awareness of these dynamics in everyday life and in community activities. As first suggested by Paulo Freire (1973), educating people about social conditions, patterns of resource distribution, oppression, and other social and environmental realities, and using respectful discussion and questioning, can help and support people to engage in collective action.</p>

<p><strong>Social workers strive to provide evidence-based interventions in community practice</strong>. Creating a body of research to inform evidence-based practice has proven challenging due to the complexity of community interventions, the difficulties of community research, and many organizations’ lack of capacity to engage in research. Yet social workers must conduct or locate research before intervening. Quick Guide 37 lists sample resources for locating evidence on community practice interventions. Exhibit 11.6 provides research findings about the most effective community intervention activities that social workers undertake (Ohmer &amp; Korr, 2006).</p>

<p>Social workers also engage in social planning efforts when they participate in proposing that elected officials or human service planning councils take action. They engage by writing letters, testifying to committees, becoming members of planning committees, and/or organizing others to lobby planning councils. As part of that process, social workers can carefully create opportunities for community members to participate so that their participation is meaningful and effective, rather than a token effort to “involve” residents. For example, social workers can invite community residents to testify at public hearings about proposals to close schools in their neighborhoods and help prepare them to testify. Social workers can also seek resident involvement in neighborhood committees and work to ensure that residents can voice their opinions, participate fully in decision-making, and assist to implement decisions. Social workers can also make connections between people in disparate situations, so that the needs of individuals are connected to broader efforts and wider structures. For example, if a social worker encounters a resident whose child has lead poisoning, the social worker may be able to link this “case” to a broader “cause” of a community problem with lead poisoning due to the old housing stock in the neighborhood and the reluctance of landlords to remediate the lead in their units. Social workers can also invite residents to participate in community-wide efforts to alleviate and prevent the problem, such as lead paint screenings in schools and programs to help tenants test for lead paint in their apartments.</p>

<h3 id="examples-of-efforts-to-promote-evidence-based-community-practice">Examples of Efforts to Promote Evidence-Based Community Practice</h3>

<ul>
  <li>Children, Families, and Communities</li>
</ul>

<p>Harvard Family Research Project, Harvard Graduate School of Education. The Education Resources Information Center (ERIC) contains new studies on programs and policies, particularly those focused on children, families, and communities. Available at https://eric.ed.gov/.</p>

<p>Society for Child and Family Policy and Practice, Division 37 of the American Psychological Association (APA). The Society provides information about services and service structures for children and youth. See www.apa.org/about/division/div37.</p>

<ul>
  <li>Community Change</li>
</ul>

<p>The Aspen Institute report, Building Knowledge about Community Change, summarizes key learning about how to evaluate community change initiatives and how to identify strategies for enhancing the evidence base for improving conditions in low-income communities. Available at www.aspeninstitute. org/publications/building-knowledge-about-community-change-moving-beyond-evaluation/.</p>

<p>Society for Community Research and Action, Division 27 of the American Psychological Association (APA). The Society provides access to research on community interventions. See www.apa.org/about/ division/div27.</p>

<ul>
  <li>Early Childhood, health Care, and housing</li>
</ul>

<p>The Centers for Disease Control and Prevention’s The Guide to Community Preventive Services includes systematic reviews of interventions in early childhood development programs, culturally competent health care, and housing. Available at www.thecommunityguide.org.</p>

<ul>
  <li>General evidence-Based resources for Community practice</li>
</ul>

<p>The Campbell Collaboration promotes positive social change through the production and use of systematic reviews and other evidence synthesis for evidence-based policy and practice. Available at campbellcollaboration.org.</p>

<p>Laura and John Arnold Foundation Evidence-Based Policy and Innovation. This nonprofit organization is committed to evidence-based social policies and programs. See www.arnoldventures. org/work/evidence-based-policy.</p>

<ul>
  <li>Housing</li>
</ul>

<p>U.S. Department of Housing and Urban Development (HUD). HUD has done much research on housing issues, and reports are available at www.huduser.gov/portal/reports/home.html.</p>

<ul>
  <li>Mental health in Communities</li>
</ul>

<p>National Registry of Evidence-based Programs and Practices (NREPP). Sponsored by the Substance Abuse and Mental Health Services Administration, NREPP is an online, searchable registry of evidence-based mental health and substance use interventions. Available at www.samhsa.gov/ebp-resource-center</p>

<ul>
  <li>Violence prevention</li>
</ul>

<p>The Center for the Study and Prevention of Violence (CSPV), University of Colorado at Boulder provides research on effective violence prevention. Available at https://cspv.colorado.edu/</p>

<p>Sources: Updated from Ohmer, 2008 and Thyer, 2008</p>

<h3 id="exhibit-116-effectiveness-of-community-practice">EXHIBIT 11.6 Effectiveness of Community Practice</h3>

<p>Community practice interventions are often complex, with multiple community locations, goals, and activities that make them difficult to evaluate. However, scholars suggest that community practice interventions:</p>

<ul>
  <li>
    <p>have a positive impact on facilitating citizen participation, including increasing collective action and community involvement;</p>
  </li>
  <li>
    <p>facilitate personal and collective competencies among participants, including increasing self-esteem, personal and community empowerment, leadership and political skills, and community pride and belonging;</p>
  </li>
  <li>
    <p>have a positive impact on improving the physical, social, and economic conditions of communities (i.e., creating and improving affordable housing; increasing home ownership, improving infrastructure and physical appearance; increasing income, investment, and employment; improving high school education; and reducing the sale of alcohol to and its use among young people);</p>
  </li>
  <li>
    <p>are often unable to find statistically significant effects (many studies indicate that interventions do not affect the physical and economic attributes of the communities); and</p>
  </li>
  <li>
    <p>increase the likelihood of involving the community organizing efforts of older female residents, African Americans, and Hispanics.</p>
  </li>
</ul>

<p>other factors that help to explain and predict citizen participation include interest in the problems the intervention was attempting to solve, neighborhood perceptions and relationships, and length of residency.</p>

<p>Community practice interventions more easily improve citizen participation and associated benefits (i.e., improving collective action and personal and political skills of participants) than they improve complex physical, social, and economic problems in poor communities. Therefore, social work strategies should simultaneously focus on developing ways to strengthen citizen participation and on building the capacity of individuals.</p>

<p>Source: Ohmer &amp; Korr, 2006</p>

<h1 id="evaluation-of-social-work-practice-with-communities">evaluation of social work practice with Communities</h1>

<p>Similar to evaluation with individuals, families, and groups, evaluation of social work community practice interventions can assess the process along the way (i.e., <strong>process evaluation</strong>); the extent to which goals were achieved (i.e., <strong>outcome evaluation</strong>); and the social worker’s skills in the intervention phase. Evaluation seeks to determine the value of the intervention and differs from simply monitoring one’s practice (Netting et al., 2017). Just as the community change effort is a collaborative process, so too is the evaluation. Community participation is important throughout the change effort to empower participants. Similarly, community members who are able to collaborate as equal partners in evaluation are likely to feel a deserved sense of ownership in the process.</p>

<p>The evaluation process begins as an element of the intervention design and may be predetermined by an organization, a funder, or a public entity. It requires social workers and community members first to determine: (1) whether both the process and outcomes will be evaluated, (2) the ways in which the process and outcomes will be evaluated, and (3) the means by which data will be collected as the basis for the evaluation. Evaluation of community change efforts may include documentation of individual, interpersonal, and community processes and outcomes. Preferably, the evaluation process will include both qualitative and quantitative data to provide information about the process of community change and progress on the desired outcomes at the individual, interpersonal, and community levels.</p>

<h1 id="critical-considerations-in-community-intervention-termination-evaluation-and-follow-up">Critical Considerations in Community intervention, termination, evaluation, and follow-up</h1>

<p>Community social work practice, including the intervention, termination, evaluation, and follow-up phases, offers many rewards and challenges. One challenging aspect of some types of community social work practice is long hours. For example, community social work practice can involve working during the day with professionals in organizations and institutions and in the evenings and on weekends with community participants. Efforts to change institutions, policies, and practices can take a long time, and there may be many setbacks along the way. Tangible rewards and successes for the work may be few and far between, which can lead to burnout unless social workers have a solid understanding of practice at the community level (Rubin &amp; Rubin, 2008).</p>

<p>Rewards include the satisfaction of working to change environments to better meet the needs of, and to provide empowerment opportunities for, individuals and communities. Many community practitioners appreciate the ability to partner with individuals, families, and groups to better their lives, while avoiding the view of persons as clients, which can involve diagnostic labels, treatment plans, and a primarily individualistic perspective. In community practice, community members are involved in making decisions that affect their lives, sometimes for the first time. Helping people gain their voices and work toward large-scale social change is work toward social justice. The variety of tasks completed, the joy of successes, and the autonomy and flexibility are other factors that attract social workers to community practice (Rubin &amp; Rubin, 2008).</p>

<p>Community practitioners must have the energy for long-term work and must be able to see value in the process and effort involved, rather than just in the outcomes. The occasional victories, even short-term or small, along with the benefits of working with and on behalf of entire communities, must be enough to sustain community practitioners. Community practitioners must celebrate small gains. They must often work diligently on short-term or immediate goals, while keeping the larger, systemic, institutional change in focus.</p>]]></content><author><name></name></author><category term="Social work Practice" /><category term="研究" /><summary type="html"><![CDATA[書籍 Birkenmaier, J., &amp; Berg-Weger, M. (2020). The practice of generalist social work. Routledge.P496-527]]></summary></entry><entry><title type="html">主観的健康感がボランティア活動参加に及ぼす影響に対する友人関係の調整効果</title><link href="http://localhost:4000/%E8%AA%BF%E6%95%B4%E5%8A%B9%E6%9E%9C/2023/04/14/%E5%81%A5%E5%BA%B7%E3%81%8C%E3%83%9C%E3%83%A9%E3%83%B3%E3%83%86%E3%82%A3%E3%82%A2%E5%8F%82%E5%8A%A0%E3%81%AB%E5%8F%8A%E3%81%BC%E3%81%99%E5%BD%B1%E9%9F%BF-%E5%8F%8B%E4%BA%BA%E9%96%A2%E4%BF%82%E3%81%AE%E8%AA%BF%E6%95%B4%E5%8A%B9%E6%9E%9C.html" rel="alternate" type="text/html" title="主観的健康感がボランティア活動参加に及ぼす影響に対する友人関係の調整効果" /><published>2023-04-14T00:00:00+09:00</published><updated>2023-04-14T00:00:00+09:00</updated><id>http://localhost:4000/%E8%AA%BF%E6%95%B4%E5%8A%B9%E6%9E%9C/2023/04/14/%E5%81%A5%E5%BA%B7%E3%81%8C%E3%83%9C%E3%83%A9%E3%83%B3%E3%83%86%E3%82%A3%E3%82%A2%E5%8F%82%E5%8A%A0%E3%81%AB%E5%8F%8A%E3%81%BC%E3%81%99%E5%BD%B1%E9%9F%BF%20%E5%8F%8B%E4%BA%BA%E9%96%A2%E4%BF%82%E3%81%AE%E8%AA%BF%E6%95%B4%E5%8A%B9%E6%9E%9C</id><content type="html" xml:base="http://localhost:4000/%E8%AA%BF%E6%95%B4%E5%8A%B9%E6%9E%9C/2023/04/14/%E5%81%A5%E5%BA%B7%E3%81%8C%E3%83%9C%E3%83%A9%E3%83%B3%E3%83%86%E3%82%A3%E3%82%A2%E5%8F%82%E5%8A%A0%E3%81%AB%E5%8F%8A%E3%81%BC%E3%81%99%E5%BD%B1%E9%9F%BF-%E5%8F%8B%E4%BA%BA%E9%96%A2%E4%BF%82%E3%81%AE%E8%AA%BF%E6%95%B4%E5%8A%B9%E6%9E%9C.html"><![CDATA[<h1 id="ロジットモデルによる結果推定">ロジット・モデルによる結果推定</h1>

<p><img src="/images/230414.png" alt="image description" width="800" height="600" /></p>

<table>
  <thead>
    <tr>
      <th>变量</th>
      <th style="text-align: center">B</th>
      <th style="text-align: center">標準偏差</th>
      <th style="text-align: center">有意差</th>
      <th style="text-align: center">EXP（B）</th>
      <th style="text-align: center">上限</th>
      <th style="text-align: center">下限</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>主観的健康感ref:不良</td>
      <td style="text-align: center">.172</td>
      <td style="text-align: center">.070</td>
      <td style="text-align: center">.014</td>
      <td style="text-align: center">1.188</td>
      <td style="text-align: center">1.036</td>
      <td style="text-align: center">1.361</td>
    </tr>
    <tr>
      <td>友人関係</td>
      <td style="text-align: center">-.044</td>
      <td style="text-align: center">.025</td>
      <td style="text-align: center">.079</td>
      <td style="text-align: center">.957</td>
      <td style="text-align: center">.912</td>
      <td style="text-align: center">1.005</td>
    </tr>
    <tr>
      <td>交差項</td>
      <td style="text-align: center">.045</td>
      <td style="text-align: center">.020</td>
      <td style="text-align: center">.024</td>
      <td style="text-align: center">1.046</td>
      <td style="text-align: center">1.006</td>
      <td style="text-align: center">1.087</td>
    </tr>
    <tr>
      <td>年齢</td>
      <td style="text-align: center">-.067</td>
      <td style="text-align: center">.026</td>
      <td style="text-align: center">.009</td>
      <td style="text-align: center">.935</td>
      <td style="text-align: center">.889</td>
      <td style="text-align: center">.983</td>
    </tr>
    <tr>
      <td>收入</td>
      <td style="text-align: center">.242</td>
      <td style="text-align: center">.026</td>
      <td style="text-align: center">.000</td>
      <td style="text-align: center">1.274</td>
      <td style="text-align: center">1.210</td>
      <td style="text-align: center">1.340</td>
    </tr>
    <tr>
      <td>性别ref:男</td>
      <td style="text-align: center">.064</td>
      <td style="text-align: center">.050</td>
      <td style="text-align: center">.198</td>
      <td style="text-align: center">1.066</td>
      <td style="text-align: center">.967</td>
      <td style="text-align: center">1.176</td>
    </tr>
    <tr>
      <td>学歴ref:中学校未満</td>
      <td style="text-align: center">.396</td>
      <td style="text-align: center">.054</td>
      <td style="text-align: center">.000</td>
      <td style="text-align: center">1.485</td>
      <td style="text-align: center">1.336</td>
      <td style="text-align: center">1.651</td>
    </tr>
    <tr>
      <td>民族ref:汉民族</td>
      <td style="text-align: center">1.349</td>
      <td style="text-align: center">.155</td>
      <td style="text-align: center">.000</td>
      <td style="text-align: center">3.855</td>
      <td style="text-align: center">2.845</td>
      <td style="text-align: center">5.224</td>
    </tr>
    <tr>
      <td>宗教ref:無宗教</td>
      <td style="text-align: center">-.098</td>
      <td style="text-align: center">.100</td>
      <td style="text-align: center">.327</td>
      <td style="text-align: center">1.103</td>
      <td style="text-align: center">.907</td>
      <td style="text-align: center">1.343</td>
    </tr>
    <tr>
      <td>定数</td>
      <td style="text-align: center">-.685</td>
      <td style="text-align: center">.103</td>
      <td style="text-align: center">.000</td>
      <td style="text-align: center">.504</td>
      <td style="text-align: center"> </td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<h1 id="調整効果図">調整効果図</h1>

<p><img src="/images/230308.png" alt="image description" width="800" height="600" /></p>]]></content><author><name></name></author><category term="調整効果" /><category term="研究" /><summary type="html"><![CDATA[ロジット・モデルによる結果推定]]></summary></entry><entry><title type="html">プログラム評価における媒介効果</title><link href="http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/13/%E5%AA%92%E4%BB%8B%E5%8A%B9%E6%9E%9C.html" rel="alternate" type="text/html" title="プログラム評価における媒介効果" /><published>2023-04-13T00:00:00+09:00</published><updated>2023-04-13T00:00:00+09:00</updated><id>http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/13/%E5%AA%92%E4%BB%8B%E5%8A%B9%E6%9E%9C</id><content type="html" xml:base="http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/13/%E5%AA%92%E4%BB%8B%E5%8A%B9%E6%9E%9C.html"><![CDATA[<script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.0.2/+esm'; mermaid.initialize({ startOnLoad: true }); </script>

<h1 id="書籍">書籍</h1>
<p>安田節之・渡辺直登（2008）『プログラム評価研究の方法』（臨床心理学研究法 / 下山晴彦編, 7）新曜社.</p>

<h1 id="媒介効果とは何か直接的効果">媒介効果とは何か（直接的効果）</h1>
<p>媒介効果（mediation effect）とは、原因と結果の間にあって双方の関係を仲介する要因の効果を意味する。多くの介入では、プログラム自体を原因とし、プログラム参加者へのアウトカム、つまり「結果」への直接的な効果が測定される。しかし、このような因果関係図式に基づいたアウトカムの測定では、プログラムの何が、どのような経路を経てアウトカムに影響を及ぼしたか、という過程は明らかにはならない。つまり、プログラムの過程をブラックボックス化させてしまい、プログラムの介入の効果があったかどうか、効果の大きさはどの程度であったか、という直接的な因果関係のみが考察される。</p>

<div class="mermaid">
flowchart LR
    プログラム原因--&gt;|直接的効果|アウトカム結果
</div>

<h1 id="媒介効果とは何か媒介効果">媒介効果とは何か（媒介効果）</h1>

<p>一方、プログラム自体が原因であることに変わりはないが、プログラムからアウトカムへの影響（c係数）は、媒介要因を通じて起こると想定している。つまり、アウトカムは原因からの影響（a係数）のほか、媒介要因からの影響（b係数）も受けることにある。</p>

<div class="mermaid">
flowchart LR
    プログラム原因--&gt;|a|媒介要因
    媒介要因--&gt;|b|アウトカム結果
    プログラム原因--&gt;|c|アウトカム結果
</div>

<h1 id="媒介効果とは何か媒介効果の影響">媒介効果とは何か（媒介効果の影響）</h1>
<p>媒介効果の影響が統計学的に同定されるためには以下の条件を満たす必要がある。</p>
<ol>
  <li>プログラムが媒介要因に影響を及ぼし（パス係数aが統計的に有意）</li>
  <li>媒介要因がプログラムのアウトカムに影響を及ぼし（パス係数bが統計的に有意）</li>
  <li>プログラムと媒介要因との関係（パス係数a）及び媒介要因とアウトカムとの関係（バス係数b)が統計的にコントロールされることにより、もともとのプログラムとアウトカムの直接的な関係が軽減されるあるいは消滅する（パス係数cが有意から有意でなくなる）
（Baron &amp; Kenny, 1986）</li>
</ol>

<h1 id="完全媒介">完全媒介</h1>
<p>媒介分析において、完全媒介とは、原因と結果の間にある媒介変数が、原因と結果の関係に完全に関与することを指します。つまり、原因が結果に与える影響は、その媒介変数を通じて完全に説明できるということです。</p>

<div class="mermaid">
flowchart LR
    X--&gt;|a|M
    M--&gt;|b|Y
    X-.-&gt;|c|Y
</div>

<h1 id="部分媒介">部分媒介</h1>
<p>不完全媒介とは、媒介変数が原因と結果の間の関係に一部しか関与していない場合を指します。つまり、媒介変数が原因と結果の関係を部分的に説明することができるが、原因と結果の関係の一部は、媒介変数とは独立して存在するということです。A-.-&gt;B</p>

<div class="mermaid">
flowchart LR
    X--&gt;|a|M
    M--&gt;|b|Y
    X--&gt;|c|Y
</div>

<h1 id="媒介効果測定の重要性">媒介効果測定の重要性</h1>
<p>プログラム評価において、媒介効果を測定する理由には、以下の3つがある。</p>
<ol>
  <li>プログラムがどういう過程を経て実際に変化（効果）をもたらしているかがチェックできる。</li>
  <li>プログラムのどこをどのように強化・改善すべきかを知ることができる。</li>
  <li>もしプログラムが効果をもたらしていなかった場合には媒介要因の影響が後から出現するかあるいは媒介要因はアウトカムに関係のないものであったかを判断できる。
（MacKinnon &amp; Dwyer, 1993)</li>
</ol>

<h1 id="例としてのエイズ感染予防プログラム">例としてのエイズ感染予防プログラム</h1>
<ol>
  <li>プログラム（キャンペーン）により、エイズを予防する知識が増せば、エイズウイルスへの感染が減ることが予想される。つまり、プログラム（原因）は、プログラムへの参加者のエイズに関する知識（媒介要因）を向上させ、その結果、エイズウイルスへの感染（結果）を防ぐことにつながると仮定ができる。このように、プログラム介入によってターゲットとなる媒介要因に変化が起こったかどうか、というのを確認するのである。</li>
</ol>
<div class="mermaid">
flowchart LR
    プログラム--&gt;|a|知識の向上
    知識の向上--&gt;|b|感染の予防
    プログラム--&gt;|c|感染の予防
</div>

<ol>
  <li>もしこのエイズ感染予防プログラムの効果が思うように上がっていない場合には、キャンペーンの対象者に今まで以上にエイズの知識の啓蒙・伝達を行い、感染の防止に努めることが考えられる。ここでは、媒介要因と仮定される対象者の知識向上を促すプログラムを強化し、感染を防ぐようにできる。</li>
  <li>プログラム実際には感染予防に効果をもたらしていない場合には、③の可能性がうかがえる。つまり、エイズ感染予防の知識向上は、エイズ感染の低減につながるまでにプログラムの実施期間以上の時間を要する。または関係がないという可能性である。例えば、感染を低減するためには、知識ではなく、行動的な側面に焦点を当てたものが必要だったのかもしれない。つまり、プログラムの仮説上の設定ミスあるいは理論上の問題。</li>
</ol>]]></content><author><name></name></author><category term="プログラム評価" /><category term="媒介効果" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">プログラム評価における調整効果</title><link href="http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/13/%E8%AA%BF%E6%95%B4%E5%8A%B9%E6%9E%9C.html" rel="alternate" type="text/html" title="プログラム評価における調整効果" /><published>2023-04-13T00:00:00+09:00</published><updated>2023-04-13T00:00:00+09:00</updated><id>http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/13/%E8%AA%BF%E6%95%B4%E5%8A%B9%E6%9E%9C</id><content type="html" xml:base="http://localhost:4000/%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E8%A9%95%E4%BE%A1/2023/04/13/%E8%AA%BF%E6%95%B4%E5%8A%B9%E6%9E%9C.html"><![CDATA[<script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.0.2/+esm'; mermaid.initialize({ startOnLoad: true }); </script>

<h1 id="書籍">書籍</h1>
<p>安田節之・渡辺直登（2008）『プログラム評価研究の方法』（臨床心理学研究法 / 下山晴彦編, 7）新曜社.</p>

<h1 id="調整効果">調整効果</h1>
<p>媒介要因は、プログラムと結果の因果連鎖（causal link）の間に位置する要因を意味する。一方、調整要因は、プログラムとの交互作用（interaction）によって結果に影響を及ぼす要因を指す。例えば、男性と女性によってプログラムの効果が違う場合。ここでは、プログラム（原因）とアウト
カム（結果）との関係が、性別という要因によって調整されている。つまり、男性（a係数）と女性（b係数）の値が性別によって異なる場合、「性別」が調整要因となる。</p>

<h1 id="性别">性别</h1>
<p>男性</p>
<div class="mermaid">
flowchart LR
    プログラム原因--&gt;|a|アウトカム結果
</div>

<p>女性</p>
<div class="mermaid">
flowchart LR
    プログラム原因--&gt;|b|アウトカム結果
</div>

<h1 id="調整効果の査定">調整効果の査定</h1>
<p>一般に、調整要因（変数）のアウトカムは、プログラムと調整要因の交互作用（c係数）の統計的有意性と効果量によって査定される（Baron &amp; Kenny, 1986）。</p>
<div class="mermaid">
flowchart LR
    プログラム原因--&gt;|a|アウトカム結果
    調整要因--&gt;|b|アウトカム結果
    プログラムと調整要因の交互作用--&gt;|c|アウトカム結果
</div>]]></content><author><name></name></author><category term="プログラム評価" /><category term="調整効果" /><summary type="html"><![CDATA[]]></summary></entry></feed>