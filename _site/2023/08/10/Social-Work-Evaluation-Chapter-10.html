<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Chapter 10 Analyzing Evaluation Data | 同志社大学社会学研究科　陳凌雲</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Chapter 10 Analyzing Evaluation Data" />
<meta name="author" content="JAMES R. DUDLEY" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="PART VI" />
<meta property="og:description" content="PART VI" />
<link rel="canonical" href="https://mrlyn20.github.io/Lyn/2023/08/10/Social-Work-Evaluation-Chapter-10.html" />
<meta property="og:url" content="https://mrlyn20.github.io/Lyn/2023/08/10/Social-Work-Evaluation-Chapter-10.html" />
<meta property="og:site_name" content="同志社大学社会学研究科　陳凌雲" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-08-10T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Chapter 10 Analyzing Evaluation Data" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"JAMES R. DUDLEY"},"dateModified":"2023-08-10T00:00:00+09:00","datePublished":"2023-08-10T00:00:00+09:00","description":"PART VI","headline":"Chapter 10 Analyzing Evaluation Data","mainEntityOfPage":{"@type":"WebPage","@id":"https://mrlyn20.github.io/Lyn/2023/08/10/Social-Work-Evaluation-Chapter-10.html"},"url":"https://mrlyn20.github.io/Lyn/2023/08/10/Social-Work-Evaluation-Chapter-10.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/Lyn/assets/css/style.css?v=b989e15f690c6dbe3b551d2fbbbc17f3503d289c">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/Lyn/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="https://mrlyn20.github.io/Lyn/">同志社大学社会学研究科　陳凌雲</a></h1>

        

        <p>地域福祉とソーシャルワーク評価について学びます。</p>

        
        <p class="view"><a href="https://github.com/MrLyn20/Lyn">View the Project on GitHub <small>MrLyn20/Lyn</small></a></p>
        

        

        
      </header>
      <section>

      <small>10 August 2023</small>
<h1>Chapter 10 Analyzing Evaluation Data</h1>

<p class="view">by JAMES R. DUDLEY</p>

<p><strong>PART VI</strong></p>

<p>Final Steps in Completing an Evaluation</p>

<p>Evaluations are not complete until two additional major tasks are addressed. Chapter 10 describes the process of analyzing the data obtained from an evaluation. Data analysis is discussed for qualitative and quantitative findings. This chapter also addresses data analysis when both qualitative and quantitative findings are collected. The final task of an evaluation is covered in Chapter 11 and involves preparing and disseminating reports of findings.</p>

<h1 id="chapter-10-analyzing-evaluation-data">CHAPTER 10 Analyzing Evaluation Data</h1>

<p>James R. Dudley and Jeffrey Shears</p>

<p><em>How do we transform evaluation data into useful information?</em></p>

<p>The analysis of evaluation data comes next in the evaluation process. Analyzing the data begins in step 5 (implement the evaluation) and continues into step 6 (prepare a written or oral report) of the Seven Evaluation Steps. In step 5, once quantitative data are collected, they are coded and entered into a computer program such as SPSS (Statistical Package for the Social Sciences) and prepared for analysis. Qualitative data are usually prepared for analysis in narrative form. In step 6, the data are analyzed and transformed into understandable findings and recommendations for stakeholders.</p>

<p>Although the basic principles of data analysis are virtually the same for evaluations and other kinds of research, differences are evident in emphasis and use. Such differences are the primary focus of this chapter. Data analysis is also closely linked to the topic of the next chapter, writing a report and disseminating the findings. The choice of which data analysis tools to use depends on the kind of report and dissemination strategy that are most helpful to the stakeholders and others interested in the results.</p>

<h2 id="formative-or-summative-evaluations-and-data-analysis">FORMATIVE OR SUMMATIVE EVALUATIONS AND DATA ANALYSIS</h2>

<p>Evaluations depend on quantitative and qualitative research methods and some-times involve both. As discussed frequently in previous chapters, the methods used depend on the evaluation’s purpose and the stage of program or practice development in which they occur. One way to begin to decide whether to mostly use quantitative or qualitative data analysis is to ask whether the evaluation is formative or summative.</p>

<h3 id="formative-evaluations">Formative Evaluations</h3>

<p>As mentioned in Chapter 2, formative evaluations mostly focus on planning for a new program or practice intervention or improving its implementation. Outcomes evaluations are also possible but only in a tentative way. Formative evaluations tend to be exploratory in nature and may use either qualitative or quantitative methods, or both, depending on their purposes. Formative evaluations are typically conducted by the agency administering the intervention, which allows for considerable flexibility in choosing the methods of data collection and analysis. Formative evaluations do not require one specific type of procedure, as they can be conducted to identify small glitches in programs, breakdowns in delivering services, or an unanticipated drifting away from the original program design. Also, the links can be explored between the interventions and client outcomes to determine how well the intervention seems to be succeeding in helping clients reach their goals.</p>

<p>Examples of  formative evaluations  include a needs assessment  questionnaire with forced-response and open-ended questions, or observations of interactions between clients and practitioners, management strategies, practice philosophies, or costs associated with a program. A more detailed example of a formative evaluation may help. An agency wanted to understand why a program for eating disorders for teenage girls has not been successful in having participants complete the twelve week program; only one fourth of these teenagers participated long enough to complete the treatment. A formative evaluation can provide some meaningful information to finetune this program. Here exploring questions that are critical of the program could be beneficial in identifying glitches in the delivery of services. Conducting a more in-depth evaluation of the clients and their needs, and obtaining a profile of those who are successful and those who fail to complete the program are important examples of a formative evaluation.</p>

<h3 id="summative-evaluations">Summative Evaluations</h3>

<p>Summative evaluations focus on the outcomes of programs and practice interventions and attempt to answer the ultimate question: Did the intervention reach its goals? These evaluations have a finality to them because they attempt to measure whether an intervention was effective. Summative evaluations are also typically conducted by an external agent, such as an independent evaluator or a governmental agency, to ensure that they are objective. Further, they primarily depend on choosing from a more limited set of research design options, such as a quasi-experimental or experi-mental design. These designs work best when they use quantitative measurement instruments with strong psychometric properties.</p>

<p>If an evaluator’s question is to determine whether an intervention is effective, then this is considered a summative evaluation and thus draws from quantitative research methods. Summative evaluations seek to explain how the independent variable, a program or practice intervention, influences the dependent variables, the desired client outcomes. For example, does participation in a parental support group influence parental attitudes? Does group therapy improve marital stability?</p>

<p>Do parental education classes significantly improve parents’ ability to support early infant development?</p>

<h2 id="stages-of-interventions-and-data-analysis">STAGES OF INTERVENTIONS AND DATA ANALYSIS</h2>

<p>The stage of development of a program or practice intervention, whether planning, implementation, or outcome, also provides some clarity about what data collection and analysis methods are used and whether quantitative and/or qualitative data analyses are preferred.</p>

<h3 id="the-planning-or-input-stage">The Planning or Input Stage</h3>

<p>One period in which data analysis is needed is during the input or needs assessment stage of a proposed program or practice intervention. Needs assessments, as discussed in Chapter 6, are usually proposed when there is a concern that a new intervention may be important to consider for a specific target population. During this stage, various evaluation strategies, such as handing out questionnaires or analyzing secondary data, might be used to examine the specific needs of a community. Evaluators could also conduct focus groups or individual interviews with community members or consult other local experts to clarify where services are needed and how to better allocate resources. For example, a needs assessment of a new target population to be served by a county’s mental health system might involve interviewing prospective clients, giving out questionnaires to staff members who work with mental health clients, or conducting focus groups with other stakeholders who have a vested interest in an issue. These strategies can be qualitative or quantitative in nature. In general, it is wise to combine different strategies. Royse, Thyer, and Padgett (2009) discuss the importance of triangulation, or seeking multiple sources and comparing them. For example, interviews with people who are homeless, those who work with the homeless, and other key informants could all be conducted and compared to discover their similarities and differences.</p>

<p>Because of the varied nature of needs assessments, there are many types of data analyses that can be used to answer questions about the perceived needs of a community. Using focus groups with stakeholders, for example, could involve video or audio recording their responses to a few open-ended questions and analyzing the responses through a content analysis of the words that are used. Another possibility is to organize their responses into themes at a more abstract level to discover any possible associations among these themes. Lune &amp; Berg (2017) and others present other impressionistic approaches that can be used to evaluate qualitative data collected from evaluations.</p>

<p>In other instances, strategies for assessing the needs in a community can be quantitative in nature. The data resulting from a questionnaire with forced-response questions or existing secondary data collected from a previous evaluation are examples. Let’s assume that there is a concern that more public housing is needed for homeless people in a local area and that existing shelters keep detailed records on these people. An evaluator might be able to complete a needs assessment by developing a descriptive account or profile of the homeless population. The descriptive analysis could give some insight into the severity of the issue. The descriptive statistics could include simply calculating mean (average) scores along with standard deviations and ranges; or frequency distributions of such variables as age, gender, income, family structure, and length of time being homeless. This information would be informative to stakeholders, as it provides concrete data for making informed decisions about the needs of homeless people in the community.</p>

<p>Another possibility for data analysis is to compare the quantitative responses of two different groups of interviewed people. In this case, bivariate analysis would be used to help determine whether the responses of the two groups are significantly different and the amount of difference that is evident. Given the previous example of a needs assessment of prospective mental health clients, you may find that groups of prospective clients and mental health workers agree that specific types of services are needed in a satellite office somewhere in the county, but they may disagree about where the location should be. Using this information, the evaluator can report on how much consensus and difference exists in the responses of the two stakeholder groups.</p>

<h3 id="implementation-stage">Implementation Stage</h3>

<p>Another point in time in which data analysis is needed is during the implementation stage of an intervention. This is the stage in which the most varied types of evaluations can occur, as described in Chapter 8. A range of evaluation activities can be considered that are similar in some ways to those mentioned for the input stage. Evaluators could conduct focus groups, interviews, administer questionnaires, conduct observations, or undertake a combination of these activities. However, the intent of these evaluations is very different from those conducted during the input stage. Evaluations during the implementation stage are intended to find out whether an intervention works as planned; how well it works; and whether some components, such as a staffing issue, an intake glitch, or ambiguity in how a specific service is delivered, need to be changed or at least fine-tuned.</p>

<p>For example, an intake unit responsible for assessing and diagnosing clients’ problems or needs in a mental health outpatient clinic may, after their assessment, refer clients to various staff members and recommend various kinds of services; yet, the staff members may treat the recommendations differently than they are proposed. Some may ignore them, others may interpret them one way, and still others may interpret them another way. Clarity and consistency are needed in how intake referrals are prepared by intake workers, understood by the treatment team, and used by them.</p>

<p>Because of the varied nature of evaluations that occur during the implementation stage, there are several types of data analyses that can be used to answer questions about the intervention’s implementation. In the example of intake services at a mental health clinic, interviews with intake workers and treatment staff could include a set of open-ended questions to determine whether there are differences in their perspectives or understandings of procedures.</p>

<p>As an illustration, an open-ended question could be, “What do you see as the relationship between the recommendations provided by the intake workers and the decisions made by the treatment staff on how services are to be implemented?” Because these would be open-ended questions with qualitative responses, a content analysis could be conducted to categorize comments by keywords. The categories could then be cross-tabulated by whether they were made by intake or treatment workers. If an examination of specific words failed to reveal important distinctions in comments, then themes could be teased out of the comments at a more abstract level of analysis and cross-tabulated.</p>

<p>Another possibility for data analysis is to compare the quantitative responses of two different groups of interviewees. In the example of intake issues at a mental health clinic, a set of forced-response statements can be used. For example, “The intake workers’ recommendations are optional to implement,” and “The recommendations of intake workers are usually not feasible.” Response categories for such statements could include strongly agree, agree, disagree, and strongly disagree. In this case, bivariate analysis would help determine whether the responses of the two groups are different and, if so, by how much. Using this information, the evaluator can report on how much consensus or difference exists in the responses of the two stakeholder groups on the intake workers’ recommendations.</p>

<h3 id="outcome-stage">Outcome Stage</h3>

<p>Outcome evaluations emphasize different kinds of data analysis than those used during the planning and implementation stages. Outcome studies focus on the relationships between the intervention and the desired client outcomes. This focus is used not only to determine whether there is an association between the intervention and outcome but also to go a step further and determine whether the intervention caused the outcome measure to change favorably.</p>

<p>For example, in a substance abuse agency, the intervention might be group treatment. The evaluator wants to conduct an outcome evaluation to find out whether the intervention is responsible for any progress in the clients’ shortand long-term decreased substance use. An association will need to be found between the intervention and clients’ outcomes, as well as evidence of a causal relationship. Several types of controls are needed to determine whether there is a causal relationship between group treatment and client progress in discontinuing substance use. This could include being able to rule out other environmental events in the clients’ lives and other changes beyond external events. As was discussed in Chapter 9, a quasi-experimental or experimental group design would need to be used to identify any extraneous influences.</p>

<p>Data analysis strategies used in the outcome stage are the most complex, and several are reviewed later in the chapter to highlight when to use each strategy and what each strategy can accomplish. Each strategy also has limitations that are also reviewed. For example, some statistical strategies can be used to find out whether there is an association between an intervention and client outcomes. Other strategies can be used to determine whether a causal relationship exists and to what extent a causal relationship is evident.</p>

<h2 id="summary-of-pertinent-tools-for-qualitative-data-analysis">SUMMARY OF PERTINENT TOOLS FOR QUALITATIVE DATA ANALYSIS</h2>

<p>As reported earlier in this chapter, many evaluations are qualitative in nature or at least have qualitative components. They may collect data using open-ended questions, in-depth interviews, focus groups, unstructured observations, or existing data sources. Three qualitative data analysis strategies are especially relevant for such evaluations: case studies, reducing responses to fewer general categories, and theme analysis.</p>

<h3 id="case-studies">Case Studies</h3>

<p>Case studies involve one or a few research participants, but they are intended to provide stakeholders with insights into an entire group of people that the case example tends to represent. Case studies are detailed portrayals of an individual that can illuminate how a larger group of people that the individual represents is functioning. Case studies are also possible with other social units such as a cultural group, a family, or neighborhood (Dudley, 2011). Case studies can be prepared using many different research strategies, such as in-depth interviews, participant observation, and existing documents. Case studies typically do not go beyond a descriptive state. A few examples of case studies follow.</p>

<p>A Mexican boy recently immigrated to the United States with his mother, who was an undocumented worker. The boy was having extreme difficulty adapting to his peers and teachers in the public school in his new community. He was finally suspended. He ended up in the juvenile court system after torturing and killing stray animals. A case study describing his difficulties in adapting to a U.S. school could provide valuable insights into the struggles that other immigrant children like him may face as they attempt to adapt to a new environment in the United States.</p>

<p>A teenager living secretly with HIV was experiencing severe depression because she did not know what to do. She did not want to seek treatment from a health clinic because she was uninformed about the treatments that could be made available to her, and she did not want to disclose her condition to her family for fear of being severely punished or disowned. To make things even worse, she had no one she could trust to talk to about what she was going through. She began to have suicidal thoughts and contemplated running away. A case study described the challenges that this teenager faced and the obstacles associated with attempting to get help; it provided valuable insights into how teenagers with HIV or AIDS could be helped in the early stages of this disease.</p>

<p>Case studies can be an important approach to consider because they offer insights about what might be typical, challenging, or possibly misunderstood about specific types of clients who participate in a specific program. A case study could also illustrate how a client was especially successful in participating in and using the specific services of a program. Quality assurance evaluations use the case study approach to explore how a few randomly selected clients function in a program and interact with providers. Case studies also can be used in a needs assessment to gain a fuller understanding of the social circumstances of prospective clients. Case studies used to conduct a needs assessment are described in Chapter 6.</p>

<p>The data analysis involved in preparing a case study begins with careful planning. A case or cases need to be selected and specific topics for exploration chosen. Such decisions are determined by carefully considering what the evaluator and other stakeholders want to accomplish and what is practically possible. Other issues are important once data have been collected. A case description should be prepared and organized to tell the story about an individual (or a family, a group, a neighborhood) in the most effective way. Constructing an outline of the story can help identify the most important topics and further questions to ask. Another task is to determine when enough data has been collected on each chosen topic or when additional data is needed to fill out the story. As a case study is prepared and all the data on topics are assembled, another consideration is to discover and describe how the topics may be related so that the story can reflect a more holistic account and perspective. It should be kept in mind that preparing a case study is an effort in creativity and art as well as science. The important thing to remember is to tell the story that needs to be told in the most creative, accurate, compelling, and comprehensive way.</p>

<h3 id="reducing-responses-to-fewer-general-categories">Reducing Responses to Fewer General Categories</h3>

<p>Another strategy for analyzing qualitative data is to create a set of general categories (usually no more than ten) and assign research participants’ responses to these categories. This option is mostly used with data collection strategies that elicit brief qualitative answers. Qualitative methods that lend themselves to brief answers include open-ended questions in interviews and questionnaires, some questions asked in focus groups, and some semi-structured observations. Condensing many short responses into fewer general categories is useful for succinctly summarizing and organizing responses together that have similar meaning. For example, a client satisfaction study could have the question, “What do you like about living here?” asked of residents of a group home for people with developmental disabilities. The responses of a large sample would be too numerous to meaningfully grasp in their original form, so a smaller number of general categories of what they liked can be used, such as “types of food or beverages,” “social activities,” and “hygiene activities.” In some ways, this strategy is like a frequency distribution that summarizes the quantitative responses to a forced-response question. The major difference is that the quantitative responses are already in categorical form, whereas the qualitative responses are assigned to newly created categories based on their similarities (e.g., taking baths and brushing teeth can fit into the “hygiene activities” category). The new categories created from this qualitative strategy are usually at the prenominal level of measurement and could be used as a set of response categories for a forced response question in a later study.</p>

<p>In review, the steps involved in reducing qualitative responses of an open-ended question into fewer newly created categories are as follows (Dudley, 2011):</p>

<ol>
  <li>Prepare the responses for analysis by listing all of them together under the same question.</li>
  <li>Carefully review all the responses to a question to make sure that each one is understandable.</li>
  <li>Code responses using the same code for responses that are similar. Coding can be done using different letters in the left-hand margin or assorted colors.</li>
  <li>Group similar responses together based on your coding and give each group an overall name, which should generally describe each of the responses in a group (e.g. “hygiene activities” is the group name selected for responses such as “taking a bath,” “washing in warm water,” “brushing one’s teeth”).</li>
  <li>Count the number of responses that fall into each group.</li>
  <li>Report the results in quantitative form (e.g., hygiene activities, 27; social activities, 19; field trips, 7; etc.).</li>
  <li>Although the groups or newly created categories provide a useful summary of the responses, it may be helpful to add in parentheses a few examples of the responses.</li>
</ol>

<p>It is important to involve two evaluators who work independently of each other in creating the new categories and assigning responses to the categories. Two reviewers are used to ensure that there is inter-rater reliability.</p>

<h3 id="theme-analysis">Theme Analysis</h3>

<p>A third qualitative data analysis strategy is to identify common themes or patterns that are prevalent in narrative data. Theme analysis is useful in analyzing lengthy narrative material from data collection strategies such as participant-observation, in-depth interviews, focus groups, and unstructured observations. This strategy can also be used to analyze existing data from sources such case records and group treatment summaries that are in narrative form.</p>

<blockquote>
  <p><strong>Example of One Theme Deriving from the Responses of a Focus Group</strong></p>

  <p>A social work student (Leary, 2003) conducted a focus group study of volunteers of several churches that assisted homeless people in overnight stays at their churches during the winter months. When the volunteers began discussing the needs of the homeless people they witnessed, one theme they reported was that the homeless people wanted to have conversations with church volunteers who would listen to them and help them. They referred to this theme as a perceived need of homeless people to have meaningful discussions with volunteers. An abbreviated version of four of the comments found in the narrative that reflected this theme were as follows:</p>

  <ul>
    <li>I think one of the big needs is just to listen to them, be compassionate, and be there for them. I remember one evaluation meeting . . . when you have the homeless at the meeting with you, and I remember one of the men saying, “Just don’t feed us and leave us.”</li>
    <li>I would have loved to have one of the clergy members, deacons, priests, whatever, come and say an opening prayer with our people as it can be a show of force that this whole congregation is behind this program. . . . I think that is a really important part, to have a show of force, that clergy and staff support the program 100 percent. I think the guests actually get a sense of being special when we are all present.</li>
    <li>During Lenten season, when we would have Lenten meals on the same night as the shelter program, one of the things that was very interesting was that . . . they were much more likely to sit down with [one of the pastors]. Some of the issues that were shared . . . [included] offering the possibility of some counseling services and providing that there. I see that as caring, a very crucial kind of caring, to their situation, and, it’s definitely a help.</li>
    <li>A lot of them have a lack of self-confidence; they don’t believe in themselves anymore. Mainly they need someone to talk to, to reassure them they are still a human being and worth something.</li>
  </ul>
</blockquote>

<p>Conducting a theme analysis usually takes more time, covers more data, and can be more intellectually demanding than the previous two strategies. Like the strategy of reducing responses to fewer general categories, it is important to involve two independent evaluators in coding themes to ensure inter-rater reliability. If the two people disagree on a specific theme or how it is reflected in the narrative, a third person can be involved to help reach a consensus.</p>

<p>The major stages involved in conducting a theme analysis include the following (Dudley, 2011):</p>

<ol>
  <li>Prepare narrative data for analysis by typing it into electronic files.</li>
  <li>Carefully review and become familiar with all narrative data to make sure they are understandable.</li>
  <li>Assign a code (e.g., using symbols or magic markers) to each point in the narrative that reflects a more general theme.</li>
  <li>Group the coded narratives reflecting each theme on the same page (e.g., copy and paste to move data around the file).</li>
  <li>After carefully reviewing the narrative for each theme, give the theme an accurate label in a few words, a phrase, or a sentence.</li>
</ol>

<p>Theme analysis can involve additional steps, such as examining how the coded narrative of each theme might vary. For example, some of the narratives illustrating a theme may describe it in a positive way, while others describe it in negative terms. Identifying variations in how a theme is depicted can help further delineate meaning evident in the theme.</p>

<blockquote>
  <p><strong>Example of Identifying Variations in a Theme</strong></p>

  <p>In one student’s evaluation (Grantham, 2001) of the needs of patients in a hospice setting, several people identified the theme of having legal issues. On further examination, she found that variations in the comments about legal issues seemed to almost always refer to one of three things: financial problems, a legal will, or advanced directives.</p>
</blockquote>

<p>Another step that can be taken in a theme analysis involves capturing how different themes may be related to one another according to what the narrative suggests for each respondent. In these instances, relationships among themes can be explored in follow-up evaluations as hypotheses.</p>

<h2 id="summary-of-pertinent-tools-for-quantitative-data-analysis">SUMMARY OF PERTINENT TOOLS FOR QUANTITATIVE DATA ANALYSIS</h2>

<h3 id="descriptive-analyses">Descriptive Analyses</h3>

<p>It is important for evaluators to ask descriptive questions to understand more about the clients participating in a program. For example, what are the ages of the clients? What is the educational level of those who complete the program? What is the demographic profile of those who drop out of the program? Other descriptive questions might be, what is the level of stress of the clients? How many children attended the program? What is the educational level of participants who do not complete the program? And, how many sessions did both the fathers and mothers participate in together?</p>

<p>Descriptive analysis, or univariate analyses, is used to answer descriptive questions. The analyses are considered univariate because the descriptive question focuses on only one variable at a time. Univariate questions provide a means of describing something about the sample, such as its variability or range. The level of measurement of the variables in descriptive research will inform you about which univariate analyses to use. If the level of measurement of the variable is ordinal or nominal, for example, then percentages and frequency distributions are appropriate. If variables are at the interval/ratio level, then you can report the mean, range, and standard deviation. (See Table 10.1.)</p>

<p><img src="https://i.imgur.com/wl2WFRp.png" alt="Imgur" /></p>

<h3 id="levels-of-measurement">Levels of Measurement</h3>

<p>Nominal-level data are the simplest form in which numerical labels are used. Nominal data are categorical, and categories are distinct, mutually exclusive, and exhaustive of all possible circumstances (e.g., category of gender is either female or male). The categories or scores in nominal level data cannot be ranked, ordered, or manipulated mathematically (e.g., gender cannot be ranked with one being higher than the other).</p>

<p>A higher, more sophisticated level of measurement is ordinal-level data. Ordinal data are ranked or ordered from lowest to highest. A Likert scale that ranges from strongly disagree to strongly agree is an ordinal-level measures. The limitation with ordinal-level data is that there is no way to determine the distance between the various levels. For example, it is not possible to calculate a numeric distance between strongly disagree and disagree.</p>

<p>Although there are four levels of measurement, we do not usually differentiate between interval and ratio data. As a result, interval and ratio data are combined and presented together. Unlike nominal and ordinal measures, interval/ratio data permit classification, ranking, and signifying the exact distance between scores to be defined. Measures such as age in years, number of days on a job, or annual income are interval/ratio data.</p>

<h3 id="frequency-distributions">Frequency Distributions</h3>

<p>A frequency distribution is a statistic that describes the number of times that each value of a variable is observed in a sample. For example, in a question using a Likert scale, a frequency distribution describes how many participants selected “very satisfied,” “satisfied,” “dissatisfied,” and so on. Frequency distributions can be presented as actual frequencies or as percentages. Usually percentages are easier to grasp with the large samples. Often, however, frequency distributions list both frequencies and percentages. Frequency distributions are an appropriate statistic for use with categorical variables, including both nominal and ordinal variables. A frequency distribution could also be used with an interval/ratio variable if the interval/ratio responses are reconstituted and reduced to categories.</p>

<h3 id="measures-of-central-tendency">Measures of Central Tendency</h3>

<p>Three types of measures of central tendency are possible to use in evaluations: <em>mean,</em> <em>median, and mode</em>. The mode is the easiest measure to use, as it is the most frequently occurring response or value of a variable. In addition, the mode can be used regardless of the level of data measurement. The median is the middle point, or the fiftieth percentile of the data, and can be used with ordinal and interval/ratio data.</p>

<p>The most commonly reported measure of central tendency in research is the mean. Keep in mind that the mean score is an average and that its interpretation is limited, as it can be extremely sensitive to outliers. As a result, the mean score might not be very close to most scores in a sample. This can be problematic when the mean is reported by itself. For example, we often see the mean score reported for a standardized test, income, or housing prices. As a result, we should be mindful that stakeholders may need an explanation of a mean score and its limitations. When analyzing interval/ratio data, we should report not only the mean but also the range or standard deviation. This added measure will give stakeholders an idea of how the data are distributed and will make the mean score more meaningful.</p>

<h2 id="measures-of-variability">Measures of Variability</h2>

<p>Measures of variability can be either a range or a standard deviation. The <em>range</em> of scores is the lowest and highest score. The range is important to report when presenting interval/ratio data, as the mean score can be sensitive to extremes in scores. Knowing the range of scores can indicate some information about the distribution of scores and help determine whether the mean approximates most people in the sample. For example, if the mean age of mothers in a support group is thirty years, but the range is from nineteen to sixty-five years, the mean score may not be close to some of the women’s age in the group, as a few sixty-five-year-old women can substantially increase the mean age of the sample.</p>

<p>When you add the <em>standard deviation</em> to the presentation, it gives a clearer picture of the sample distribution. The standard deviation is a measure of variability that informs how all the scores relate to one another and to the mean. The standard deviation is useful in interpreting the percentage of scores that are close to the mean score. In normally distributed data, 68 percent of scores fall within plus or minus one standard deviation of the mean. Further, 95 percent of the scores fall within two standard deviations of the mean, and 99 percent fall within three standard deviations. Returning to the age of mothers, if the data are normally distributed and the mean age is thirty and the standard deviation is three, then you would expect that 68 percent of mothers are between the ages of twenty-seven and thirty-three (30 ± 3, where 3 equals one standard deviation). Similarly, 95 percent of mothers in the study are between twenty-four and thirty-six years old (30 ± 6, where 6 equals two standard deviations). Further, you could conclude that 99 percent of mothers are between twenty-one and thirty-nine years old. This interpretation could be trusted if data are normally distributed; however, most data sets are usually skewed and not normally distributed. In our earlier example, if there are a few sixty-five-year-old mothers in the sample, they do not indicate a normally distributed age of participants, with a standard deviation of three.</p>

<h3 id="testing-hypotheses">Testing Hypotheses</h3>

<p>Often program and practice evaluations are designed to test the hypothesized relationship between the intervention and progress on client outcomes. The intervention is considered the independent variable and the client outcome is the dependent variable.</p>

<blockquote>
  <p><strong>Important Research Terms</strong></p>

  <p>A <em>hypothesis</em> is a hypothetical explanation describing the  relationship between two variables.</p>

  <p>An <em>independent variable</em> is the variable presumed to cause a change to occur in the dependent variable.</p>

  <p>The <em>dependent variable</em> is the effect variable, or the variable changed by the independent variable.</p>
</blockquote>

<p>Several different types of hypothesis-testing are possible to determine whether there is a relationship between the intervention and client outcome. Each type of testing is determined by the type of quasi-experimental or experimental design used (see Chapter 9). Table 10.2 summarizes the types of hypotheses that are possible, the level of measurement required for independent and dependent variables, and the statistical tests to be used.</p>

<p><img src="https://i.imgur.com/qpSbmvM.png" alt="Imgur" /></p>

<h3 id="questions-of-association">Questions of Association</h3>

<p>Often hypothesis-testing occurs only to explore an association between the intervention and outcome. When the intervention is introduced, the client outcome is expected to change. With questions of association, nothing more can be determined, such as whether the intervention had a causal influence or was responsible for the change in client outcome. Questions of association are explored in a one-group pretest–posttest design. This design is a pre-experimental design (see Chapter 9).</p>

<p>Questions of association between the intervention and client outcome can be determined by applying a statistical test. The two most common statistical tests are chi-square and correlation. A <em>chi-square test</em> is used to determine whether the values of one variable are associated with the values of another variable. This test is also sometimes referred to as a cross-tabulation of variables. The chi-square test is used only when both the intervention and the client outcomes are measured at the nominal or ordinal level. In other words, both variables must be categorical. For example, an evaluation question could be, does attending a psychoeducational group session that provides information on the high-risk factors associated with contracting AIDS result in giving more correct answers to a true/ false test about AIDS after the session than before it? This can be determined by comparing the group members’ overall test scores before the intervention and after the intervention. The chi-square test can determine if the differences in overall scores are statistically significant.</p>

<p>A <em>correlation test</em> is the other statistical test frequently used to explore questions of association. It is also sometimes referred to as a Pearson correlation. This test not only answers the question of whether there is an association between the intervention and client outcome but also indicates how strong the association is. For example, an evaluation question might be, is there a relationship between the number of counseling group sessions fathers attended and the number of fathering activities that they carried out with their children? The assumption in a correlation test is that both variables are at the interval/ratio level. In this example, the intervention measured at the interval/ratio level would be the number of counseling group sessions members attended. The client outcome variable is also at the interval/ratio level and can be the number of specific activities that a father participated in with his child each week. The results of the correlation test may indicate that the variables are positively associated, negatively associated, or not associated.</p>

<p>The correlation test indicates the strength of the relationship between the intervention and client outcome and can range from –1.0 to 1.0 with a score of 1 or –1 indicating a perfect association, positive or negative, respectively. Evaluators are much more likely to find correlations between the intervention and client outcome to be less than ±0.6.</p>

<p>For example, we might say that a correlation score of 0.3 is a weak correlation, but we will keep in mind that most correlation scores in evaluations are rarely greater than 0.6. A positive correlation generally occurs when the higher numbers for one variable are associated with the higher numbers of another variable, and a negative correlation generally occurs when the higher numbers of one variable are associated with lower numbers of the other variable. For example, an evaluation that finds a negative association between family therapy and reduced marital stress indicates that as the number of family therapy sessions that couples participate in increases, the level of their marital stress decreases.</p>

<h3 id="questions-of-differences-between-groups">Questions of Differences Between Groups</h3>

<p>A second type of hypothesis-testing explores whether there is a difference between two or more groups, such as the group receiving the intervention and a comparison group that is not. A group design that is likely to rely on this type of analysis is the one-group pretest–posttest design with a comparison group. Two commonly used tests of differences between groups are the <em>t</em>-test and analysis of variance (ANOVA). A <em>t</em>-test examines differences across two groups, whereas ANOVA is a test examining differences across three or more groups.</p>

<p>The requirements for using a <em>t</em>-test are that the independent variable (an intervention is either introduced or not) must be dichotomous and nominal. The dependent variable (the client outcome) must be measurable at the interval/ratio level. The requirements for using an ANOVA are the same as for a <em>t</em>-test except the independent variable is nominal and includes three or more categories. In an evaluation, this could mean comparing three groups of participants (e.g., an intervention group, a group receiving traditional services, and a group receiving no services).</p>

<p>There are some basic questions that the <em>t</em>-test can answer in evaluations. For example, a program evaluation question may ask whether there is a difference in parenting attitudes (the client outcome) between those who have completed a nine-week intervention on parenting and those who have had no intervention. In brief, a <em>t</em>-test can be used to determine whether the two groups are statistically significantly different based on their parenting-attitudes scores. What we attempt to determine is whether the mean score for one group differs significantly from the mean score for the other group, or whether the observed differences are too small and thus attributable to either sampling error or chance factors. If we cannot determine that the mean scores are significantly different, then we conclude that the groups are the same for purposes of analysis.</p>

<p>There are two types of <em>t</em>-tests that are often used in evaluations: paired samples and independent samples. The requirements for both tests are that the independent variable is at the nominal level and the dependent variable is at the interval/ratio level. The decision about which type of <em>t</em>-test to use in an evaluation is based solely on the makeup of the groups in an evaluation.</p>

<p>A <em>paired-samples</em> t-_test_ is used if there is an interest in comparing a pretest score and a posttest score of the same group. This test is often used with a one-group pretest–posttest design. For example, the evaluation hypothesis may be to determine whether a ten-week community center enrichment program decreased classroom disruptions in adolescent boys. The pretest measures indicate how many disruptions the teacher reported weekly over the first semester of school before implementation of the program. During the second semester of the school year, the adolescents complete the program and the teacher records the number of classroom disruptions weekly again. Let’s presume that the pretest scores for the group were, on average,11.5 disruptions per week during the first semester. The posttest scores indicate a drop to an average of 9.2 disruptions weekly after the program is completed. The question is, Was there a significant difference in scores or are the differences attributable to chance or error? The <em>t</em>-test informs us whether the scores are statistically significantly different from one another. If they are, we could reasonably say that the program effectively reduced classroom disruptions. If the scores are not found to be significantly different, then we conclude that the pretest and posttest scores are basically the same, and we can conclude that the intervention did not significantly decrease classroom disruptions.</p>

<p>An <em>independent-samples</em> t-_test_ is used to compare two different groups. This test is often used with a one-group pretest–posttest design with a comparison group. An example would be to compare the self-esteem scores of two groups of clients after the first group completed a special program and the comparison group received no intervention. We could compare the self-esteem posttest mean score of the first group with the posttest mean score of the second group.</p>

<p>ANOVA allows for expansion of the principles of the <em>t</em>-test to a statistical test that examines whether there are differences across three or more groups. The ANOVA like the <em>t</em>-test assumes that the independent variable is nominal and the dependent variable is interval/ratio. In an evaluation using ANOVA, for example, this could mean comparing three different groups of students in a middle school who have truancy problems (e.g., the intervention group that a provides social support and a range of fun activities, a student group receiving traditional counseling services, and a student group receiving no services). We would compare the mean posttest scores of the three groups on their number of absences from school. Progress would be reflected in a reduction in the number of absences from school during the semester. We would be asking if the participants in the intervention group made significantly more progress in attending school than the other two groups.</p>

<p>An ANOVA can also be used to determine whether there are significant differences in the number of interventions of three different treatment subgroups. An ANOVA can be used if, for example, there are concerns that clients received different numbers of needed therapy sessions because of their geographic location. The research question might be, is there a difference in the number of therapy sessions provided because of clients’ geographic location? In this case, location could be measured as urban, suburban, and rural. The independent variable is the geographic location where the therapy sessions are provided (urban, suburban, or rural) which is a nominal variable; the dependent variable is the number of therapy sessions offered (interval/ratio). Let’s say that you conduct an evaluation and find out that urban clients received an average of six sessions per month, suburban clients received an average of five sessions a month, and rural clients received an average of two sessions a month. Your initial thought may be that urban and suburban clients receive statistically significantly more therapy sessions than the rural clients. However, the ANOVA findings may indicate that there is not a statistically significant difference in the number of therapy sessions among these groups; thus, you conclude that the differences in number of therapy sessions is simply due to chance and there is really no difference in the number of therapy sessions in each group for purposes of analysis.</p>

<h3 id="questions-of-prediction">Questions of Prediction</h3>

<p>Regression models are another statistical test that can be used in program evaluations. Several regression models or tests are available to predict a client outcome (dependent variable) from more than one intervention (independent variables). If participants have experienced a few interventions, then a regression model can also show how the interventions, working together, predict the dependent variable. Consider an agency that serves families after one of their children dies. If the family members participate in group therapy, individual grief counseling, and a support group, then the regression can show how much variance or change in the client outcome (e.g., recovery from grief) is accounted for by the combination of all three interventions. In addition, the regression can show whether specific interventions, such as the group therapy, are more effective than the other interventions in improving the client outcome. If one intervention is found not to be a significant predictor of the client outcome, then this is scientific evidence that this intervention may not be effective.</p>

<p>Two regression models that can be used in evaluations are linear regression and logistic regression. Both allow the research hypothesis to predict a dependent variable from a few independent variables. The difference between the models is that the dependent variable is at the interval/ratio level in linear regression and at the nominal level in logistic regression. For more information on regression analysis, see Weinbach and Grinnell (2014) as a resource.</p>

<h2 id="mixed-methods-and-data-analysis">MIXED METHODS AND DATA ANALYSIS</h2>

<p>Qualitative and quantitative data analyses have been presented separately so far in this chapter. This is not intended to mislead readers into thinking that the methods are unrelated; they often are related. Often evaluations use mixed methods, quantitative and qualitative. With mixed methods, each method enhances the other by its specific qualities. Sometimes one method is primary and the other secondary. Other times both quantitative and qualitative methods are equally valuable to an evaluation.</p>

<p>An illustration of an evaluation with both methods being equally important is Ellis, Marsh, and Craven (2009). Their mixed methods evaluation examined the effectiveness of a widely used peer support program designed to facilitate students’ transition to adolescence and high school. The quantitative component was an experimental design involving seventh-grade students in three schools. This design determined that the peer support program enhanced the students’ self-concept, school citizenship, connectedness, and resourcefulness during a two-year period. These four concepts were all measured by well-tested measurement instruments. The qualitative component focused on 90 percent of the experimental group who responded to open-ended questionnaire items and focus group discussions. These findings gave the students opportunities to express their views about the benefits of the program, the effectiveness of the peer support leaders, and other issues not identified by the quantitative methods. Using two of the qualitative data analysis strategies described earlier in the chapter (theme analysis and reducing responses to fewer general categories), their findings describe benefits of the peer support program in several domains including connectedness, problem-solving ability, sense of self, optimistic thinking, school citizenship, and adjustment to high school. Many of the quantitative and qualitative findings reinforced each other while the qualitative findings also provided major insights into the personal perspectives of the students.</p>

<p>The combination of qualitative and quantitative methods in evaluations offers several advantages to evaluations, including complementarity, triangulation, and accountability.</p>

<h3 id="complementary-data">Complementary Data</h3>

<p>Quantitative and qualitative methods each provide distinct kinds of data that can be complementary to each other and useful in evaluations. Quantitative data are useful for purposes such as providing numeric measures of client satisfaction, client outcomes, and profiles of prospective clients. The numeric measures can also be used to make decisions about program effectiveness. In contrast, qualitative data provide a human side to quantitative measures, showing why quantitative measures are important and how they affect real people. These qualitative data can provide a fuller picture of the concerns and encounters of people and provide greater identification with them, their plight, and the progress they make.</p>

<h3 id="triangulation">Triangulation</h3>

<p>Qualitative and quantitative findings on the same topic can be helpful in triangulating findings of an evaluation. Use of both methods can provide two different types of information on the same topic. For example, in one evaluation, clients with a dual diagnosis of developmental disability and mental illness were ask forced-response questions such as “Do you like living here?” (Dudley, Calhoun, Ahlgrim-Delzell, &amp; Conroy, 1998). They were also asked open-ended questions on the same topics to learn more about the meaning of their responses. Open-ended questions asked, “What do you like about living here?” and “What do you not like about living here?” Sometimes there were inconsistencies in the responses. For example, a few responded that they liked living where they were but then they focused on a long list of things that they did not like in responses to the open-ended questions. So, the combination of the two types of questions provided the evaluator with an opportunity to ask for clarification about any discrepancies between their responses. In other cases, open-ended questions clarified why many clients said that they liked where they lived, as several comments confirmed their positive responses (e.g., they liked having their own bedroom, being treated with respect, having more freedom than in the past).</p>

<blockquote>
  <p><strong>Example of an Evaluation Using a Mixed Methods Approach</strong></p>

  <p>The purpose of an evaluation conducted by Lynch (2007) was to explore the impact of an independent-living skills-training program on the resilience, social support, and life skills of sixteen ethnically diverse foster-care teenagers. The teenagers’ scores on standardized measures of resilience, social support, and life skills were compared before and after they participated in the training program. The improvements in scores from pretest to posttest were found to be statistically significant for social support but not for resilience and life skills. In a qualitative component of this mixed-methods study, their descriptions of the same constructs of resilience, social support, and life skills were, in most cases, consistent with scores on standardized measures. For example, most of the youth had difficulty describing and recollecting life skills information, such as managing money and locating appropriate housing, which was consistent with their scores suggesting that they “mastered” only about half of the life skills items.</p>
</blockquote>

<h3 id="accountability-in-giving-accurate-responses">Accountability in Giving Accurate Responses</h3>

<p>A third advantage of using mixed methods in evaluation is that it holds research participants accountable for giving accurate answers. When forced-response questions are asked, it is relatively easy for participants to answer them without revealing much, if any, information about their views or motives. In the previous example of clients with a dual diagnosis, a “yes” response to the question about whether they like where they live tells little about what they like. They may answer affirmatively because that is the normative response to give and they may think a negative response could get them into trouble with their providers. Therefore, qualitative responses on the same topic can hold participants accountable for their answers. If they do not like where they live, it will be more difficult for them to cover up their negative feelings in responses to the open-ended questions. Accountability in this case addresses validity or accuracy in reporting, for when a question is asked in two different ways, responses are likely to be closer to the truth or reality.</p>

<h2 id="summary">SUMMARY</h2>

<p>The chapter highlights many of the data analysis tools and strategies that can be used to analyze evaluation data. Quantitative, qualitative, and mixed methods strategies are introduced. Three options are introduced for qualitative data analysis: case studies, reducing responses to fewer general categories, and theme analysis. Quantitative data analysis strategies that are covered begin with descriptive statistics including frequency distributions, descriptive statistics, and measures of variability. Then a section on hypothesis-testing describes how evaluation studies can use statistical tests to determine whether an intervention has a significant positive impact on the client outcomes. Hypothesis-testing strategies are described for determining whether there is an association between an intervention and client outcomes, whether there is a difference between two or more groups in determining their impact on client outcomes, and predicting the combined impact of two or more interventions on client outcomes. Mixed methods strategies (combining quantitative and qualitative analyses) are also described for various purposes such as complementing quantitative and qualitative findings, triangulation, and holding the research participants accountable for giving accurate responses.</p>

<p>The information in this chapter can be supplemented by a text that exclusively covers qualitative and quantitative data analysis and provides more detail on how to conduct data analyses. Some of these texts are identified in the chapter and listed as references. The next chapter addresses the last steps in conducting an evaluation, preparing a report and disseminating the findings to stakeholders and other interested parties. The findings incorporated into a report are determined, to a large extent, by the choices made in data analysis, so this chapter is an important resource to use in the final steps of preparing and disseminating a report.</p>

<h2 id="discussion-questions-and-assignments">DISCUSSION QUESTIONS AND ASSIGNMENTS</h2>

<ol>
  <li>Select an evaluation report from a social work or evaluation journal. Critique the methods section of the evaluation by answering the following questions:
    <ul>
      <li>What data collection methods were used? Were the methods distinctly quantitative or qualitative? Or were mixed methods used?</li>
      <li>How were the data analyzed? Which qualitative and quantitative data analysis tools described in this chapter were used?</li>
    </ul>
  </li>
  <li>Find and review an evaluation study that used mixed methods. Did the authors refer to the evaluation as a mixed-methods evaluation? How did the data analysis and the findings link the quantitative and qualitative data analyses? Describe the findings that made connections between the quantitative and qualitative findings. Explain whether you think such findings were helpful to the overall findings section. If you think these combined findings were not helpful, explain why not.</li>
</ol>

<h2 id="references">REFERENCES</h2>

<ul>
  <li>Dudley, J. R. (2011). <em>Research methods for social work: Being producers and consumers of research</em> (upd. 2nd ed.). Boston, MA: Pearson.</li>
  <li>Dudley, J., Calhoun, M., Ahlgrim-Delzell, L., &amp; Conroy, J. (1998). Measuring the consumer satisfaction of class members of a lawsuit. <em>Journal of Intellectual Disability Research, 42</em>(3), 199–207.</li>
  <li>Ellis, L. A., Marsh, H. W., &amp; Craven, R. G. (2009). Addressing the challenges faced by early adolescents: A mixed-method evaluation of the benefits of peer support. <em>American</em> <em>Journal</em> <em>of Community Psychology, 44</em>(1–2), 54–75.</li>
  <li>Grantham, V. (2001). <em>Theme analysis of client records</em>. Unpublished student assignment, University of North Carolina, Charlotte, NC.</li>
  <li>Leary, A. (2003). <em>Room in the inn: Exploring church involvement in serving the homeless</em>. Unpublished student research project, University of North Carolina, Charlotte, NC.</li>
  <li>Lune, H., &amp; Berg, B. (2017). <em>Qualitative research methods for the social sciences</em> (9th ed.). Essex, England: Pearson Education.</li>
  <li>Lynch, C. J. (2007). <em>Exploring the implementation of a transitional services program for adolescents in the Texas Foster Care System</em>. Unpublished doctoral dissertation, University of Texas, Austin, TX.</li>
  <li>Royse, D., Thyer, B., &amp; Padgett, D. (2009). <em>Program evaluation: An introduction</em> (5th ed.). Belmont CA: Wadsworth Cengage Learning.</li>
  <li>Weinbach, R. W., &amp; Grinnell, R. M. (2014). <em>Statistics for social workers</em> (9th ed.). Boston, MA: Pearson.</li>
</ul>



  <small>tags: <em></em></small>



      </section>
      <footer>
        
        <p>This project is maintained by <a href="https://github.com/MrLyn20">MrLyn20</a></p>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/Lyn/assets/js/scale.fix.js"></script>
  </body>
</html>
